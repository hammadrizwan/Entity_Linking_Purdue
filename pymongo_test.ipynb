{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39deb362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\purdue\\lib\\site-packages\\pymongo\\pyopenssl_context.py:26: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
      "  from cryptography.x509 import load_der_x509_certificate as _load_der_x509_certificate\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e8079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "# client = MongoClient(‘host\", port_number)\n",
    "client = MongoClient(\"localhost\", 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4d731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydatabase = client[\"PapersWithCode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ab87ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'PapersWithCode')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c361911",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ab7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[\"dataset_entities\"]={}\n",
    "entities[\"method_entities\"]={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62277025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mycollection = mydatabase[\"datasets\"]\n",
    "cursor = mycollection.find({})\n",
    "for document in cursor:\n",
    "#     print(document[\"name\"])\n",
    "#     print(document[\"full_name\"])\n",
    "#     print(document[\"variants\"])\n",
    "#     print(document[\"paper\"])\n",
    "    try:\n",
    "        entities[\"dataset_entities\"][document[\"name\"]]={\"full_name\":document[\"full_name\"],\"variants\":document[\"variants\"], \"title\":document[\"paper\"][\"title\"], \"url\":document[\"paper\"][\"url\"]}\n",
    "    except:\n",
    "        entities[\"dataset_entities\"][document[\"name\"]]={\"full_name\":document[\"full_name\"],\"variants\":document[\"variants\"], \"title\":None, \"url\":None}\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd56060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ea488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entities={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e68bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mycollection = mydatabase[\"methods\"]\n",
    "cursor = mycollection.find({})\n",
    "for document in cursor:\n",
    "#     print(document[\"name\"])\n",
    "#     print(document[\"full_name\"])\n",
    "#     print(document[\"source_url\"])\n",
    "#     print(document[\"source_title\"])\n",
    "    entities[\"method_entities\"][document[\"name\"]]={\"full_name\":document[\"full_name\"],\"url\":document[\"source_url\"],\"title\":document[\"source_title\"]}\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c397d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaee6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in entities.keys():\n",
    "#     for subkey in \n",
    "#     if(len(entities[key])!=3):\n",
    "#         print(entities[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2564c232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_entities': {'MNIST': {'full_name': '',\n",
       "   'variants': ['USPS-to-MNIST',\n",
       "    'MNIST-to-USPS',\n",
       "    'Rotating MNIST',\n",
       "    'Noisy MNIST (Motion)',\n",
       "    'Noisy MNIST (Contrast)',\n",
       "    'Noisy MNIST (AWGN)',\n",
       "    'MNIST (Conditional)',\n",
       "    'Indexed Rotating MNIST',\n",
       "    'Rotated MNIST',\n",
       "    'Moving MNIST',\n",
       "    'Sequential MNIST',\n",
       "    'SVNH-to-MNIST',\n",
       "    'MNIST-test',\n",
       "    'MNIST-full',\n",
       "    'MNIST',\n",
       "    '75 Superpixel MNIST'],\n",
       "   'title': 'Gradient-based learning applied to document recognition',\n",
       "   'url': 'http://arxiv.org/pdf/1102.0183.pdf'},\n",
       "  'CelebA': {'full_name': 'CelebFaces Attributes Dataset',\n",
       "   'variants': ['CelebA Aligned',\n",
       "    'CelebA 64x64',\n",
       "    'CelebA 256x256',\n",
       "    'CelebA 128 x 128',\n",
       "    'CelebA + AFLW Unaligned',\n",
       "    'CelebA 128x128',\n",
       "    'CelebA'],\n",
       "   'title': 'Deep Learning Face Attributes in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-learning-face-attributes-in-the-wild'},\n",
       "  'JFT-300M': {'full_name': 'JFT-300M',\n",
       "   'variants': ['JFT-300M'],\n",
       "   'title': 'Revisiting Unreasonable Effectiveness of Data in Deep Learning Era',\n",
       "   'url': 'https://paperswithcode.com/paper/revisiting-unreasonable-effectiveness-of-data'},\n",
       "  'GLUE': {'full_name': 'General Language Understanding Evaluation benchmark',\n",
       "   'variants': ['FinanceInc/auditor_sentiment_2021',\n",
       "    'FinanceInc/auditor_sentiment',\n",
       "    'CHANGE-IT',\n",
       "    'GLUE STSB',\n",
       "    'GLUE SST2',\n",
       "    'GLUE RTE',\n",
       "    'GLUE QQP',\n",
       "    'GLUE QNLI',\n",
       "    'GLUE MNLI',\n",
       "    'GLUE COLA',\n",
       "    'GLUE WNLI',\n",
       "    'GLUE MRPC',\n",
       "    'GLUE',\n",
       "    'RTE',\n",
       "    'WNLI',\n",
       "    'QNLI',\n",
       "    'MultiNLI',\n",
       "    'Quora Question Pairs',\n",
       "    'STS Benchmark',\n",
       "    'MRPC',\n",
       "    'SST-2 Binary classification',\n",
       "    'CoLA'],\n",
       "   'title': 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/glue-a-multi-task-benchmark-and-analysis'},\n",
       "  'MultiNLI': {'full_name': 'Multi-Genre Natural Language Inference',\n",
       "   'variants': ['MultiNLI',\n",
       "    'MultiNLI Dev',\n",
       "    'MNLI',\n",
       "    'multi_nli',\n",
       "    'MultiNLI-matched',\n",
       "    'MultiNLI-mismatched'],\n",
       "   'title': 'A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference',\n",
       "   'url': 'https://paperswithcode.com/paper/a-broad-coverage-challenge-corpus-for'},\n",
       "  'ImageNet': {'full_name': '',\n",
       "   'variants': ['imagenet-1k',\n",
       "    'ImageNet V2',\n",
       "    'ImageNet 50 samples per class',\n",
       "    'ImageNet 512x512',\n",
       "    'ImageNet - 500 classes + 10 steps of 50 classes',\n",
       "    'ImageNet Detection',\n",
       "    'ImageNet-Caltech',\n",
       "    'ImageNet-50 (5 tasks) ',\n",
       "    'ImageNet-100',\n",
       "    'ImageNet ResNet-50 - 90 Epochs',\n",
       "    'ImageNet ResNet-50 - 60 Epochs',\n",
       "    'ImageNet ResNet-50 - 50 Epochs',\n",
       "    'ImageNet - ResNet 50 - 90% sparsity',\n",
       "    'ImageNet64x64',\n",
       "    'ImageNet 64x64',\n",
       "    'ImageNet - 500 classes + 50 steps of 10 classes',\n",
       "    'ImageNet - 500 classes + 5 steps of 100 classes',\n",
       "    'ImageNet-100 - 50 classes + 50 steps of 1 class',\n",
       "    'ImageNet-100 - 50 classes + 5 steps of 10 classes',\n",
       "    'ImageNet-100 - 50 classes + 25 steps of 2 classes',\n",
       "    'ImageNet-100 - 50 classes + 10 steps of 5 classes',\n",
       "    'NAS-Bench-201, ImageNet-16-120',\n",
       "    'Imagenet-dog-15',\n",
       "    'ImageNet-R',\n",
       "    'ImageNet-LT',\n",
       "    'ImageNet-A',\n",
       "    'ImageNet-10',\n",
       "    'ImageNet ReaL',\n",
       "    'ImageNet 32x32',\n",
       "    'ImageNet 128x128',\n",
       "    'ImageNet - 10% labeled data',\n",
       "    'ImageNet - 1% labeled data',\n",
       "    'ImageNet - 0-Shot',\n",
       "    'ImageNet (targeted PGD, max perturbation=16)',\n",
       "    'ImageNet (non-targeted PGD, max perturbation=4)',\n",
       "    'ImageNet (Fine-grained 6 Tasks)',\n",
       "    'ImageNet',\n",
       "    'ILSVRC 2016',\n",
       "    'ILSVRC 2015'],\n",
       "   'title': 'ImageNet: A large-scale hierarchical image database',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2009.5206848'},\n",
       "  'Penn Treebank': {'full_name': '',\n",
       "   'variants': ['PTB dataset, ECG lead II',\n",
       "    'PTB',\n",
       "    'Penn Treebank (Character Level) 3x1000 LSTM - 500 Epochs',\n",
       "    'Penn Treebank (Word Level)',\n",
       "    'Penn Treebank (Character Level)',\n",
       "    'Penn Treebank'],\n",
       "   'title': 'Building a Large Annotated Corpus of English: The Penn Treebank',\n",
       "   'url': 'http://dl.acm.org/citation.cfm?id=972470.972475'},\n",
       "  'WikiText-103': {'full_name': 'WikiText-103',\n",
       "   'variants': ['WikiText-103'],\n",
       "   'title': 'Pointer Sentinel Mixture Models',\n",
       "   'url': 'https://paperswithcode.com/paper/pointer-sentinel-mixture-models'},\n",
       "  'LFW': {'full_name': 'Labeled Faces in the Wild',\n",
       "   'variants': ['LFW', 'Labeled Faces in the Wild', 'LFW (Online Open Set)'],\n",
       "   'title': 'Labeled faces in the wild: A database for studying face recognition in unconstrained environments',\n",
       "   'url': 'http://vis-www.cs.umass.edu/lfw/lfw.pdf'},\n",
       "  'WikiSQL': {'full_name': 'WikiSQL',\n",
       "   'variants': ['WikiSQL'],\n",
       "   'title': 'Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/seq2sql-generating-structured-queries-from'},\n",
       "  'OpenAI Gym': {'full_name': 'OpenAI Gym',\n",
       "   'variants': ['OpenAI Gym',\n",
       "    'Cart Pole (OpenAI Gym)',\n",
       "    'Lunar Lander (OpenAI Gym)'],\n",
       "   'title': 'OpenAI Gym',\n",
       "   'url': 'https://paperswithcode.com/paper/openai-gym'},\n",
       "  'WikiText-2': {'full_name': 'WikiText-2',\n",
       "   'variants': ['WikiText-103', 'WikiText-2', 'wikitext wikitext-2-raw-v1'],\n",
       "   'title': 'Pointer Sentinel Mixture Models',\n",
       "   'url': 'https://paperswithcode.com/paper/pointer-sentinel-mixture-models'},\n",
       "  'WikiLarge': {'full_name': '',\n",
       "   'variants': ['WikiLarge'],\n",
       "   'title': 'Sentence Simplification with Deep Reinforcement Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/sentence-simplification-with-deep'},\n",
       "  'Food-101': {'full_name': '',\n",
       "   'variants': ['Food-101', 'Food-101N', 'food101'],\n",
       "   'title': 'Food-101 - Mining Discriminative Components with Random Forests',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-10599-4_29'},\n",
       "  'Fashion-MNIST': {'full_name': '',\n",
       "   'variants': ['Fashion-MNIST', 'Rotated Fashion-MNIST', 'fashion_mnist'],\n",
       "   'title': 'Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms',\n",
       "   'url': 'https://paperswithcode.com/paper/fashion-mnist-a-novel-image-dataset-for'},\n",
       "  'ShapeNet': {'full_name': '',\n",
       "   'variants': ['ShapeNet',\n",
       "    'ShapeNet Car',\n",
       "    'ShapeNet Chair',\n",
       "    'ShapeNet Airplane'],\n",
       "   'title': 'ShapeNet: An Information-Rich 3D Model Repository',\n",
       "   'url': 'https://paperswithcode.com/paper/shapenet-an-information-rich-3d-model'},\n",
       "  'CINIC-10': {'full_name': 'CINIC-10',\n",
       "   'variants': ['CINIC-10'],\n",
       "   'title': 'CINIC-10 is not ImageNet or CIFAR-10',\n",
       "   'url': 'https://paperswithcode.com/paper/cinic-10-is-not-imagenet-or-cifar-10'},\n",
       "  'Flickr30k': {'full_name': 'Flickr30k',\n",
       "   'variants': ['Flickr30k',\n",
       "    'Flickr',\n",
       "    'Flickr30k Captions test',\n",
       "    'Flickr30K 1K test'],\n",
       "   'title': 'From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions',\n",
       "   'url': 'https://paperswithcode.com/paper/from-image-descriptions-to-visual-denotations'},\n",
       "  'COCO': {'full_name': 'Microsoft Common Objects in Context',\n",
       "   'variants': ['COCO 2017 (Sports, Food)',\n",
       "    'COCO 2017 (Outdoor, Accessories, Appliance, Truck)',\n",
       "    'COCO 2017 (Electronic, Indoor, Kitchen, Furniture)',\n",
       "    'COCO Visual Question Answering (VQA) abstract images 1.0 open ended',\n",
       "    'COCO Visual Question Answering (VQA) abstract 1.0 multiple choice',\n",
       "    'COCO 2017',\n",
       "    'COCO 2014',\n",
       "    'coco minval',\n",
       "    'COCO-Stuff-3',\n",
       "    'COCO-Stuff 256x256',\n",
       "    'COCO 256 x 256',\n",
       "    'COCO 2015',\n",
       "    'MS-COCO (10-shot)',\n",
       "    'MS-COCO',\n",
       "    'COCO Visual Question Answering (VQA) real images 2.0 open ended',\n",
       "    'COCO Visual Question Answering (VQA) real images 1.0 open ended',\n",
       "    'MSCOCO',\n",
       "    'DensePose-COCO',\n",
       "    'COCO_20k',\n",
       "    'COCO-Animals',\n",
       "    'COCO+',\n",
       "    'COCO test-dev',\n",
       "    'COCO test-challenge',\n",
       "    'COCO panoptic',\n",
       "    'COCO minival',\n",
       "    'COCO count-test',\n",
       "    'COCO Visual Question Answering (VQA) real images 1.0 multiple choice',\n",
       "    'COCO (image as query)',\n",
       "    'COCO'],\n",
       "   'title': 'Microsoft COCO: Common Objects in Context',\n",
       "   'url': 'https://paperswithcode.com/paper/microsoft-coco-common-objects-in-context'},\n",
       "  'BSDS500': {'full_name': 'Berkeley Segmentation Dataset 500',\n",
       "   'variants': ['BSDS500 (Quality 30 Grayscale)',\n",
       "    'BSDS500 (Quality 30 Color)',\n",
       "    'BSDS500 (Quality 20 Grayscale)',\n",
       "    'BSDS500 (Quality 20 Color)',\n",
       "    'BSDS500 (Quality 10 Grayscale)',\n",
       "    'BSDS500 (Quality 10 Color)',\n",
       "    'BSDS500'],\n",
       "   'title': 'Contour Detection and Hierarchical Image Segmentation',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2010.161'},\n",
       "  'MHP': {'full_name': 'Multiple-Human Parsing',\n",
       "   'variants': ['MHP', 'MHP v2.0', 'MHP v1.0'],\n",
       "   'title': 'Multiple-Human Parsing in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/multiple-human-parsing-in-the-wild'},\n",
       "  'LRW': {'full_name': 'Lip Reading in the Wild',\n",
       "   'variants': ['LRW', 'Lip Reading in the Wild', 'Lipreading in the Wild'],\n",
       "   'title': 'Lip Reading in the Wild',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-54184-6_6'},\n",
       "  'FDDB': {'full_name': 'Face Detection Dataset and Benchmark',\n",
       "   'variants': ['FDDB'],\n",
       "   'title': 'Fddb: A benchmark for face detection in unconstrained settings',\n",
       "   'url': 'http://vis-www.cs.umass.edu/fddb/fddb.pdf'},\n",
       "  'GOT-10k': {'full_name': 'Generic Object Tracking Benchmark',\n",
       "   'variants': ['GOT-10k'],\n",
       "   'title': 'GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/got-10k-a-large-high-diversity-benchmark-for'},\n",
       "  'DukeMTMC-reID': {'full_name': '',\n",
       "   'variants': ['DukeMTMC-reID',\n",
       "    'DukeMTMCreID',\n",
       "    'Market-1501->DukeMTMC-reID',\n",
       "    'MSMT17->DukeMTMC-reID'],\n",
       "   'title': 'Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/performance-measures-and-a-data-set-for-multi'},\n",
       "  'KITTI': {'full_name': '',\n",
       "   'variants': ['2019_test set',\n",
       "    'KITTI (FCGF setting)',\n",
       "    '2D KITTI Cars Moderate',\n",
       "    'KITTI 2015 Scene Flow Test',\n",
       "    'KITTI 2015 Scene Flow Training',\n",
       "    'KITTI Novel View Synthesis',\n",
       "    'KITTI 2015 - unsupervised',\n",
       "    'KITTI 2012 - unsupervised',\n",
       "    'KITTI Pedestrians Moderate val',\n",
       "    'KITTI Pedestrian Hard',\n",
       "    'KITTI Panoptic Segmentation',\n",
       "    'KITTI Object Tracking Evaluation 2012',\n",
       "    'KITTI Horizon',\n",
       "    'KITTI Depth Completion Eigen Split',\n",
       "    'KITTI Tracking test',\n",
       "    'KITTI2015',\n",
       "    'KITTI 2015 unsupervised',\n",
       "    'KITTI 2015 - 4x upscaling',\n",
       "    'KITTI 2015 - 2x upscaling',\n",
       "    'KITTI 2015',\n",
       "    'KITTI2012',\n",
       "    'KITTI 2012 unsupervised',\n",
       "    'KITTI 2012 - 4x upscaling',\n",
       "    'KITTI 2012 - 2x upscaling',\n",
       "    'KITTI 2012',\n",
       "    'PreSIL to KITTI',\n",
       "    'KITTI Semantic Segmentation',\n",
       "    'KITTI Pedestrians Moderate',\n",
       "    'KITTI Pedestrians Hard',\n",
       "    'KITTI Pedestrians Easy',\n",
       "    'KITTI Pedestrian Moderate val',\n",
       "    'KITTI Pedestrian Hard val',\n",
       "    'KITTI Pedestrian Easy val',\n",
       "    'KITTI Eigen split unsupervised',\n",
       "    'KITTI Eigen split',\n",
       "    'KITTI Depth Completion',\n",
       "    'KITTI Cyclists Moderate',\n",
       "    'KITTI Cyclists Hard',\n",
       "    'KITTI Cyclists Easy',\n",
       "    'KITTI Cyclist Moderate val',\n",
       "    'KITTI Cyclist Hard val',\n",
       "    'KITTI Cyclist Easy val',\n",
       "    'KITTI Cars Moderate val',\n",
       "    'KITTI Cars Moderate',\n",
       "    'KITTI Cars Hard val',\n",
       "    'KITTI Cars Hard',\n",
       "    'KITTI Cars Easy val',\n",
       "    'KITTI Cars Easy',\n",
       "    'KITTI'],\n",
       "   'title': 'Are we ready for autonomous driving? The KITTI vision benchmark suite',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2012.6248074'},\n",
       "  'UCF101': {'full_name': 'UCF101 Human Actions dataset',\n",
       "   'variants': ['UCF-HMDB',\n",
       "    'UCF101-24',\n",
       "    'UCF101',\n",
       "    'UCF-101 16 frames, Unconditional, Single GPU',\n",
       "    'UCF-101 16 frames, 64x64, Unconditional',\n",
       "    'UCF-101 16 frames, 128x128, Unconditional',\n",
       "    'UCF-101'],\n",
       "   'title': 'UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/ucf101-a-dataset-of-101-human-actions-classes'},\n",
       "  'HMDB51': {'full_name': '',\n",
       "   'variants': ['HMDB-UCF',\n",
       "    'UCF-to-HMDBsmall',\n",
       "    'UCF-to-HMDBfull',\n",
       "    'UCF --> HMDB (full)',\n",
       "    'Olympic-to-HMDBsmall',\n",
       "    'HMDBsmall-to-UCF',\n",
       "    'HMDBfull-to-UCF',\n",
       "    'HMDB --> UCF (full)',\n",
       "    'HMDB51',\n",
       "    'HMDB-51'],\n",
       "   'title': 'HMDB: A large video database for human motion recognition',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2011.6126543'},\n",
       "  'MIMIC-III': {'full_name': 'The Medical Information Mart for Intensive Care III',\n",
       "   'variants': ['MIMIC-III'],\n",
       "   'title': 'MIMIC-III, a freely accessible critical care database',\n",
       "   'url': 'https://paperswithcode.com/paper/mimic-iii-a-freely-accessible-critical-care'},\n",
       "  'TID2013': {'full_name': 'TID2013',\n",
       "   'variants': ['TID2013'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'LIVE': {'full_name': 'Laboratory for Image & Video Engineering',\n",
       "   'variants': ['LIVE'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Visual Genome': {'full_name': '',\n",
       "   'variants': ['VG graph-text',\n",
       "    'Visual Genome 256x256',\n",
       "    'Visual Genome 64x64',\n",
       "    'Visual Genome 128x128',\n",
       "    'Visual Genome (subjects)',\n",
       "    'Visual Genome (pairs)',\n",
       "    'Visual Genome'],\n",
       "   'title': 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations',\n",
       "   'url': 'https://paperswithcode.com/paper/visual-genome-connecting-language-and-vision'},\n",
       "  'COCO-Stuff': {'full_name': 'Common Objects in COntext-stuff',\n",
       "   'variants': ['COCO-Stuff-27',\n",
       "    'COCO-Stuff full',\n",
       "    'COCO-Stuff-3',\n",
       "    'COCO-Stuff-15',\n",
       "    'COCO-Stuff test',\n",
       "    'COCO-Stuff Labels-to-Photos',\n",
       "    'COCO-Stuff 64x64',\n",
       "    'COCO-Stuff 128x128',\n",
       "    'COCO-Stuff'],\n",
       "   'title': 'COCO-Stuff: Thing and Stuff Classes in Context',\n",
       "   'url': 'https://paperswithcode.com/paper/coco-stuff-thing-and-stuff-classes-in-context'},\n",
       "  'MARS': {'full_name': 'Motion Analysis and Re-identification Set',\n",
       "   'variants': ['MARS'],\n",
       "   'title': 'MARS: A Video Benchmark for Large-Scale Person Re-Identification',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-46466-4_52'},\n",
       "  'iLIDS-VID': {'full_name': 'iLIDS-VID',\n",
       "   'variants': ['iLIDS-VID'],\n",
       "   'title': 'Unsupervised Person Re-identification by Deep Learning Tracklet Association',\n",
       "   'url': 'https://paperswithcode.com/paper/unsupervised-person-re-identification-by-deep-1'},\n",
       "  'Market-1501': {'full_name': '',\n",
       "   'variants': ['Market-1501',\n",
       "    'DukeMTMC-reID->Market-1501',\n",
       "    'Duke to Market',\n",
       "    'Market to Duke',\n",
       "    'Market to MSMT'],\n",
       "   'title': 'Scalable Person Re-Identification: A Benchmark',\n",
       "   'url': 'https://paperswithcode.com/paper/scalable-person-re-identification-a-benchmark'},\n",
       "  'VIPeR': {'full_name': 'Viewpoint Invariant Pedestrian Recognition',\n",
       "   'variants': ['VIPeR'],\n",
       "   'title': 'Evaluating appearance models for recognition, reacquisition, and tracking',\n",
       "   'url': 'http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.7285&rep=rep1&type=pdf'},\n",
       "  'CUHK01': {'full_name': 'CUHK Person Re-identification',\n",
       "   'variants': ['CUHK01'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'PRID2011': {'full_name': 'Person RE-ID 2011',\n",
       "   'variants': ['PRID2011'],\n",
       "   'title': 'Mask R-CNN',\n",
       "   'url': 'https://paperswithcode.com/paper/mask-r-cnn'},\n",
       "  'CUHK03': {'full_name': 'Chinese University of Hong Kong Re-identification',\n",
       "   'variants': ['CUHK - Blur Detection Dataset',\n",
       "    'CUHK',\n",
       "    'CUHK03 labeled',\n",
       "    'CUHK03 detected',\n",
       "    'CUHK03 (detected)',\n",
       "    'CUHK03'],\n",
       "   'title': 'DeepReID: Deep Filter Pairing Neural Network for Person Re-Identification',\n",
       "   'url': 'https://paperswithcode.com/paper/deepreid-deep-filter-pairing-neural-network'},\n",
       "  'VehicleID': {'full_name': 'PKU VehicleID',\n",
       "   'variants': ['VehicleID',\n",
       "    'VehicleID Small',\n",
       "    'VehicleID Medium',\n",
       "    'VehicleID Large'],\n",
       "   'title': 'Deep Relative Distance Learning: Tell the Difference Between Similar Vehicles',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-relative-distance-learning-tell-the'},\n",
       "  'BP4D': {'full_name': '',\n",
       "   'variants': ['BP4D'],\n",
       "   'title': 'BP4D-Spontaneous: a high-resolution spontaneous 3D dynamic facial expression database',\n",
       "   'url': 'https://doi.org/10.1016/j.imavis.2014.06.002'},\n",
       "  'DISFA': {'full_name': 'Denver Intensity of Spontaneous Facial Action',\n",
       "   'variants': ['DISFA'],\n",
       "   'title': 'DISFA: A Spontaneous Facial Action Intensity Database',\n",
       "   'url': 'https://doi.org/10.1109/T-AFFC.2013.4'},\n",
       "  'CUB-200-2011': {'full_name': 'Caltech-UCSD Birds-200-2011',\n",
       "   'variants': ['CUB-200-2011, 10 samples per class',\n",
       "    'CUB-200-2011 5-way (5-shot)',\n",
       "    'CUB-200-2011 5-way (1-shot)',\n",
       "    'Imbalanced CUB-200-2011',\n",
       "    'CUB-200-2011, 5 samples per class',\n",
       "    'CUB-200-2011, 30 samples per class',\n",
       "    'CUB-LT',\n",
       "    'CUB-200-2011 - 0-Shot',\n",
       "    'CUB-200 - 0-Shot Learning',\n",
       "    'CUB Birds',\n",
       "    'CUB 200 50-way (0-shot)',\n",
       "    'CUB 200 5-way 5-shot',\n",
       "    'CUB 200 5-way 1-shot',\n",
       "    'CUB 128 x 128',\n",
       "    'CUB',\n",
       "    'CUB-200-2011'],\n",
       "   'title': 'The Caltech-UCSD Birds-200-2011 Dataset',\n",
       "   'url': 'http://www.vision.caltech.edu/visipedia/CUB-200-2011.html'},\n",
       "  'SUN397': {'full_name': 'SUN397',\n",
       "   'variants': ['SUN397'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'FewRel': {'full_name': 'Few-Shot Relation Classification Dataset',\n",
       "   'variants': ['FewRel'],\n",
       "   'title': 'FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation',\n",
       "   'url': 'https://paperswithcode.com/paper/fewrel-a-large-scale-supervised-few-shot'},\n",
       "  'DuReader': {'full_name': '',\n",
       "   'variants': ['DuReader'],\n",
       "   'title': 'DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications',\n",
       "   'url': 'https://paperswithcode.com/paper/dureader-a-chinese-machine-reading'},\n",
       "  'SearchQA': {'full_name': '',\n",
       "   'variants': ['SearchQA'],\n",
       "   'title': 'SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine',\n",
       "   'url': 'https://paperswithcode.com/paper/searchqa-a-new-qa-dataset-augmented-with'},\n",
       "  'CoQA': {'full_name': 'Conversational Question Answering Challenge',\n",
       "   'variants': ['CoQA'],\n",
       "   'title': 'CoQA: A Conversational Question Answering Challenge',\n",
       "   'url': 'https://paperswithcode.com/paper/coqa-a-conversational-question-answering'},\n",
       "  'MovieQA': {'full_name': 'MovieQA',\n",
       "   'variants': ['MovieQA'],\n",
       "   'title': 'MovieQA: Understanding Stories in Movies through Question-Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/movieqa-understanding-stories-in-movies'},\n",
       "  'Hutter Prize': {'full_name': '',\n",
       "   'variants': ['Hutter Prize'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Text8': {'full_name': '',\n",
       "   'variants': ['Text8'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ICDAR 2013': {'full_name': 'ICDAR 2013',\n",
       "   'variants': ['ICDAR 2013', 'ICDAR2013'],\n",
       "   'title': 'ICDAR 2013 Robust Reading Competition',\n",
       "   'url': 'https://doi.org/10.1109/ICDAR.2013.221'},\n",
       "  'Visual Madlibs': {'full_name': '',\n",
       "   'variants': ['Visual Madlibs'],\n",
       "   'title': 'Visual Madlibs: Fill in the blank Image Generation and Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/visual-madlibs-fill-in-the-blank-image'},\n",
       "  'DAQUAR': {'full_name': '',\n",
       "   'variants': ['DAQUAR'],\n",
       "   'title': 'A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input',\n",
       "   'url': 'https://paperswithcode.com/paper/a-multi-world-approach-to-question-answering'},\n",
       "  'Visual7W': {'full_name': '',\n",
       "   'variants': ['Visual7W'],\n",
       "   'title': 'Visual7W: Grounded Question Answering in Images',\n",
       "   'url': 'https://paperswithcode.com/paper/visual7w-grounded-question-answering-in'},\n",
       "  'FM-IQA': {'full_name': 'Freestyle Multilingual Image Question Answering',\n",
       "   'variants': ['FM-IQA'],\n",
       "   'title': 'Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/are-you-talking-to-a-machine-dataset-and'},\n",
       "  'NewsQA': {'full_name': '',\n",
       "   'variants': ['NewsQA'],\n",
       "   'title': 'NewsQA: A Machine Comprehension Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/newsqa-a-machine-comprehension-dataset'},\n",
       "  'TriviaQA': {'full_name': '',\n",
       "   'variants': ['TriviaQA', 'KILT: TriviaQA'],\n",
       "   'title': 'TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension',\n",
       "   'url': 'https://paperswithcode.com/paper/triviaqa-a-large-scale-distantly-supervised'},\n",
       "  'RecipeQA': {'full_name': '',\n",
       "   'variants': ['RecipeQA'],\n",
       "   'title': 'RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes',\n",
       "   'url': 'https://paperswithcode.com/paper/recipeqa-a-challenge-dataset-for-multimodal'},\n",
       "  'SQuAD': {'full_name': 'Stanford Question Answering Dataset',\n",
       "   'variants': ['The Stanford Question Answering Dataset',\n",
       "    'squad_v2',\n",
       "    'SQuAD',\n",
       "    'SQuAD2.0 dev',\n",
       "    'SQuAD2.0',\n",
       "    'SQuAD1.1 dev',\n",
       "    'SQuAD1.1'],\n",
       "   'title': 'SQuAD: 100,000+ Questions for Machine Comprehension of Text',\n",
       "   'url': 'https://paperswithcode.com/paper/squad-100000-questions-for-machine'},\n",
       "  'NarrativeQA': {'full_name': 'NarrativeQA',\n",
       "   'variants': ['NarrativeQA'],\n",
       "   'title': 'The NarrativeQA Reading Comprehension Challenge',\n",
       "   'url': 'https://paperswithcode.com/paper/the-narrativeqa-reading-comprehension'},\n",
       "  'CliCR': {'full_name': 'CliCR',\n",
       "   'variants': ['CliCR'],\n",
       "   'title': 'CliCR: A Dataset of Clinical Case Reports for Machine Reading Comprehension',\n",
       "   'url': 'https://paperswithcode.com/paper/clicr-a-dataset-of-clinical-case-reports-for'},\n",
       "  'MS MARCO': {'full_name': 'Microsoft Machine Reading Comprehension Dataset',\n",
       "   'variants': ['MS MARCO', 'MSMARCO', 'MSMARCO (BEIR)'],\n",
       "   'title': 'MS MARCO: A Human Generated MAchine Reading COmprehension Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/ms-marco-a-human-generated-machine-reading'},\n",
       "  'MultiRC': {'full_name': 'Multi-Sentence Reading Comprehension',\n",
       "   'variants': ['MultiRC'],\n",
       "   'title': 'Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences',\n",
       "   'url': 'https://paperswithcode.com/paper/looking-beyond-the-surface-a-challenge-set'},\n",
       "  'HotpotQA': {'full_name': '',\n",
       "   'variants': ['HotpotQA', 'HotpotQA (BEIR)'],\n",
       "   'title': 'HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/hotpotqa-a-dataset-for-diverse-explainable'},\n",
       "  'RACE': {'full_name': 'ReAding Comprehension dataset from Examinations',\n",
       "   'variants': ['RACE'],\n",
       "   'title': 'RACE: Large-scale ReAding Comprehension Dataset From Examinations',\n",
       "   'url': 'https://paperswithcode.com/paper/race-large-scale-reading-comprehension'},\n",
       "  'QuAC': {'full_name': 'Question Answering in Context',\n",
       "   'variants': ['QuAC'],\n",
       "   'title': 'QuAC: Question Answering in Context',\n",
       "   'url': 'https://paperswithcode.com/paper/quac-question-answering-in-context-1'},\n",
       "  'Wizard-of-Oz': {'full_name': '',\n",
       "   'variants': ['Wizard-of-Oz'],\n",
       "   'title': 'Neural Belief Tracker: Data-Driven Dialogue State Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/neural-belief-tracker-data-driven-dialogue'},\n",
       "  'VCR': {'full_name': 'Visual Commonsense Reasoning',\n",
       "   'variants': ['VCR',\n",
       "    'VCR (QA-R) test',\n",
       "    'VCR (QA-R) dev',\n",
       "    'VCR (Q-AR) test',\n",
       "    'VCR (Q-AR) dev',\n",
       "    'VCR (Q-A) test',\n",
       "    'VCR (Q-A) dev'],\n",
       "   'title': 'From Recognition to Cognition: Visual Commonsense Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/from-recognition-to-cognition-visual'},\n",
       "  'SWAG': {'full_name': 'Situations With Adversarial Generations',\n",
       "   'variants': ['SWAG'],\n",
       "   'title': 'SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference',\n",
       "   'url': 'https://paperswithcode.com/paper/swag-a-large-scale-adversarial-dataset-for'},\n",
       "  'Event2Mind': {'full_name': '',\n",
       "   'variants': ['Event2Mind', 'Event2Mind dev', 'Event2Mind test'],\n",
       "   'title': 'Event2Mind: Commonsense Inference on Events, Intents, and Reactions',\n",
       "   'url': 'https://paperswithcode.com/paper/event2mind-commonsense-inference-on-events'},\n",
       "  'XNLI': {'full_name': 'Cross-lingual Natural Language Inference',\n",
       "   'variants': ['XNLI Dev',\n",
       "    'XNLI',\n",
       "    'XNLI Zero-Shot English-to-Spanish',\n",
       "    'XNLI Zero-Shot English-to-German',\n",
       "    'XNLI Zero-Shot English-to-French',\n",
       "    'XNLI French',\n",
       "    'XNLI Chinese Dev',\n",
       "    'XNLI Chinese'],\n",
       "   'title': 'XNLI: Evaluating Cross-lingual Sentence Representations',\n",
       "   'url': 'https://paperswithcode.com/paper/xnli-evaluating-cross-lingual-sentence'},\n",
       "  'SNLI': {'full_name': 'Stanford Natural Language Inference',\n",
       "   'variants': ['SNLI', 'SNLI (8 training examples per class)'],\n",
       "   'title': 'A large annotated corpus for learning natural language inference',\n",
       "   'url': 'https://paperswithcode.com/paper/a-large-annotated-corpus-for-learning-natural'},\n",
       "  'SciTail': {'full_name': '',\n",
       "   'variants': ['SciTail'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CHB-MIT': {'full_name': 'CHB-MIT Scalp EEG',\n",
       "   'variants': ['CHB-MIT'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  '2010 i2b2/VA': {'full_name': '2010 i2b2/VA',\n",
       "   'variants': ['2010 i2b2/VA'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'AFW': {'full_name': 'Annotated Faces in the Wild',\n",
       "   'variants': ['AFW', 'Annotated Faces in the Wild'],\n",
       "   'title': 'Face detection, pose estimation, and landmark localization in the wild',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2012.6248014'},\n",
       "  'TempEval-3': {'full_name': 'TempEval-3: events, times, and temporal relations',\n",
       "   'variants': ['TempEval-3'],\n",
       "   'title': 'TempEval-3: Evaluating Events, Time Expressions, and Temporal Relations',\n",
       "   'url': 'https://paperswithcode.com/paper/tempeval-3-evaluating-events-time-expressions'},\n",
       "  'TimeBank': {'full_name': '',\n",
       "   'variants': ['TimeBank'],\n",
       "   'title': 'Enriching TimeBank: Towards a more precise annotation of temporal relations in a text',\n",
       "   'url': 'https://paperswithcode.com/paper/enriching-timebank-towards-a-more-precise'},\n",
       "  'SemEval-2010 Task 8': {'full_name': '',\n",
       "   'variants': ['SemEval-2010 Task 8'],\n",
       "   'title': 'SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals',\n",
       "   'url': 'https://paperswithcode.com/paper/semeval-2010-task-8-multi-way-classification'},\n",
       "  'IEMOCAP': {'full_name': 'The Interactive Emotional Dyadic Motion Capture\\xa0(IEMOCAP) Database',\n",
       "   'variants': ['IEMOCAP'],\n",
       "   'title': 'IEMOCAP: interactive emotional dyadic motion capture database',\n",
       "   'url': 'https://doi.org/10.1007/s10579-008-9076-6'},\n",
       "  'Charades-STA': {'full_name': '',\n",
       "   'variants': ['Charades-STA'],\n",
       "   'title': 'TALL: Temporal Activity Localization via Language Query',\n",
       "   'url': 'https://paperswithcode.com/paper/tall-temporal-activity-localization-via'},\n",
       "  'SentEval': {'full_name': '',\n",
       "   'variants': ['SentEval'],\n",
       "   'title': 'SentEval: An Evaluation Toolkit for Universal Sentence Representations',\n",
       "   'url': 'https://paperswithcode.com/paper/senteval-an-evaluation-toolkit-for-universal'},\n",
       "  'JFLEG': {'full_name': 'JHU FLuency-Extended GUG corpus',\n",
       "   'variants': ['JFLEG', 'Restricted', 'Unrestricted', '_Restricted_'],\n",
       "   'title': 'JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction',\n",
       "   'url': 'https://paperswithcode.com/paper/jfleg-a-fluency-corpus-and-benchmark-for'},\n",
       "  'ESC-50': {'full_name': 'ESC-50',\n",
       "   'variants': ['ESC-50'],\n",
       "   'title': 'ESC: Dataset for Environmental Sound Classification',\n",
       "   'url': 'https://doi.org/10.1145/2733373.2806390'},\n",
       "  'Quora Question Pairs': {'full_name': '',\n",
       "   'variants': ['Quora Question Pairs'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MMI': {'full_name': 'MMI Facial Expression Database',\n",
       "   'variants': ['MMI'],\n",
       "   'title': 'Web-based database for facial expression analysis',\n",
       "   'url': 'https://doi.org/10.1109/ICME.2005.1521424'},\n",
       "  'JAFFE': {'full_name': 'Japanese Female Facial Expression',\n",
       "   'variants': ['JAFFE'],\n",
       "   'title': 'Coding Facial Expressions with Gabor Wavelets',\n",
       "   'url': 'http://www.kasrl.org/jaffe_download.html'},\n",
       "  'Oulu-CASIA': {'full_name': 'Oulu-CASIA NIR&VIS facial expression database',\n",
       "   'variants': ['Oulu-CASIA', 'CASIA NIR-VIS 2.0', 'Oulu-CASIA NIR-VIS'],\n",
       "   'title': 'Facial expression recognition from near-infrared videos',\n",
       "   'url': 'https://doi.org/10.1016/j.imavis.2011.07.002'},\n",
       "  'SFEW': {'full_name': 'Static Facial Expression in the Wild',\n",
       "   'variants': ['SFEW'],\n",
       "   'title': 'Static facial expression analysis in tough conditions: Data, evaluation protocol and benchmark',\n",
       "   'url': 'https://doi.org/10.1109/ICCVW.2011.6130508'},\n",
       "  'ATIS': {'full_name': 'Airline Travel Information Systems',\n",
       "   'variants': ['ATIS'],\n",
       "   'title': 'The ATIS Spoken Language Systems Pilot Corpus',\n",
       "   'url': 'https://www.aclweb.org/anthology/H90-1021/'},\n",
       "  'ActivityNet': {'full_name': '',\n",
       "   'variants': ['ActivityNet',\n",
       "    'ActivityNet-Entities',\n",
       "    'ActivityNet-1.3',\n",
       "    'ActivityNet-1.2'],\n",
       "   'title': 'ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/activitynet-a-large-scale-video-benchmark-for'},\n",
       "  'MSRA-TD500': {'full_name': 'MSRA Text Detection 500 Database',\n",
       "   'variants': ['MSRA-TD500'],\n",
       "   'title': 'Detecting texts of arbitrary orientations in natural images',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2012.6247787'},\n",
       "  'ICDAR 2015': {'full_name': '',\n",
       "   'variants': ['ICDAR 2015'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Total-Text': {'full_name': '',\n",
       "   'variants': ['Total-Text'],\n",
       "   'title': 'Total-Text: A Comprehensive Dataset for Scene Text Detection and Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/total-text-a-comprehensive-dataset-for-scene'},\n",
       "  'DOTA': {'full_name': 'Dataset for Object deTection in Aerial Images',\n",
       "   'variants': ['DOTA', 'DOTA 1.5', 'DOTA 1.0'],\n",
       "   'title': 'DOTA: A Large-scale Dataset for Object Detection in Aerial Images',\n",
       "   'url': 'https://paperswithcode.com/paper/dota-a-large-scale-dataset-for-object'},\n",
       "  'HRSC2016': {'full_name': 'High resolution ship collections 2016',\n",
       "   'variants': [],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ShanghaiTech': {'full_name': '',\n",
       "   'variants': ['ShanghaiTech', 'ShanghaiTech A', 'ShanghaiTech B'],\n",
       "   'title': 'Single-Image Crowd Counting via Multi-Column Convolutional Neural Network',\n",
       "   'url': 'https://paperswithcode.com/paper/single-image-crowd-counting-via-multi-column-1'},\n",
       "  'UCSD Ped2': {'full_name': 'UCSD Anomaly Detection Dataset',\n",
       "   'variants': ['UCSD Ped2', 'UCSD-MIT Human Motion'],\n",
       "   'title': 'Anomaly detection in crowded scenes',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2010.5539872'},\n",
       "  'DCASE 2017': {'full_name': 'DCASE 2017',\n",
       "   'variants': ['DCASE 2017'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'PANDORA': {'full_name': '',\n",
       "   'variants': ['PANDORA'],\n",
       "   'title': 'PANDORA Talks: Personality and Demographics on Reddit',\n",
       "   'url': 'https://paperswithcode.com/paper/pandora-talks-personality-and-demographics-on'},\n",
       "  'AVA': {'full_name': 'Atomic Visual Actions',\n",
       "   'variants': ['AVA v2.1', 'AVA-ActiveSpeaker', 'AVA-Speech', 'AVA v2.2'],\n",
       "   'title': 'AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions',\n",
       "   'url': 'https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally'},\n",
       "  'EPIC-KITCHENS-55': {'full_name': '',\n",
       "   'variants': ['EPIC-KITCHENS-55'],\n",
       "   'title': 'Scaling Egocentric Vision: The EPIC-KITCHENS Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/scaling-egocentric-vision-the-epic-kitchens'},\n",
       "  'Charades': {'full_name': '',\n",
       "   'variants': ['Charades'],\n",
       "   'title': 'Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/hollywood-in-homes-crowdsourcing-data'},\n",
       "  'OTB-2015': {'full_name': '',\n",
       "   'variants': ['OTB-2015'],\n",
       "   'title': 'Object Tracking Benchmark',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2014.2388226'},\n",
       "  'OTB-2013': {'full_name': '',\n",
       "   'variants': ['OTB-2013'],\n",
       "   'title': 'Online Object Tracking: A Benchmark',\n",
       "   'url': 'https://paperswithcode.com/paper/online-object-tracking-a-benchmark'},\n",
       "  'LaSOT': {'full_name': 'Large-scale Single Object Tracking',\n",
       "   'variants': ['LaSOT'],\n",
       "   'title': 'LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/lasot-a-high-quality-benchmark-for-large'},\n",
       "  'TrackingNet': {'full_name': '',\n",
       "   'variants': ['TrackingNet'],\n",
       "   'title': 'TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/trackingnet-a-large-scale-dataset-and'},\n",
       "  'VOT2018': {'full_name': 'VOT2018',\n",
       "   'variants': ['VOT2018', 'VOT-2018'],\n",
       "   'title': 'The Sixth Visual Object Tracking VOT2018 Challenge Results',\n",
       "   'url': 'https://doi.org/10.1007/978-3-030-11009-3_1'},\n",
       "  'VOT2017': {'full_name': 'Visual Object Tracking Challenge',\n",
       "   'variants': ['VOT2017/18', 'VOT2017'],\n",
       "   'title': 'The Visual Object Tracking VOT2017 Challenge Results',\n",
       "   'url': 'https://doi.org/10.1109/ICCVW.2017.230'},\n",
       "  'AG News': {'full_name': 'AG’s News Corpus',\n",
       "   'variants': ['AG News', 'AG News (200 Labels)', 'ag_news'],\n",
       "   'title': 'Character-level Convolutional Networks for Text Classification',\n",
       "   'url': 'https://paperswithcode.com/paper/character-level-convolutional-networks-for'},\n",
       "  'DBpedia': {'full_name': 'DBpedia',\n",
       "   'variants': ['DBpedia', 'DBpedia (BEIR)', 'dbpedia_14'],\n",
       "   'title': 'DBpedia: A Nucleus for a Web of Open Data',\n",
       "   'url': 'https://doi.org/10.1007/978-3-540-76298-0_52'},\n",
       "  'SST': {'full_name': 'Stanford Sentiment Treebank',\n",
       "   'variants': ['SST',\n",
       "    'SST-5 Fine-grained classification',\n",
       "    'SST-2 Binary classification',\n",
       "    'SST2'],\n",
       "   'title': 'Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank',\n",
       "   'url': 'https://paperswithcode.com/paper/recursive-deep-models-for-semantic'},\n",
       "  'SUBJ': {'full_name': 'Subjectivity dataset',\n",
       "   'variants': ['SUBJ'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'BDD100K': {'full_name': '',\n",
       "   'variants': ['BDD100K', 'BDD100K-APS'],\n",
       "   'title': 'BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/bdd100k-a-diverse-driving-video-database-with'},\n",
       "  'GTA5': {'full_name': 'Grand Theft Auto 5',\n",
       "   'variants': ['GTA5', 'GTAV-to-Cityscapes Labels', 'GTA5 to Cityscapes'],\n",
       "   'title': 'Playing for Data: Ground Truth from Computer Games',\n",
       "   'url': 'https://paperswithcode.com/paper/playing-for-data-ground-truth-from-computer'},\n",
       "  'MovieLens': {'full_name': 'MovieLens',\n",
       "   'variants': ['MovieLens 25M',\n",
       "    'MovieLens',\n",
       "    'MovieLens-Latest',\n",
       "    'MovieLens 20M',\n",
       "    'MovieLens 1M',\n",
       "    'MovieLens 10M',\n",
       "    'MovieLens 100K'],\n",
       "   'title': 'The MovieLens Datasets: History and Context',\n",
       "   'url': 'https://doi.org/10.1145/2827872'},\n",
       "  'Middlebury': {'full_name': 'Middlebury Stereo',\n",
       "   'variants': ['Middlebury',\n",
       "    'Middlebury - 2x upscaling',\n",
       "    'Middlebury - 4x upscaling'],\n",
       "   'title': 'A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms',\n",
       "   'url': 'https://doi.org/10.1023/A:1014573219977'},\n",
       "  'V-COCO': {'full_name': 'Verbs in COCO',\n",
       "   'variants': ['V-COCO'],\n",
       "   'title': 'Visual Semantic Role Labeling',\n",
       "   'url': 'https://paperswithcode.com/paper/visual-semantic-role-labeling'},\n",
       "  'HICO-DET': {'full_name': 'HICO-DET',\n",
       "   'variants': ['HICO-DET'],\n",
       "   'title': 'Learning to Detect Human-Object Interactions',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-to-detect-human-object-interactions'},\n",
       "  'UTD-MHAD': {'full_name': '',\n",
       "   'variants': ['UTD-MHAD'],\n",
       "   'title': 'UTD-MHAD: A multimodal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor',\n",
       "   'url': 'https://doi.org/10.1109/ICIP.2015.7350781'},\n",
       "  'MPII': {'full_name': 'MPII Human Pose',\n",
       "   'variants': ['MPII', 'MPII Multi-Person', 'MPII Single Person'],\n",
       "   'title': '2D Human Pose Estimation: New Benchmark and State of the Art Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/2d-human-pose-estimation-new-benchmark-and'},\n",
       "  'Kinetics': {'full_name': 'Kinetics Human Action Video Dataset',\n",
       "   'variants': ['AVA-Kinetics',\n",
       "    'Kinetics-400',\n",
       "    'Kinetics-600 48 frames, 64x64',\n",
       "    'Kinetics-600 12 frames, 64x64',\n",
       "    'Kinetics-600 12 frames, 128x128',\n",
       "    'Kinetics-700',\n",
       "    'Kinetics-600',\n",
       "    'Kinetics'],\n",
       "   'title': 'The Kinetics Human Action Video Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/the-kinetics-human-action-video-dataset'},\n",
       "  'MSRC-12': {'full_name': 'MSRC-12 Kinect Gesture Dataset',\n",
       "   'variants': ['MSRC-12'],\n",
       "   'title': 'Instructing people for training gestural interactive systems',\n",
       "   'url': 'https://doi.org/10.1145/2207676.2208303'},\n",
       "  'TIMIT': {'full_name': 'TIMIT Acoustic-Phonetic Continuous Speech Corpus',\n",
       "   'variants': ['TIMIT'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Volleyball': {'full_name': '',\n",
       "   'variants': ['Volleyball'],\n",
       "   'title': 'A Hierarchical Deep Temporal Model for Group Activity Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/a-hierarchical-deep-temporal-model-for-group'},\n",
       "  'Collective Activity': {'full_name': '',\n",
       "   'variants': ['Collective Activity'],\n",
       "   'title': 'Improved Actor Relation Graph based Group Activity Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/video-understanding-based-on-human-action-and'},\n",
       "  'MOT16': {'full_name': 'Multiple Object Tracking 2016',\n",
       "   'variants': ['MOT16'],\n",
       "   'title': 'MOT16: A Benchmark for Multi-Object Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/mot16-a-benchmark-for-multi-object-tracking'},\n",
       "  'NUS-WIDE': {'full_name': '',\n",
       "   'variants': ['NUS-WIDE'],\n",
       "   'title': 'NUS-WIDE: a real-world web image database from National University of Singapore',\n",
       "   'url': 'https://doi.org/10.1145/1646396.1646452'},\n",
       "  'PASCAL VOC 2007': {'full_name': 'PASCAL VOC 2007',\n",
       "   'variants': ['PASCAL VOC 2007', 'Pascal VOC 2007 count-test'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CelebA-HQ': {'full_name': 'CelebA-HQ',\n",
       "   'variants': ['CelebA-Test',\n",
       "    'CelebA-HQ 256x256',\n",
       "    'CelebA-HQ 1024x1024',\n",
       "    'Celeb-HQ 4x upscaling',\n",
       "    'CelebA-HQ 64x64',\n",
       "    'CelebA-HQ 128x128',\n",
       "    'CelebA-HQ'],\n",
       "   'title': 'Progressive Growing of GANs for Improved Quality, Stability, and Variation',\n",
       "   'url': 'https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved'},\n",
       "  'GTEA': {'full_name': 'Georgia Tech Egocentric Activity',\n",
       "   'variants': ['GTEA'],\n",
       "   'title': 'Learning to recognize objects in egocentric activities',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2011.5995444'},\n",
       "  '50 Salads': {'full_name': '',\n",
       "   'variants': ['50 Salads'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'DIV2K': {'full_name': '',\n",
       "   'variants': ['DIV2K',\n",
       "    'DIV2K val - 16x upscaling',\n",
       "    'DIV2K val - 2x upscaling',\n",
       "    'DIV2K val - 4x upscaling'],\n",
       "   'title': 'NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study',\n",
       "   'url': 'https://doi.org/10.1109/CVPRW.2017.150'},\n",
       "  'MAESTRO': {'full_name': 'MAESTRO',\n",
       "   'variants': ['MAESTRO'],\n",
       "   'title': 'Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/enabling-factorized-piano-music-modeling-and'},\n",
       "  'CASIA-B': {'full_name': 'CASIA-B',\n",
       "   'variants': ['CASIA-B'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'AFLW': {'full_name': 'Annotated Facial Landmarks in the Wild',\n",
       "   'variants': ['AFLW-PIFA (34 points)',\n",
       "    'AFLW-PIFA (21 points)',\n",
       "    'AFLW-MTFL',\n",
       "    'AFLW-LFPA',\n",
       "    'AFLW-Full',\n",
       "    'AFLW-Front',\n",
       "    'AFLW (Zhang CVPR 2018 crops)',\n",
       "    'AFLW'],\n",
       "   'title': 'Annotated Facial Landmarks in the Wild: A large-scale, real-world database for facial landmark localization',\n",
       "   'url': 'https://doi.org/10.1109/ICCVW.2011.6130513'},\n",
       "  'BIWI': {'full_name': '',\n",
       "   'variants': ['BIWI'],\n",
       "   'title': 'Real Time Head Pose Estimation from Consumer Depth Cameras',\n",
       "   'url': 'https://doi.org/10.1007/978-3-642-23123-0_11'},\n",
       "  'STB': {'full_name': 'Stereo Hand Pose Benchmark',\n",
       "   'variants': ['STB'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'YCB-Video': {'full_name': '',\n",
       "   'variants': ['YCB-Video'],\n",
       "   'title': 'PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes',\n",
       "   'url': 'https://paperswithcode.com/paper/posecnn-a-convolutional-neural-network-for-6d'},\n",
       "  'ApolloCar3D': {'full_name': '',\n",
       "   'variants': ['ApolloCar3D'],\n",
       "   'title': 'ApolloCar3D: A Large 3D Car Instance Understanding Benchmark for Autonomous Driving',\n",
       "   'url': 'https://paperswithcode.com/paper/apollocar3d-a-large-3d-car-instance'},\n",
       "  'Darmstadt Noise Dataset': {'full_name': 'zaid allal',\n",
       "   'variants': ['Darmstadt Noise Dataset'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Multi-Ego': {'full_name': '',\n",
       "   'variants': ['Multi-Ego'],\n",
       "   'title': 'Multi-Stream Dynamic Video Summarization',\n",
       "   'url': 'https://paperswithcode.com/paper/multi-view-egocentric-video-summarization'},\n",
       "  'SumMe': {'full_name': 'SumMe',\n",
       "   'variants': ['SumMe'],\n",
       "   'title': 'Creating Summaries from User Videos',\n",
       "   'url': 'https://paperswithcode.com/paper/creating-summaries-from-user-videos'},\n",
       "  'Reddit TIFU': {'full_name': '',\n",
       "   'variants': ['Reddit TIFU'],\n",
       "   'title': 'Abstractive Summarization of Reddit Posts with Multi-level Memory Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/abstractive-summarization-of-reddit-posts'},\n",
       "  'DAVIS 2016': {'full_name': 'DAVIS 2016',\n",
       "   'variants': ['DAVIS 2016', 'DAVIS-2016'],\n",
       "   'title': 'A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation'},\n",
       "  'FBMS-59': {'full_name': 'Freiburg-Berkeley Motion Segmentation',\n",
       "   'variants': ['FBMS-59'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CamVid': {'full_name': 'Cambridge-driving Labeled Video Database',\n",
       "   'variants': ['CamVid'],\n",
       "   'title': 'Semantic object classes in video: A high-definition ground truth database',\n",
       "   'url': 'https://doi.org/10.1016/j.patrec.2008.04.005'},\n",
       "  'DAVIS 2017': {'full_name': 'DAVIS 2017',\n",
       "   'variants': ['DAVIS 2017',\n",
       "    'DAVIS 2017 (test-dev)',\n",
       "    'DAVIS 2017 (val)',\n",
       "    'DAVIS-2017'],\n",
       "   'title': 'The 2017 DAVIS Challenge on Video Object Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/the-2017-davis-challenge-on-video-object'},\n",
       "  'CCGbank': {'full_name': '', 'variants': [], 'title': None, 'url': None},\n",
       "  'SVHN': {'full_name': 'Street View House Numbers',\n",
       "   'variants': ['svhn,1000',\n",
       "    'SVHN, 4000 Labels',\n",
       "    'SVHN, 2000 Labels',\n",
       "    'SVHN-to-MNIST',\n",
       "    'SVHN, 500 Labels',\n",
       "    'SVHN, 40 Labels',\n",
       "    'SVHN, 250 Labels',\n",
       "    'SVHN, 1000 labels',\n",
       "    'SVHN'],\n",
       "   'title': 'Reading digits in natural images with unsupervised feature learning',\n",
       "   'url': 'http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf'},\n",
       "  'STL-10': {'full_name': 'Self-Taught Learning 10',\n",
       "   'variants': ['STL-10', 'STL-10, 1000 Labels', 'STL-10, 5000 Labels'],\n",
       "   'title': 'An Analysis of Single-Layer Networks in Unsupervised Feature Learning',\n",
       "   'url': 'http://proceedings.mlr.press/v15/coates11a/coates11a.pdf'},\n",
       "  'CIFAR-10': {'full_name': '',\n",
       "   'variants': ['cifar10',\n",
       "    'CIFAR10_CATS',\n",
       "    'Unlabeled CIFAR-10 vs CIFAR-100',\n",
       "    'CIFAR-10 (with noisy labels)',\n",
       "    'noise padded CIFAR-10',\n",
       "    'cifar10, 10 labels',\n",
       "    'cifar-10,4000',\n",
       "    'CIFAR10 100k',\n",
       "    'CIFAR-100 vs CIFAR-10',\n",
       "    'CIFAR-100 WRN-28-10 - 200 Epochs',\n",
       "    'CIFAR-10 model detecting CIFAR-10',\n",
       "    'CIFAR-10 image generation',\n",
       "    'CIFAR-10 WRN-28-10 - 200 Epochs',\n",
       "    'CIFAR-10-LT (ρ=100)',\n",
       "    'CIFAR-10-LT (ρ=10)',\n",
       "    'CIFAR-10, 80 Labels',\n",
       "    'CIFAR-10, 500 Labels',\n",
       "    'CIFAR-10, 20 Labels',\n",
       "    'CIFAR-10 vs CIFAR-100',\n",
       "    'CIFAR-10 ResNet-18 - 200 Epochs',\n",
       "    'CIFAR-10 (Conditional)',\n",
       "    'cifar10, 250 Labels',\n",
       "    'One-class CIFAR-10',\n",
       "    'CIFAR-10, 4000 Labels',\n",
       "    'CIFAR-10, 40 Labels',\n",
       "    'CIFAR-10, 250 Labels',\n",
       "    'CIFAR-10, 2000 Labels',\n",
       "    'CIFAR-10, 1000 Labels',\n",
       "    'CIFAR-10 Image Classification',\n",
       "    'CIFAR-10'],\n",
       "   'title': 'Learning multiple layers of features from tiny images',\n",
       "   'url': 'https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf'},\n",
       "  'Clothing1M': {'full_name': '',\n",
       "   'variants': ['Clothing1M', 'Clothing1M (using clean data)'],\n",
       "   'title': 'Learning From Massive Noisy Labeled Data for Image Classification',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-from-massive-noisy-labeled-data-for'},\n",
       "  'CIFAR-100': {'full_name': '',\n",
       "   'variants': ['cifar100',\n",
       "    'Unlabeled CIFAR-10 vs CIFAR-100',\n",
       "    'CIFAR-100 ResNet-18 - 200 Epochs',\n",
       "    'CIFAR-10, 2000 Labeled Samples',\n",
       "    'cifar-100, 10000 Labels',\n",
       "    'One-class CIFAR-100',\n",
       "    'Cifar100 (20 tasks)',\n",
       "    'CIFAR100 5-way (1-shot)',\n",
       "    'CIFAR-100-LT (ρ=100)',\n",
       "    'CIFAR-100-LT (ρ=10)',\n",
       "    'CIFAR-100, 5000Labels',\n",
       "    'CIFAR-100, 400 Labels',\n",
       "    'CIFAR-100, 2500 Labels',\n",
       "    'CIFAR-100, 1000 Labels',\n",
       "    'CIFAR-100 - 50 classes + 50 steps of 1 class',\n",
       "    'CIFAR-100 - 50 classes + 5 steps of 10 classes',\n",
       "    'CIFAR-100 - 50 classes + 25 steps of 2 classes',\n",
       "    'CIFAR-100 - 50 classes + 10 steps of 5 classes',\n",
       "    'CIFAR-100'],\n",
       "   'title': 'Learning multiple layers of features from tiny images',\n",
       "   'url': 'https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf'},\n",
       "  'ADE20K': {'full_name': '',\n",
       "   'variants': ['ADE20K',\n",
       "    'ADE20K Labels-to-Photos',\n",
       "    'ADE20K-Outdoor Labels-to-Photos',\n",
       "    'ADE20K val'],\n",
       "   'title': 'Scene Parsing Through ADE20K Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/scene-parsing-through-ade20k-dataset'},\n",
       "  'MPII Human Pose': {'full_name': 'MPII Human Pose',\n",
       "   'variants': ['MPII Human Pose', 'MPII Single Person'],\n",
       "   'title': '2D Human Pose Estimation: New Benchmark and State of the Art Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/2d-human-pose-estimation-new-benchmark-and'},\n",
       "  'Human3.6M': {'full_name': '',\n",
       "   'variants': ['Human3.6M'],\n",
       "   'title': 'Human3.6m: Large scale datasets and predictive methods for 3D human sensing in natural environments',\n",
       "   'url': 'https://paperswithcode.com/paper/human36m-large-scale-datasets-and-predictive'},\n",
       "  'CIHP': {'full_name': 'Crowd Instance-level Human Parsing',\n",
       "   'variants': ['CIHP'],\n",
       "   'title': 'Instance-level Human Parsing via Part Grouping Network',\n",
       "   'url': 'https://paperswithcode.com/paper/instance-level-human-parsing-via-part'},\n",
       "  'MultiMNIST': {'full_name': '',\n",
       "   'variants': ['MultiMNIST'],\n",
       "   'title': 'Dynamic Routing Between Capsules',\n",
       "   'url': 'https://paperswithcode.com/paper/dynamic-routing-between-capsules'},\n",
       "  'iNaturalist': {'full_name': '',\n",
       "   'variants': ['iNaturalist',\n",
       "    'iNaturalist (227-way multi-shot)',\n",
       "    'iNaturalist 2018'],\n",
       "   'title': 'The iNaturalist Species Classification and Detection Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/the-inaturalist-species-classification-and'},\n",
       "  'ScanNet': {'full_name': '',\n",
       "   'variants': ['ScanNet', 'ScanNetV1', 'ScanNetV2', 'ScanNet(v2)'],\n",
       "   'title': 'ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes',\n",
       "   'url': 'https://paperswithcode.com/paper/scannet-richly-annotated-3d-reconstructions'},\n",
       "  'SBD': {'full_name': 'Semantic Boundaries Dataset',\n",
       "   'variants': ['SBD', 'Sbd val'],\n",
       "   'title': 'Semantic contours from inverse detectors',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2011.6126343'},\n",
       "  'SK-LARGE': {'full_name': 'SK-LARGE',\n",
       "   'variants': ['SK-LARGE'],\n",
       "   'title': 'DeepSkeleton: Learning Multi-task Scale-associated Deep Side Outputs for Object Skeleton Extraction in Natural Images',\n",
       "   'url': 'https://paperswithcode.com/paper/deepskeleton-learning-multi-task-scale'},\n",
       "  'Indian Pines': {'full_name': '',\n",
       "   'variants': ['Indian Pines'],\n",
       "   'title': '220 band AVIRIS hyperspectral image data set',\n",
       "   'url': 'https://purr.purdue.edu/publications/1947/1'},\n",
       "  'Pavia University': {'full_name': 'Pavia University',\n",
       "   'variants': ['Pavia University'],\n",
       "   'title': 'Pavia centre and university',\n",
       "   'url': 'http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes#Pavia_Centre_and_University'},\n",
       "  'RVL-CDIP': {'full_name': 'RVL-CDIP',\n",
       "   'variants': ['RVL-CDIP'],\n",
       "   'title': 'Evaluation of Deep Convolutional Nets for Document Image Classification and Retrieval',\n",
       "   'url': 'https://paperswithcode.com/paper/evaluation-of-deep-convolutional-nets-for'},\n",
       "  'COCO Captions': {'full_name': '',\n",
       "   'variants': ['COCO Captions',\n",
       "    'COCO Captions test',\n",
       "    'MSCOCO-1k',\n",
       "    'COCO Captions Karpathy Test'],\n",
       "   'title': 'Microsoft COCO Captions: Data Collection and Evaluation Server',\n",
       "   'url': 'https://paperswithcode.com/paper/microsoft-coco-captions-data-collection-and'},\n",
       "  'RotoWire': {'full_name': 'RotoWire',\n",
       "   'variants': ['RotoWire (Relation Generation)',\n",
       "    'Rotowire (Content Selection)',\n",
       "    'RotoWire (Content Ordering)',\n",
       "    'RotoWire'],\n",
       "   'title': 'Challenges in Data-to-Document Generation',\n",
       "   'url': 'https://paperswithcode.com/paper/challenges-in-data-to-document-generation'},\n",
       "  'WikiBio': {'full_name': 'Kishor Salvi',\n",
       "   'variants': ['WikiBio'],\n",
       "   'title': 'Neural Text Generation from Structured Data with Application to the Biography Domain',\n",
       "   'url': 'https://paperswithcode.com/paper/neural-text-generation-from-structured-data'},\n",
       "  'DailyDialog': {'full_name': '',\n",
       "   'variants': ['DailyDialog'],\n",
       "   'title': 'DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/dailydialog-a-manually-labelled-multi-turn'},\n",
       "  'WebNLG': {'full_name': '',\n",
       "   'variants': ['WebNLG 2.0 (Unconstrained)',\n",
       "    'WebNLG 2.0 (Constrained)',\n",
       "    'WebNLG (Unseen)',\n",
       "    'WebNLG (Seen)',\n",
       "    'WebNLG (All)',\n",
       "    'WebNLG (Constrained)',\n",
       "    'WebNLG(C)',\n",
       "    'WebNLG(U)',\n",
       "    'WebNLG en',\n",
       "    'WebNLG v2.1',\n",
       "    'WebNLG Full',\n",
       "    'WebNLG'],\n",
       "   'title': 'Creating Training Corpora for NLG Micro-Planners',\n",
       "   'url': 'https://paperswithcode.com/paper/creating-training-corpora-for-nlg-micro'},\n",
       "  'MegaFace': {'full_name': '',\n",
       "   'variants': ['MegaFace'],\n",
       "   'title': 'The MegaFace Benchmark: 1 Million Faces for Recognition at Scale',\n",
       "   'url': 'https://paperswithcode.com/paper/the-megaface-benchmark-1-million-faces-for'},\n",
       "  'IJB-B': {'full_name': 'IARPA Janus Benchmark-B',\n",
       "   'variants': ['IJB-B'],\n",
       "   'title': 'IARPA Janus Benchmark-B Face Dataset',\n",
       "   'url': 'https://doi.org/10.1109/CVPRW.2017.87'},\n",
       "  'IJB-A': {'full_name': 'IARPA Janus Benchmark A',\n",
       "   'variants': ['IJB-A'],\n",
       "   'title': 'Pushing the Frontiers of Unconstrained Face Detection and Recognition: IARPA Janus Benchmark A',\n",
       "   'url': 'https://paperswithcode.com/paper/pushing-the-frontiers-of-unconstrained-face'},\n",
       "  '300W': {'full_name': '300 Faces-In-The-Wild',\n",
       "   'variants': ['300W', '300W (Full)'],\n",
       "   'title': '300 Faces in-the-Wild Challenge: The First Facial Landmark Localization Challenge',\n",
       "   'url': 'https://doi.org/10.1109/ICCVW.2013.59'},\n",
       "  'FG-NET': {'full_name': '',\n",
       "   'variants': ['FG-NET', 'FGNET'],\n",
       "   'title': 'Toward Automatic Simulation of Aging Effects on Face Images',\n",
       "   'url': 'https://doi.org/10.1109/34.993553'},\n",
       "  'IJB-C': {'full_name': 'IARPA Janus Benchmark-C',\n",
       "   'variants': ['IJB-C'],\n",
       "   'title': 'IARPA Janus Benchmark - C: Face Dataset and Protocol',\n",
       "   'url': 'https://doi.org/10.1109/ICB2018.2018.00033'},\n",
       "  'PASCAL Face': {'full_name': 'PASCAL Face',\n",
       "   'variants': ['PASCAL Face'],\n",
       "   'title': 'Face detection by structural models',\n",
       "   'url': 'https://doi.org/10.1016/j.imavis.2013.12.004'},\n",
       "  'AFLW2000-3D': {'full_name': '',\n",
       "   'variants': ['AFLW2000', 'AFLW2000-3D'],\n",
       "   'title': 'Face Alignment Across Large Poses: A 3D Solution',\n",
       "   'url': 'https://paperswithcode.com/paper/face-alignment-across-large-poses-a-3d'},\n",
       "  'Florence': {'full_name': 'Florence 3D Faces',\n",
       "   'variants': ['Florence'],\n",
       "   'title': 'The florence 2D/3D hybrid face dataset',\n",
       "   'url': 'https://doi.org/10.1145/2072572.2072597'},\n",
       "  'MORPH': {'full_name': '',\n",
       "   'variants': ['MORPH', 'MORPH Album2'],\n",
       "   'title': 'MORPH: A Longitudinal Image Database of Normal Adult Age-Progression',\n",
       "   'url': 'https://doi.org/10.1109/FGR.2006.78'},\n",
       "  'CUFS': {'full_name': 'CUHK Face Sketch Database',\n",
       "   'variants': ['CUFS'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CUFSF': {'full_name': 'CUHK Face Sketch FERET Database',\n",
       "   'variants': ['CUFSF'],\n",
       "   'title': 'Coupled information-theoretic encoding for face photo-sketch recognition',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2011.5995324'},\n",
       "  'Caltech-101': {'full_name': '',\n",
       "   'variants': ['Caltech-101', 'Caltech-101, 202 Labels'],\n",
       "   'title': 'Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2004.383'},\n",
       "  'Oxford-IIIT Pets': {'full_name': '',\n",
       "   'variants': ['Oxford-IIIT Pets'],\n",
       "   'title': 'Cats and dogs',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2012.6248092'},\n",
       "  'Stanford Cars': {'full_name': '',\n",
       "   'variants': ['Stanford Cars',\n",
       "    'Stanford Cars 5-way (1-shot)',\n",
       "    'Stanford Cars 5-way (5-shot)',\n",
       "    'Stanford Cars (Fine-grained 6 Tasks)'],\n",
       "   'title': '3D Object Representations for Fine-Grained Categorization',\n",
       "   'url': 'https://doi.org/10.1109/ICCVW.2013.77'},\n",
       "  'NABirds': {'full_name': 'North America Birds',\n",
       "   'variants': ['NABirds'],\n",
       "   'title': 'Building a Bird Recognition App and Large Scale Dataset With Citizen Scientists: The Fine Print in Fine-Grained Dataset Collection',\n",
       "   'url': 'https://paperswithcode.com/paper/building-a-bird-recognition-app-and-large'},\n",
       "  'Stanford Dogs': {'full_name': 'Stanford Dogs',\n",
       "   'variants': ['Stanford Dogs',\n",
       "    'Stanford Dogs 5-way (1-shot)',\n",
       "    'Stanford Dogs 5-way (5-shot)'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'FFHQ': {'full_name': 'Flickr-Faces-HQ',\n",
       "   'variants': ['FFHQ-U',\n",
       "    'FFHQ 512 x 512 - 4x upscaling',\n",
       "    'FFHQ 512 x 512 - 16x upscaling',\n",
       "    'FFHQ 256 x 256 - 4x upscaling',\n",
       "    'FFHQ 256 x 256',\n",
       "    'FFHQ 1024 x 1024 - 4x upscaling',\n",
       "    'FFHQ 1024 x 1024',\n",
       "    'FFHQ'],\n",
       "   'title': 'A Style-Based Generator Architecture for Generative Adversarial Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for'},\n",
       "  'RaFD': {'full_name': 'Radboud Faces Database',\n",
       "   'variants': ['RaFD'],\n",
       "   'title': 'Presentation and validation of the radboud faces database',\n",
       "   'url': 'https://doi.org/10.1080/02699930903485076'},\n",
       "  'WikiQA': {'full_name': 'Wikipedia open-domain Question Answering',\n",
       "   'variants': ['WikiQA'],\n",
       "   'title': 'WikiQA: A Challenge Dataset for Open-Domain Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/wikiqa-a-challenge-dataset-for-open-domain'},\n",
       "  'WebQuestions': {'full_name': '',\n",
       "   'variants': ['WebQuestions'],\n",
       "   'title': 'Semantic Parsing on Freebase from Question-Answer Pairs',\n",
       "   'url': 'https://paperswithcode.com/paper/semantic-parsing-on-freebase-from-question'},\n",
       "  'SimpleQuestions': {'full_name': '',\n",
       "   'variants': ['SimpleQuestions'],\n",
       "   'title': 'Large-scale Simple Question Answering with Memory Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/large-scale-simple-question-answering-with'},\n",
       "  'TrecQA': {'full_name': 'Text Retrieval Conference Question Answering',\n",
       "   'variants': ['TrecQA'],\n",
       "   'title': 'What is the Jeopardy Model? A Quasi-Synchronous Grammar for QA',\n",
       "   'url': 'https://www.aclweb.org/anthology/D07-1003/'},\n",
       "  'WikiHop': {'full_name': '',\n",
       "   'variants': ['WikiHop'],\n",
       "   'title': 'Constructing Datasets for Multi-hop Reading Comprehension Across Documents',\n",
       "   'url': 'https://paperswithcode.com/paper/constructing-datasets-for-multi-hop-reading'},\n",
       "  'TuSimple': {'full_name': '',\n",
       "   'variants': ['TuSimple'],\n",
       "   'title': 'TuSimple benchmark',\n",
       "   'url': 'https://github.com/TuSimple/tusimple-benchmark'},\n",
       "  'GTSRB': {'full_name': 'German Traffic Sign Recognition Benchmark',\n",
       "   'variants': ['GTSRB', 'Synth Signs-to-GTSRB', 'SYNSIG-to-GTSRB'],\n",
       "   'title': 'computer: Benchmarking machine learning algorithms for traffic sign recognition',\n",
       "   'url': 'http://www.sciencedirect.com/science/article/pii/S0893608012000457'},\n",
       "  'Tsinghua-Tencent 100K': {'full_name': 'Traffic-Sign Detection and Classification in the Wild',\n",
       "   'variants': ['Tsinghua-Tencent 100K'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'PA-100K': {'full_name': 'PA-100K Dataset',\n",
       "   'variants': ['PA-100K'],\n",
       "   'title': 'HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/hydraplus-net-attentive-deep-features-for'},\n",
       "  'PETA': {'full_name': 'Pedestrian Attribute',\n",
       "   'variants': ['PETA'],\n",
       "   'title': 'Pedestrian Attribute Recognition At Far Distance',\n",
       "   'url': 'https://doi.org/10.1145/2647868.2654966'},\n",
       "  'RAP': {'full_name': 'Richly Annotated Pedestrian',\n",
       "   'variants': ['RAP'],\n",
       "   'title': 'A Richly Annotated Dataset for Pedestrian Attribute Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/a-richly-annotated-dataset-for-pedestrian'},\n",
       "  'PhC-U373': {'full_name': '',\n",
       "   'variants': ['PhC-U373'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'DRIVE': {'full_name': 'Digital Retinal Images for Vessel Extraction',\n",
       "   'variants': ['DRIVE'],\n",
       "   'title': 'Ridge-based vessel segmentation in color images of the retina',\n",
       "   'url': 'https://doi.org/10.1109/TMI.2004.825627'},\n",
       "  'STARE': {'full_name': 'Structured Analysis of the Retina',\n",
       "   'variants': ['STARE'],\n",
       "   'title': 'Locating blood vessels in retinal images by piecewise threshold probing of a matched filter response',\n",
       "   'url': 'http://cecas.clemson.edu/~ahoover/stare/'},\n",
       "  'CHASE_DB1': {'full_name': 'CHASE_DB1',\n",
       "   'variants': ['CHASE_DB1'],\n",
       "   'title': 'An Ensemble Classification-Based Approach Applied to Retinal Blood Vessel Segmentation',\n",
       "   'url': 'https://doi.org/10.1109/TBME.2012.2205687'},\n",
       "  'LUNA': {'full_name': '',\n",
       "   'variants': ['LUNA', 'LUNA2016 FPRED', 'LUNA16'],\n",
       "   'title': 'Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the LUNA16 challenge',\n",
       "   'url': 'https://paperswithcode.com/paper/validation-comparison-and-combination-of'},\n",
       "  'Tox21': {'full_name': 'Tox21 Machine Learning Data Set',\n",
       "   'variants': ['Tox21', 'Tox21 '],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'QM9': {'full_name': 'Quantum Machines 9',\n",
       "   'variants': ['QM9'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Douban': {'full_name': 'Douban Conversation Corpus',\n",
       "   'variants': ['Douban', 'Douban Monti'],\n",
       "   'title': 'Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots',\n",
       "   'url': 'https://paperswithcode.com/paper/sequential-matching-network-a-new'},\n",
       "  'Criteo': {'full_name': 'Display Advertising Challenge',\n",
       "   'variants': ['Criteo'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'iPinYou': {'full_name': 'iPinYou Global RTB Bidding Algorithm Competition Dataset',\n",
       "   'variants': ['iPinYou'],\n",
       "   'title': 'iPinYou Global RTB Bidding Algorithm Competition Dataset',\n",
       "   'url': 'https://doi.org/10.1145/2648584.2648590'},\n",
       "  'PASCAL-Part': {'full_name': 'PASCAL-Part',\n",
       "   'variants': ['PASCAL-Part', 'PASCAL Part 2010 - Animals'],\n",
       "   'title': 'Detect What You Can: Detecting and Representing Objects using Holistic Models and Body Parts',\n",
       "   'url': 'https://paperswithcode.com/paper/detect-what-you-can-detecting-and'},\n",
       "  'Citeseer': {'full_name': '',\n",
       "   'variants': ['Citeseer (weighted evaluation)',\n",
       "    'Citeseer random partition',\n",
       "    'Citeseer Full-supervised',\n",
       "    'Citeseer (nonstandard variant)',\n",
       "    'Citeseer (biased evaluation)',\n",
       "    'Citeseer',\n",
       "    'CiteSeer with Public Split: fixed 5 nodes per class',\n",
       "    'CiteSeer with Public Split: fixed 20 nodes per class',\n",
       "    'CiteSeer (1%)',\n",
       "    'CiteSeer (0.5%)'],\n",
       "   'title': 'CiteSeer: An Automatic Citation Indexing System',\n",
       "   'url': 'https://doi.org/10.1145/276675.276685'},\n",
       "  'Cora': {'full_name': '',\n",
       "   'variants': ['Cora (weighted evaluation)',\n",
       "    'Cora: fixed 5 node per class',\n",
       "    'Cora: fixed 20 node per class',\n",
       "    'Cora: fixed 10 node per class',\n",
       "    'Cora random partition',\n",
       "    'Cora Full-supervised',\n",
       "    'Cora (nonstandard variant)',\n",
       "    'Cora (biased evaluation)',\n",
       "    'Cora with Public Split: fixed 20 nodes per class',\n",
       "    'Cora (3%)',\n",
       "    'Cora (1%)',\n",
       "    'Cora (0.5%)',\n",
       "    'Cora'],\n",
       "   'title': 'Automating the Construction of Internet Portals with Machine Learning',\n",
       "   'url': 'https://doi.org/10.1023/A:1009953814988'},\n",
       "  'Pubmed': {'full_name': '',\n",
       "   'variants': ['Pubmed (weighted evaluation)',\n",
       "    'Pubmed random partition',\n",
       "    'Pubmed (nonstandard variant)',\n",
       "    'Pubmed (biased evaluation)',\n",
       "    'PubMed 20k RCT',\n",
       "    'Pubmed Full-supervised',\n",
       "    'Pubmed',\n",
       "    'PubMed with Public Split: fixed 20 nodes per class',\n",
       "    'PubMed (0.1%)',\n",
       "    'PubMed (0.05%)',\n",
       "    'PubMed (0.03%)'],\n",
       "   'title': 'Collective Classification in Network Data',\n",
       "   'url': 'http://www.aaai.org/ojs/index.php/aimagazine/article/view/2157'},\n",
       "  'NELL': {'full_name': 'Never Ending Language Learning',\n",
       "   'variants': ['NELL'],\n",
       "   'title': 'Toward an Architecture for Never-Ending Language Learning',\n",
       "   'url': 'http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/view/1879'},\n",
       "  'WN18': {'full_name': 'WordNet18',\n",
       "   'variants': ['WN18', 'WN18RR', 'WN18 (filtered)'],\n",
       "   'title': 'Translating Embeddings for Modeling Multi-relational Data',\n",
       "   'url': 'https://paperswithcode.com/paper/translating-embeddings-for-modeling-multi'},\n",
       "  'Scan2CAD': {'full_name': '',\n",
       "   'variants': ['Scan2CAD'],\n",
       "   'title': 'Scan2CAD: Learning CAD Model Alignment in RGB-D Scans',\n",
       "   'url': 'https://paperswithcode.com/paper/scan2cad-learning-cad-model-alignment-in-rgb'},\n",
       "  'UTKFace': {'full_name': '',\n",
       "   'variants': ['UTKFace'],\n",
       "   'title': 'Age Progression/Regression by Conditional Adversarial Autoencoder',\n",
       "   'url': 'https://paperswithcode.com/paper/age-progressionregression-by-conditional'},\n",
       "  'AFAD': {'full_name': 'Asian Face Age Dataset',\n",
       "   'variants': [],\n",
       "   'title': 'Ordinal Regression With Multiple Output CNN for Age Estimation',\n",
       "   'url': 'https://paperswithcode.com/paper/ordinal-regression-with-multiple-output-cnn'},\n",
       "  'CACD': {'full_name': 'Cross-Age Celebrity Dataset',\n",
       "   'variants': ['CACD'],\n",
       "   'title': 'Cross-Age Reference Coding for Age-Invariant Face Recognition and Retrieval',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-10599-4_49'},\n",
       "  'JIGSAWS': {'full_name': 'JHU-ISI Gesture and Skill Assessment Working Set',\n",
       "   'variants': ['JIGSAWS'],\n",
       "   'title': 'Jhu-isi gesture and skill assessment working set (jigsaws): A surgical activity dataset for human motion modeling',\n",
       "   'url': 'https://cirl.lcsr.jhu.edu/wp-content/uploads/2015/11/JIGSAWS.pdf'},\n",
       "  'CompCars': {'full_name': 'Comprehensive Cars',\n",
       "   'variants': ['CompCars'],\n",
       "   'title': 'A Large-Scale Car Dataset for Fine-Grained Categorization and Verification',\n",
       "   'url': 'https://paperswithcode.com/paper/a-large-scale-car-dataset-for-fine-grained'},\n",
       "  'METR-LA': {'full_name': '', 'variants': [], 'title': None, 'url': None},\n",
       "  'RT-GENE': {'full_name': '',\n",
       "   'variants': ['RT-GENE'],\n",
       "   'title': 'RT-GENE: Real-Time Eye Gaze Estimation in Natural Environments',\n",
       "   'url': 'https://paperswithcode.com/paper/rt-gene-real-time-eye-gaze-estimation-in'},\n",
       "  'WN18RR': {'full_name': '',\n",
       "   'variants': ['WN18RR'],\n",
       "   'title': 'Translating Embeddings for Modeling Multi-relational Data',\n",
       "   'url': 'https://paperswithcode.com/paper/translating-embeddings-for-modeling-multi'},\n",
       "  'FB15k-237': {'full_name': '',\n",
       "   'variants': ['FB15k-237'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'T-LESS': {'full_name': '',\n",
       "   'variants': ['T-LESS'],\n",
       "   'title': 'T-LESS: An RGB-D Dataset for 6D Pose Estimation of Texture-less Objects',\n",
       "   'url': 'https://paperswithcode.com/paper/t-less-an-rgb-d-dataset-for-6d-pose'},\n",
       "  'ACE 2004': {'full_name': 'ACE 2004 Multilingual Training Corpus',\n",
       "   'variants': ['ACE 2004', 'ACE2004'],\n",
       "   'title': 'Ace 2004 multilingual training corpus',\n",
       "   'url': 'https://catalog.ldc.upenn.edu/LDC2005T09'},\n",
       "  'ACE 2005': {'full_name': 'ACE 2005 Multilingual Training Corpus',\n",
       "   'variants': ['ACE 2005', 'ACE2005'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'GENIA': {'full_name': '',\n",
       "   'variants': ['GENIA', 'GENIA - LAS', 'GENIA - UAS', 'GENIA 2013'],\n",
       "   'title': 'GENIA corpus - a semantically annotated corpus for bio-textmining',\n",
       "   'url': 'http://bioinformatics.oupjournals.org/cgi/content/abstract/19/suppl_1/i180?etoc'},\n",
       "  'SemEval 2014 Task 4 Sub Task 2': {'full_name': '',\n",
       "   'variants': ['SemEval 2014 Task 4 Sub Task 2'],\n",
       "   'title': 'SemEval-2014 Task 4: Aspect Based Sentiment Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/semeval-2014-task-4-aspect-based-sentiment'},\n",
       "  'Ohsumed': {'full_name': '',\n",
       "   'variants': ['Ohsumed'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MR': {'full_name': 'MR Movie Reviews',\n",
       "   'variants': ['MR', 'rotten_tomatoes'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'STS Benchmark': {'full_name': '',\n",
       "   'variants': ['STS Benchmark'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Weibo NER': {'full_name': 'Weibo NER',\n",
       "   'variants': ['Weibo NER'],\n",
       "   'title': 'Named Entity Recognition for Chinese Social Media with Jointly Trained Embeddings',\n",
       "   'url': 'https://paperswithcode.com/paper/named-entity-recognition-for-chinese-social'},\n",
       "  'Resume NER': {'full_name': 'Resume NER',\n",
       "   'variants': ['Resume NER'],\n",
       "   'title': 'Chinese NER Using Lattice LSTM',\n",
       "   'url': 'https://paperswithcode.com/paper/chinese-ner-using-lattice-lstm'},\n",
       "  'Reuters-21578': {'full_name': '',\n",
       "   'variants': ['Reuters-21578'],\n",
       "   'title': 'Reuters-21578',\n",
       "   'url': 'http://www.daviddlewis.com/resources/testcollections/reuters21578'},\n",
       "  'FCE': {'full_name': 'First Certificate in English',\n",
       "   'variants': ['FCE'],\n",
       "   'title': 'A New Dataset and Method for Automatically Grading ESOL Texts',\n",
       "   'url': 'https://www.aclweb.org/anthology/P11-1019/'},\n",
       "  'TACRED': {'full_name': 'The TAC Relation Extraction Dataset',\n",
       "   'variants': ['TACRED'],\n",
       "   'title': 'Position-aware Attention and Supervised Data Improve Slot Filling',\n",
       "   'url': 'https://paperswithcode.com/paper/position-aware-attention-and-supervised-data'},\n",
       "  'Natural Questions': {'full_name': '',\n",
       "   'variants': ['Natural Questions',\n",
       "    'Natural Questions (long)',\n",
       "    'Natural Questions (short)',\n",
       "    'NQ',\n",
       "    'NQ (BEIR)'],\n",
       "   'title': 'Natural Questions: a Benchmark for Question Answering Research',\n",
       "   'url': 'https://paperswithcode.com/paper/natural-questions-a-benchmark-for-question'},\n",
       "  'MUTAG': {'full_name': '',\n",
       "   'variants': ['MUTAG'],\n",
       "   'title': 'Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds',\n",
       "   'url': 'http://pubs.acs.org/doi/abs/10.1021/jm00106a046'},\n",
       "  'NCI1': {'full_name': '',\n",
       "   'variants': ['NCI1', 'NCI-123'],\n",
       "   'title': 'Comparison of descriptor spaces for chemical compound retrieval and classification',\n",
       "   'url': 'https://doi.org/10.1109/ICDM.2006.39'},\n",
       "  'PROTEINS': {'full_name': '',\n",
       "   'variants': ['PROTEINS'],\n",
       "   'title': 'Protein function prediction via graph kernels',\n",
       "   'url': 'https://doi.org/10.1093/bioinformatics/bti1007'},\n",
       "  'ENZYMES': {'full_name': '',\n",
       "   'variants': ['ENZYMES'],\n",
       "   'title': 'Protein function prediction via graph kernels',\n",
       "   'url': 'https://doi.org/10.1093/bioinformatics/bti1007'},\n",
       "  'COLLAB': {'full_name': '',\n",
       "   'variants': ['COLLAB'],\n",
       "   'title': 'Deep Graph Kernels',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-graph-kernels'},\n",
       "  'BC5CDR': {'full_name': 'BioCreative V CDR corpus',\n",
       "   'variants': ['BC5CDR', 'BC5CDR-disease', 'BC5CDR-chemical'],\n",
       "   'title': 'BioCreative V CDR task corpus: a resource for chemical disease relation extraction',\n",
       "   'url': 'https://doi.org/10.1093/database/baw068'},\n",
       "  'JNLPBA': {'full_name': 'JNLPBA',\n",
       "   'variants': ['JNLPBA'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ChemProt': {'full_name': '',\n",
       "   'variants': ['ChemProt'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SciERC': {'full_name': '',\n",
       "   'variants': ['SciERC'],\n",
       "   'title': 'Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction',\n",
       "   'url': 'https://paperswithcode.com/paper/multi-task-identification-of-entities'},\n",
       "  'Paper Field': {'full_name': 'Paper Field',\n",
       "   'variants': ['Paper Field'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'PASCAL Context': {'full_name': '',\n",
       "   'variants': ['PASCAL Context'],\n",
       "   'title': 'The Role of Context for Object Detection and Semantic Segmentation in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/the-role-of-context-for-object-detection-and'},\n",
       "  'SCUT-CTW1500': {'full_name': '',\n",
       "   'variants': ['SCUT-CTW1500'],\n",
       "   'title': 'Detecting Curve Text in the Wild: New Dataset and New Solution',\n",
       "   'url': 'https://paperswithcode.com/paper/detecting-curve-text-in-the-wild-new-dataset'},\n",
       "  'OCHuman': {'full_name': None,\n",
       "   'variants': ['OCHuman'],\n",
       "   'title': 'Pose2Seg: Detection Free Human Instance Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/pose2seg-detection-free-human-instance'},\n",
       "  'YAGO3-10': {'full_name': 'Yet Another Great Ontology 3-10',\n",
       "   'variants': ['YAGO3-10'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MSU-MFSD': {'full_name': '',\n",
       "   'variants': ['MSU-MFSD'],\n",
       "   'title': 'Face Spoof Detection With Image Distortion Analysis',\n",
       "   'url': 'https://doi.org/10.1109/TIFS.2015.2400395'},\n",
       "  'SciCite': {'full_name': 'SciCite',\n",
       "   'variants': ['ScienceCite', 'SciCite'],\n",
       "   'title': 'Structural Scaffolds for Citation Intent Classification in Scientific Publications',\n",
       "   'url': 'https://paperswithcode.com/paper/structural-scaffolds-for-citation-intent'},\n",
       "  'PanoContext': {'full_name': 'PanoContext',\n",
       "   'variants': ['PanoContext'],\n",
       "   'title': 'PanoContext: A Whole-Room 3D Context Model for Panoramic Scene Understanding',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-10599-4_43'},\n",
       "  'Office-31': {'full_name': 'Office Dataset',\n",
       "   'variants': ['Office-31', ''],\n",
       "   'title': 'Adapting Visual Category Models to New Domains',\n",
       "   'url': 'https://doi.org/10.1007/978-3-642-15561-1_16'},\n",
       "  'ImageCLEF-DA': {'full_name': 'ImageCLEF-DA',\n",
       "   'variants': ['ImageCLEF-DA'],\n",
       "   'title': 'Deep Transfer Learning with Joint Adaptation Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-transfer-learning-with-joint-adaptation'},\n",
       "  'Office-Home': {'full_name': '',\n",
       "   'variants': ['Office-Home', 'Office-Home (RS-UT imbalance)'],\n",
       "   'title': 'Deep Hashing Network for Unsupervised Domain Adaptation',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-hashing-network-for-unsupervised-domain'},\n",
       "  'HPatches': {'full_name': 'Homography-patches dataset',\n",
       "   'variants': ['HPatches'],\n",
       "   'title': 'HPatches: A benchmark and evaluation of handcrafted and learned local descriptors',\n",
       "   'url': 'https://paperswithcode.com/paper/hpatches-a-benchmark-and-evaluation-of'},\n",
       "  'CityPersons': {'full_name': '',\n",
       "   'variants': ['CityPersons'],\n",
       "   'title': 'CityPersons: A Diverse Dataset for Pedestrian Detection',\n",
       "   'url': 'https://paperswithcode.com/paper/citypersons-a-diverse-dataset-for-pedestrian'},\n",
       "  'CREMI': {'full_name': '',\n",
       "   'variants': ['CREMI'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ContactDB': {'full_name': '',\n",
       "   'variants': ['ContactDB'],\n",
       "   'title': 'ContactDB: Analyzing and Predicting Grasp Contact via Thermal Imaging',\n",
       "   'url': 'https://paperswithcode.com/paper/contactdb-analyzing-and-predicting-grasp'},\n",
       "  'Polyvore': {'full_name': 'Polyvore Outfits',\n",
       "   'variants': ['Polyvore'],\n",
       "   'title': 'Learning Fashion Compatibility with Bidirectional LSTMs',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-fashion-compatibility-with'},\n",
       "  'Watercolor2k': {'full_name': '',\n",
       "   'variants': ['Watercolor2k'],\n",
       "   'title': 'Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation',\n",
       "   'url': 'https://paperswithcode.com/paper/cross-domain-weakly-supervised-object'},\n",
       "  'Comic2k': {'full_name': None,\n",
       "   'variants': ['Comic2k'],\n",
       "   'title': 'Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation',\n",
       "   'url': 'https://paperswithcode.com/paper/cross-domain-weakly-supervised-object'},\n",
       "  'Clipart1k': {'full_name': '',\n",
       "   'variants': [],\n",
       "   'title': 'Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation',\n",
       "   'url': 'https://paperswithcode.com/paper/cross-domain-weakly-supervised-object'},\n",
       "  'PeopleArt': {'full_name': 'PeopleArt',\n",
       "   'variants': ['PeopleArt'],\n",
       "   'title': 'Detecting People in Artwork with CNNs',\n",
       "   'url': 'https://paperswithcode.com/paper/detecting-people-in-artwork-with-cnns'},\n",
       "  'IconArt': {'full_name': '',\n",
       "   'variants': ['IconArt'],\n",
       "   'title': 'Weakly Supervised Object Detection in Artworks',\n",
       "   'url': 'https://paperswithcode.com/paper/weakly-supervised-object-detection-in'},\n",
       "  'COFW': {'full_name': 'Caltech Occluded Faces in the Wild',\n",
       "   'variants': ['COFW'],\n",
       "   'title': 'Robust Face Landmark Estimation under Occlusion',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2013.191'},\n",
       "  'RWTH-PHOENIX-Weather 2014': {'full_name': '',\n",
       "   'variants': ['RWTH-PHOENIX-Weather 2014'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'VRD': {'full_name': 'Visual Relationship Detection dataset',\n",
       "   'variants': ['VRD',\n",
       "    'VRD Predicate Detection',\n",
       "    'VRD Phrase Detection',\n",
       "    'VRD Relationship Detection'],\n",
       "   'title': 'Visual Relationship Detection with Language Priors',\n",
       "   'url': 'https://paperswithcode.com/paper/visual-relationship-detection-with-language'},\n",
       "  'PPI': {'full_name': 'Protein-Protein Interactions (PPI)',\n",
       "   'variants': ['PPI'],\n",
       "   'title': 'Inductive Representation Learning on Large Graphs',\n",
       "   'url': 'https://paperswithcode.com/paper/inductive-representation-learning-on-large'},\n",
       "  'Kuzushiji-MNIST': {'full_name': '',\n",
       "   'variants': ['Kuzushiji-MNIST'],\n",
       "   'title': 'Deep Learning for Classical Japanese Literature',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-learning-for-classical-japanese'},\n",
       "  'Slashdot': {'full_name': '',\n",
       "   'variants': ['Slashdot'],\n",
       "   'title': 'Signed Networks in Social Media',\n",
       "   'url': 'https://dl.acm.org/doi/10.1145/1753326.1753532'},\n",
       "  'Epinions': {'full_name': None,\n",
       "   'variants': ['Epinions'],\n",
       "   'title': 'Trust Management for the Semantic Web',\n",
       "   'url': 'https://doi.org/10.1007/978-3-540-39718-2_23'},\n",
       "  'VOT2016': {'full_name': 'VOT2016',\n",
       "   'variants': ['VOT-2016', 'VOT2016'],\n",
       "   'title': 'The Visual Object Tracking VOT2016 Challenge Results',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-48881-3_54'},\n",
       "  'CULane': {'full_name': '',\n",
       "   'variants': ['CULane'],\n",
       "   'title': 'Spatial As Deep: Spatial CNN for Traffic Scene Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/spatial-as-deep-spatial-cnn-for-traffic-scene'},\n",
       "  'Udacity': {'full_name': None,\n",
       "   'variants': ['Udacity'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SUN360': {'full_name': 'Scene UNderstanding 360° panorama',\n",
       "   'variants': ['SUN360'],\n",
       "   'title': 'Recognizing scene viewpoint using panoramic place representation',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2012.6247991'},\n",
       "  'ACL Title and Abstract Dataset': {'full_name': '',\n",
       "   'variants': ['ACL Title and Abstract Dataset'],\n",
       "   'title': 'Paper Abstract Writing through Editing Mechanism',\n",
       "   'url': 'https://paperswithcode.com/paper/paper-abstract-writing-through-editing'},\n",
       "  'Wikipedia Person and Animal Dataset': {'full_name': '',\n",
       "   'variants': ['Wikipedia Person and Animal Dataset'],\n",
       "   'title': 'Describing a Knowledge Base',\n",
       "   'url': 'https://paperswithcode.com/paper/describing-a-knowledge-base'},\n",
       "  'VizWiz': {'full_name': 'VizWiz-VQA',\n",
       "   'variants': ['VizWiz 2020 test-dev',\n",
       "    'VizWiz 2020 test',\n",
       "    'VizWiz 2020 VQA',\n",
       "    'VizWiz 2020 Answerability',\n",
       "    'VizWiz 2018 Answerability',\n",
       "    'VizWiz 2018',\n",
       "    'VizWiz'],\n",
       "   'title': 'VizWiz Grand Challenge: Answering Visual Questions from Blind People',\n",
       "   'url': 'https://paperswithcode.com/paper/vizwiz-grand-challenge-answering-visual'},\n",
       "  'KT3DMoSeg': {'full_name': '',\n",
       "   'variants': ['KT3DMoSeg'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Hopkins155': {'full_name': '',\n",
       "   'variants': ['Hopkins155'],\n",
       "   'title': 'A Benchmark for the Comparison of 3-D Motion Segmentation Algorithms',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2007.382974'},\n",
       "  'S3DIS': {'full_name': 'Stanford 3D Indoor Scene Dataset (S3DIS)',\n",
       "   'variants': ['S3DIS', 'S3DIS Area5'],\n",
       "   'title': '3D Semantic Parsing of Large-Scale Indoor Spaces',\n",
       "   'url': 'https://paperswithcode.com/paper/3d-semantic-parsing-of-large-scale-indoor'},\n",
       "  'VoxCeleb1': {'full_name': 'VoxCeleb1',\n",
       "   'variants': ['VoxCeleb',\n",
       "    'VoxCeleb1',\n",
       "    'VoxCeleb1 - 1-shot learning',\n",
       "    'VoxCeleb1 - 8-shot learning',\n",
       "    'VoxCeleb1 - 32-shot learning'],\n",
       "   'title': 'VoxCeleb: a large-scale speaker identification dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/voxceleb-a-large-scale-speaker-identification'},\n",
       "  'OQMD v1.2': {'full_name': 'The Open Quantum Materials Database',\n",
       "   'variants': ['OQMD v1.2'],\n",
       "   'title': 'Crystal Graph Neural Networks for Data Mining in Materials Science',\n",
       "   'url': 'https://paperswithcode.com/paper/crystal-graph-neural-networks-for-data-mining'},\n",
       "  'Moments in Time': {'full_name': '',\n",
       "   'variants': ['Moments in Time', 'Moments in Time Dataset'],\n",
       "   'title': 'Moments in Time Dataset: one million videos for event understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/moments-in-time-dataset-one-million-videos'},\n",
       "  'VQA-CP': {'full_name': None,\n",
       "   'variants': ['VQA-CP'],\n",
       "   'title': \"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\n",
       "   'url': 'https://paperswithcode.com/paper/dont-just-assume-look-and-answer-overcoming'},\n",
       "  'LJSpeech': {'full_name': 'The LJ Speech Dataset',\n",
       "   'variants': ['LJSpeech'],\n",
       "   'title': 'The lj speech dataset',\n",
       "   'url': 'https://keithito.com/LJ-Speech-Dataset/'},\n",
       "  'QNLI': {'full_name': 'Question-answering NLI',\n",
       "   'variants': ['QNLI', 'QNLI (8 training examples per class)'],\n",
       "   'title': 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/glue-a-multi-task-benchmark-and-analysis'},\n",
       "  'RTE': {'full_name': 'Recognizing Textual Entailment',\n",
       "   'variants': ['RTE'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MRPC': {'full_name': 'Microsoft Research Paraphrase Corpus',\n",
       "   'variants': ['MRPC', 'MRPC Dev'],\n",
       "   'title': 'Automatically Constructing a Corpus of Sentential Paraphrases',\n",
       "   'url': 'https://www.aclweb.org/anthology/I05-5002/'},\n",
       "  'CODAH': {'full_name': 'COmmonsense Dataset Adversarially-authored by Humans',\n",
       "   'variants': ['CODAH'],\n",
       "   'title': 'CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense',\n",
       "   'url': 'https://paperswithcode.com/paper/codah-an-adversarially-authored-question'},\n",
       "  'CrowdPose': {'full_name': 'CrowdPose',\n",
       "   'variants': ['CrowdPose'],\n",
       "   'title': 'CrowdPose: Efficient Crowded Scenes Pose Estimation and A New Benchmark',\n",
       "   'url': 'https://paperswithcode.com/paper/crowdpose-efficient-crowded-scenes-pose'},\n",
       "  'LDC2017T10': {'full_name': 'Abstract Meaning Representation (AMR) Annotation Release 2.0',\n",
       "   'variants': ['LDC2017T10'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MemexQA': {'full_name': '',\n",
       "   'variants': ['MemexQA'],\n",
       "   'title': 'MemexQA: Visual Memex Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/memexqa-visual-memex-question-answering'},\n",
       "  'ECSSD': {'full_name': 'Extended Complex Scene Saliency Dataset',\n",
       "   'variants': ['ECSSD'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'HKU-IS': {'full_name': '',\n",
       "   'variants': ['HKU-IS'],\n",
       "   'title': 'Visual Saliency Based on Multiscale Deep Features',\n",
       "   'url': 'https://paperswithcode.com/paper/visual-saliency-based-on-multiscale-deep'},\n",
       "  'PASCAL-S': {'full_name': '',\n",
       "   'variants': ['PASCAL-S'],\n",
       "   'title': 'The Secrets of Salient Object Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/the-secrets-of-salient-object-segmentation'},\n",
       "  'DUT-OMRON': {'full_name': '',\n",
       "   'variants': ['DUT-OMRON'],\n",
       "   'title': 'Saliency Detection via Graph-Based Manifold Ranking',\n",
       "   'url': 'https://paperswithcode.com/paper/saliency-detection-via-graph-based-manifold'},\n",
       "  'MSMT17': {'full_name': '',\n",
       "   'variants': ['MSMT17',\n",
       "    'Market-1501->MSMT17',\n",
       "    'DukeMTMC-reID->MSMT17',\n",
       "    'MSMT17->Market-1501'],\n",
       "   'title': 'Person Transfer GAN to Bridge Domain Gap for Person Re-Identification',\n",
       "   'url': 'https://paperswithcode.com/paper/person-transfer-gan-to-bridge-domain-gap-for'},\n",
       "  'USPS': {'full_name': 'USPS',\n",
       "   'variants': ['USPS', 'MNIST-to-USPS', 'USPS-to-MNIST'],\n",
       "   'title': 'A Database for Handwritten Text Recognition Research',\n",
       "   'url': 'https://doi.org/10.1109/34.291440'},\n",
       "  'SIXray': {'full_name': None,\n",
       "   'variants': ['SIXray'],\n",
       "   'title': 'SIXray : A Large-scale Security Inspection X-ray Benchmark for Prohibited Item Discovery in Overlapping Images',\n",
       "   'url': 'https://paperswithcode.com/paper/sixray-a-large-scale-security-inspection-x'},\n",
       "  'Django': {'full_name': 'Django',\n",
       "   'variants': ['Django'],\n",
       "   'title': 'Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation (T)',\n",
       "   'url': 'https://doi.org/10.1109/ASE.2015.36'},\n",
       "  'PACS': {'full_name': 'Photo-Art-Cartoon-Sketch',\n",
       "   'variants': ['PACS', 'PACS-StaQC-py', 'PACS-SO-DS', 'PACS-CoNaLa'],\n",
       "   'title': 'Deeper, Broader and Artier Domain Generalization',\n",
       "   'url': 'https://paperswithcode.com/paper/deeper-broader-and-artier-domain'},\n",
       "  'BioGRID': {'full_name': 'Biological General Repository for Interaction Datasets',\n",
       "   'variants': ['BioGRID', 'BioGRID(yeast)', 'BioGRID (human)'],\n",
       "   'title': 'BioGRID: a general repository for interaction datasets',\n",
       "   'url': 'https://doi.org/10.1093/nar/gkj109'},\n",
       "  'Freiburg Forest': {'full_name': 'Freiburg Forest',\n",
       "   'variants': ['Freiburg Forest', 'Freiburg Forest Dataset'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SNIPS': {'full_name': 'SNIPS Natural Language Understanding benchmark',\n",
       "   'variants': ['SNIPS'],\n",
       "   'title': 'Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces',\n",
       "   'url': 'https://paperswithcode.com/paper/snips-voice-platform-an-embedded-spoken'},\n",
       "  'Nottingham': {'full_name': 'Nottingham',\n",
       "   'variants': ['Nottingham'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SOD': {'full_name': 'small obstacle detection',\n",
       "   'variants': ['SOD'],\n",
       "   'title': 'LiDAR guided Small obstacle Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/lidar-guided-small-obstacle-segmentation'},\n",
       "  'Cluttered Omniglot': {'full_name': '',\n",
       "   'variants': ['Cluttered Omniglot'],\n",
       "   'title': 'One-Shot Segmentation in Clutter',\n",
       "   'url': 'https://paperswithcode.com/paper/one-shot-segmentation-in-clutter'},\n",
       "  'PKU-MMD': {'full_name': 'PKU-MMD',\n",
       "   'variants': ['PKU-MMD'],\n",
       "   'title': 'PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/pku-mmd-a-large-scale-benchmark-for'},\n",
       "  'NTU RGB+D': {'full_name': '',\n",
       "   'variants': ['NTU RGB+D', 'NTU RGB+D 120', 'Filtered NTU RGB+D'],\n",
       "   'title': 'NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/ntu-rgbd-a-large-scale-dataset-for-3d-human'},\n",
       "  'Birdsnap': {'full_name': '',\n",
       "   'variants': ['Birdsnap'],\n",
       "   'title': 'Birdsnap: Large-scale Fine-grained Visual Categorization of Birds',\n",
       "   'url': 'https://paperswithcode.com/paper/birdsnap-large-scale-fine-grained-visual'},\n",
       "  'CoLA': {'full_name': 'Corpus of Linguistic Acceptability',\n",
       "   'variants': ['CoLA', 'CoLA Dev'],\n",
       "   'title': 'Neural Network Acceptability Judgments',\n",
       "   'url': 'https://paperswithcode.com/paper/neural-network-acceptability-judgments'},\n",
       "  'ASTD': {'full_name': 'Arabic Sentiment Tweets Dataset',\n",
       "   'variants': ['ASTD'],\n",
       "   'title': 'ASTD: Arabic Sentiment Tweets Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/astd-arabic-sentiment-tweets-dataset'},\n",
       "  'LSMDC': {'full_name': 'Large Scale Movie Description Challenge',\n",
       "   'variants': ['LSMDC'],\n",
       "   'title': 'A Dataset for Movie Description',\n",
       "   'url': 'https://paperswithcode.com/paper/a-dataset-for-movie-description'},\n",
       "  'MSR-VTT': {'full_name': '',\n",
       "   'variants': ['MSR-VTT', 'MSRVTT-QA', 'MSR-VTT-1kA'],\n",
       "   'title': 'MSR-VTT: A Large Video Description Dataset for Bridging Video and Language',\n",
       "   'url': 'https://paperswithcode.com/paper/msr-vtt-a-large-video-description-dataset-for'},\n",
       "  'MSVD': {'full_name': 'Microsoft Research Video Description Corpus',\n",
       "   'variants': ['MSVD', 'MSVD-QA'],\n",
       "   'title': 'Collecting Highly Parallel Data for Paraphrase Evaluation',\n",
       "   'url': 'https://www.aclweb.org/anthology/P11-1020/'},\n",
       "  'DiDeMo': {'full_name': 'Distinct Describable Moments',\n",
       "   'variants': ['DiDeMo'],\n",
       "   'title': 'Localizing Moments in Video with Natural Language',\n",
       "   'url': 'https://paperswithcode.com/paper/localizing-moments-in-video-with-natural'},\n",
       "  'MuPoTS-3D': {'full_name': 'Multiperson Pose Test Set in 3DMulti-person Pose estimation Test Set in 3D',\n",
       "   'variants': ['MuPoTS-3D'],\n",
       "   'title': 'Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB',\n",
       "   'url': 'https://paperswithcode.com/paper/single-shot-multi-person-3d-pose-estimation'},\n",
       "  'Helsinki Prosody Corpus': {'full_name': '',\n",
       "   'variants': ['Helsinki Prosody Corpus'],\n",
       "   'title': 'Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations',\n",
       "   'url': 'https://paperswithcode.com/paper/predicting-prosodic-prominence-from-text-with'},\n",
       "  'WMCA': {'full_name': 'Wide Multi Channel Presentation Attack',\n",
       "   'variants': ['WMCA'],\n",
       "   'title': 'Biometric Face Presentation Attack Detection with Multi-Channel Convolutional Neural Network',\n",
       "   'url': 'https://paperswithcode.com/paper/biometric-face-presentation-attack-detection-1'},\n",
       "  'AQUAINT': {'full_name': None,\n",
       "   'variants': ['AQUAINT'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MAFL': {'full_name': 'Multi-Attribute Facial Landmark',\n",
       "   'variants': ['MAFL'],\n",
       "   'title': 'Facial Landmark Detection by Deep Multi-task Learning',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-10599-4_7'},\n",
       "  'Species-800': {'full_name': 'Species-800',\n",
       "   'variants': ['Species-800'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'LINNAEUS': {'full_name': '',\n",
       "   'variants': ['LINNAEUS'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'NLVR': {'full_name': 'Natural Language Visual Reasoningnatural language for visual reasoning',\n",
       "   'variants': ['NLVR', 'NLVR2 Dev', 'NLVR2 Test'],\n",
       "   'title': 'A Corpus of Natural Language for Visual Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/a-corpus-of-natural-language-for-visual'},\n",
       "  'ChestX-ray14': {'full_name': 'ChestX-ray14',\n",
       "   'variants': ['ChestX-ray14', 'ChestXray14 1024x1024'],\n",
       "   'title': 'ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases',\n",
       "   'url': 'https://paperswithcode.com/paper/chestx-ray8-hospital-scale-chest-x-ray'},\n",
       "  'HICO': {'full_name': 'Humans Interacting with Common Objects',\n",
       "   'variants': ['HICO'],\n",
       "   'title': 'HICO: A Benchmark for Recognizing Human-Object Interactions in Images',\n",
       "   'url': 'https://paperswithcode.com/paper/hico-a-benchmark-for-recognizing-human-object'},\n",
       "  'Adverse Drug Events (ADE) Corpus': {'full_name': '',\n",
       "   'variants': ['Adverse Drug Events (ADE) Corpus'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Sports-1M': {'full_name': '',\n",
       "   'variants': ['Sports-1M'],\n",
       "   'title': 'Large-Scale Video Classification with Convolutional Neural Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/large-scale-video-classification-with-1'},\n",
       "  'YouTube-8M': {'full_name': '',\n",
       "   'variants': ['YouTube-8M'],\n",
       "   'title': 'YouTube-8M: A Large-Scale Video Classification Benchmark',\n",
       "   'url': 'https://paperswithcode.com/paper/youtube-8m-a-large-scale-video-classification'},\n",
       "  'Something-Something V2': {'full_name': '20BN-Something-Something\\xa0Dataset V2',\n",
       "   'variants': ['Something-Something V2'],\n",
       "   'title': 'The \"something something\" video database for learning and evaluating visual common sense',\n",
       "   'url': 'https://paperswithcode.com/paper/the-something-something-video-database-for'},\n",
       "  'Jester': {'full_name': 'Jester dataset',\n",
       "   'variants': ['Jester', 'Jester val', 'Jester test'],\n",
       "   'title': 'Eigentaste: A Constant Time Collaborative Filtering Algorithm',\n",
       "   'url': 'https://doi.org/10.1023/A:1011419012209'},\n",
       "  'Something-Something V1': {'full_name': '20BN-Something-Something\\xa0Dataset V1',\n",
       "   'variants': ['Something-Something V1'],\n",
       "   'title': 'The \"something something\" video database for learning and evaluating visual common sense',\n",
       "   'url': 'https://paperswithcode.com/paper/the-something-something-video-database-for'},\n",
       "  'HVU': {'full_name': 'Holistic Video Understanding',\n",
       "   'variants': ['HVU'],\n",
       "   'title': 'Large Scale Holistic Video Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/holistic-large-scale-video-understanding'},\n",
       "  'PTC': {'full_name': 'Predictive Toxicology Challenge',\n",
       "   'variants': ['PTC'],\n",
       "   'title': 'The predictive toxicology challenge',\n",
       "   'url': 'http://www.predictive-toxicology.org/ptc/Citedby:xxref-S2SS1p3'},\n",
       "  'UT-Kinect': {'full_name': 'UTKinect-Action3D Dataset',\n",
       "   'variants': ['UT-Kinect'],\n",
       "   'title': 'View invariant human action recognition using histograms of 3D joints',\n",
       "   'url': 'https://paperswithcode.com/paper/view-invariant-human-action-recognition-using'},\n",
       "  'IPC-grounded': {'full_name': '',\n",
       "   'variants': ['IPC-grounded'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CAD-120': {'full_name': '',\n",
       "   'variants': ['CAD-120'],\n",
       "   'title': 'Learning Human Activities and Object Affordances from RGB-D Videos',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-human-activities-and-object'},\n",
       "  'NTU RGB+D 120': {'full_name': '',\n",
       "   'variants': ['NTU RGB+D 120'],\n",
       "   'title': 'NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/ntu-rgbd-120-a-large-scale-benchmark-for-3d'},\n",
       "  'N-UCLA': {'full_name': 'Northwestern-UCLA Multiview Action 3D Dataset',\n",
       "   'variants': ['N-UCLA'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CK+': {'full_name': 'Extended Cohn-Kanade dataset',\n",
       "   'variants': ['CK+'],\n",
       "   'title': 'The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression',\n",
       "   'url': 'https://doi.org/10.1109/CVPRW.2010.5543262'},\n",
       "  'Acted Facial Expressions In The Wild (AFEW)': {'full_name': '',\n",
       "   'variants': ['Acted Facial Expressions In The Wild (AFEW)'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'YouTube-VOS 2018 val': {'full_name': 'Youtube Video Object Segmentation',\n",
       "   'variants': ['YouTube-VOS 2018 val'],\n",
       "   'title': 'YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark',\n",
       "   'url': 'https://arxiv.org/pdf/1809.03327.pdf'},\n",
       "  'TabFact': {'full_name': 'TabFact',\n",
       "   'variants': ['TabFact'],\n",
       "   'title': 'TabFact: A Large-scale Dataset for Table-based Fact Verification',\n",
       "   'url': 'https://paperswithcode.com/paper/tabfact-a-large-scale-dataset-for-table-based'},\n",
       "  'MPI-INF-3DHP': {'full_name': '',\n",
       "   'variants': ['MPI-INF-3DHP'],\n",
       "   'title': 'Monocular 3D Human Pose Estimation In The Wild Using Improved CNN Supervision',\n",
       "   'url': 'https://paperswithcode.com/paper/monocular-3d-human-pose-estimation-in-the'},\n",
       "  'Beijing Multi-Site Air-Quality Dataset': {'full_name': '',\n",
       "   'variants': ['Beijing Multi-Site Air-Quality Dataset'],\n",
       "   'title': 'Cautionary Tales on Air-Quality Improvement in Beijing',\n",
       "   'url': 'https://paperswithcode.com/paper/cautionary-tales-on-air-quality-improvement'},\n",
       "  'PhysioNet Challenge 2012': {'full_name': 'PhysioNet Challenge 2012',\n",
       "   'variants': ['PhysioNet Challenge 2012'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MuJoCo': {'full_name': '',\n",
       "   'variants': ['MuJoCo'],\n",
       "   'title': 'MuJoCo: A physics engine for model-based control',\n",
       "   'url': 'https://paperswithcode.com/paper/mujoco-a-physics-engine-for-model-based'},\n",
       "  'SunYs': {'full_name': 'Lungvesselct',\n",
       "   'variants': ['SunYs'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'WFLW': {'full_name': 'Wider Facial Landmarks in the Wild',\n",
       "   'variants': ['WFLW'],\n",
       "   'title': 'Look at Boundary: A Boundary-Aware Face Alignment Algorithm',\n",
       "   'url': 'https://paperswithcode.com/paper/look-at-boundary-a-boundary-aware-face'},\n",
       "  'REDS': {'full_name': 'REalistic and Diverse Scenes dataset\\nrealistic and dynamic scenes',\n",
       "   'variants': ['REDS'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'nuScenes': {'full_name': '',\n",
       "   'variants': ['nuScenes', 'nuScenes-F', 'nuScenes-FB'],\n",
       "   'title': 'nuScenes: A multimodal dataset for autonomous driving',\n",
       "   'url': 'https://paperswithcode.com/paper/nuscenes-a-multimodal-dataset-for-autonomous'},\n",
       "  'Sleep-EDF': {'full_name': 'Sleep-EDF Expanded',\n",
       "   'variants': ['Sleep-EDF-SC', 'Sleep-EDF-ST', 'Sleep-EDF'],\n",
       "   'title': 'Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physiologic signals',\n",
       "   'url': 'http://circ.ahajournals.org/content/101/23/e215.full'},\n",
       "  'CommonsenseQA': {'full_name': '',\n",
       "   'variants': ['CommonsenseQA'],\n",
       "   'title': 'CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge',\n",
       "   'url': 'https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge'},\n",
       "  '3DPW': {'full_name': '',\n",
       "   'variants': ['3DPW'],\n",
       "   'title': 'Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera',\n",
       "   'url': 'https://paperswithcode.com/paper/recovering-accurate-3d-human-pose-in-the-wild'},\n",
       "  'VOT2019': {'full_name': None,\n",
       "   'variants': ['VOT2019'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MUSDB18': {'full_name': '',\n",
       "   'variants': ['MUSDB18'],\n",
       "   'title': 'The MUSDB18 corpus for music separation',\n",
       "   'url': 'https://doi.org/10.5281/zenodo.1117372'},\n",
       "  'BoolQ': {'full_name': 'Boolean Questions',\n",
       "   'variants': ['BoolQ'],\n",
       "   'title': 'BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions',\n",
       "   'url': 'https://paperswithcode.com/paper/boolq-exploring-the-surprising-difficulty-of'},\n",
       "  'COPA': {'full_name': 'Choice of Plausible Alternatives',\n",
       "   'variants': ['COPA'],\n",
       "   'title': 'Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning',\n",
       "   'url': 'http://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418'},\n",
       "  'ReCoRD': {'full_name': 'ReCoRD',\n",
       "   'variants': ['ReCoRD'],\n",
       "   'title': 'ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension',\n",
       "   'url': 'https://paperswithcode.com/paper/record-bridging-the-gap-between-human-and'},\n",
       "  'LIDC-IDRI': {'full_name': 'LIDC-IDRI',\n",
       "   'variants': ['LIDC-IDRI'],\n",
       "   'title': 'The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on CT scans',\n",
       "   'url': 'http://dx.doi.org/10.1118/1.3528204'},\n",
       "  'ORL': {'full_name': 'Our Database of Faces',\n",
       "   'variants': ['ORL'],\n",
       "   'title': 'Parameterisation of a stochastic model for human face identification',\n",
       "   'url': 'https://doi.org/10.1109/ACV.1994.341300'},\n",
       "  'EgoGesture': {'full_name': '',\n",
       "   'variants': ['EgoGesture'],\n",
       "   'title': 'EgoGesture: A New Dataset and Benchmark for Egocentric Hand Gesture Recognition',\n",
       "   'url': 'https://doi.org/10.1109/TMM.2018.2808769'},\n",
       "  'Street Scene': {'full_name': None,\n",
       "   'variants': ['Street Scene'],\n",
       "   'title': 'Street Scene: A new dataset and evaluation protocol for video anomaly detection',\n",
       "   'url': 'https://paperswithcode.com/paper/street-scene-a-new-dataset-and-evaluation'},\n",
       "  'PH2': {'full_name': '', 'variants': ['PH2'], 'title': None, 'url': None},\n",
       "  'FSNS - Test': {'full_name': '',\n",
       "   'variants': ['FSNS - Test'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Materials Project': {'full_name': '',\n",
       "   'variants': ['Materials Project'],\n",
       "   'title': 'The Materials Project: A materials genome approach to accelerating materials innovation',\n",
       "   'url': 'http://link.aip.org/link/AMPADS/v1/i1/p011002/s1&Agg=doi'},\n",
       "  'Semantic3D': {'full_name': '',\n",
       "   'variants': ['Semantic3D'],\n",
       "   'title': 'Semantic3D.net: A new Large-scale Point Cloud Classification Benchmark',\n",
       "   'url': 'https://paperswithcode.com/paper/semantic3dnet-a-new-large-scale-point-cloud'},\n",
       "  'SemanticKITTI': {'full_name': '',\n",
       "   'variants': ['SemanticKITTI'],\n",
       "   'title': 'SemanticKITTI: A Dataset for Semantic Scene Understanding of LiDAR Sequences',\n",
       "   'url': 'https://paperswithcode.com/paper/a-dataset-for-semantic-segmentation-of-point'},\n",
       "  'Wine': {'full_name': 'Wine Data Set',\n",
       "   'variants': ['Wine'],\n",
       "   'title': 'Endgame Analysis of Dou Shou Qi',\n",
       "   'url': 'https://paperswithcode.com/paper/endgame-analysis-of-dou-shou-qi'},\n",
       "  'JSB Chorales': {'full_name': '',\n",
       "   'variants': ['JSB Chorales'],\n",
       "   'title': 'Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription',\n",
       "   'url': 'https://paperswithcode.com/paper/modeling-temporal-dependencies-in-high'},\n",
       "  'Tiny ImageNet': {'full_name': 'Tiny ImageNet',\n",
       "   'variants': ['Tiny ImageNet',\n",
       "    'Tiny ImageNet Classification',\n",
       "    'Tiny-ImageNet'],\n",
       "   'title': 'Tiny imagenet visual recognition challenge',\n",
       "   'url': 'https://tiny-imagenet.herokuapp.com'},\n",
       "  'AFHQ': {'full_name': 'Animal Faces-HQ',\n",
       "   'variants': ['AFHQ', 'AFHQV2', 'AFHQ Dog', 'AFHQ Cat', 'AFHQ Wild'],\n",
       "   'title': 'StarGAN v2: Diverse Image Synthesis for Multiple Domains',\n",
       "   'url': 'https://paperswithcode.com/paper/stargan-v2-diverse-image-synthesis-for'},\n",
       "  'FSS-1000': {'full_name': None,\n",
       "   'variants': ['FSS-1000'],\n",
       "   'title': 'FSS-1000: A 1000-Class Dataset for Few-Shot Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/fss-1000-a-1000-class-dataset-for-few-shot'},\n",
       "  'Reddit': {'full_name': '',\n",
       "   'variants': ['Reddit TIFU', 'Reddit (multi-ref)', 'REDDIT-B', 'Reddit'],\n",
       "   'title': 'Inductive Representation Learning on Large Graphs',\n",
       "   'url': 'https://paperswithcode.com/paper/inductive-representation-learning-on-large'},\n",
       "  'DeepFashion': {'full_name': '',\n",
       "   'variants': ['Deep-Fashion',\n",
       "    'DeepFashion',\n",
       "    'DeepFashion - Consumer-to-shop'],\n",
       "   'title': 'DeepFashion: Powering Robust Clothes Recognition and Retrieval With Rich Annotations',\n",
       "   'url': 'https://paperswithcode.com/paper/deepfashion-powering-robust-clothes'},\n",
       "  'FER2013': {'full_name': 'Facial Expression Recognition 2013 Dataset',\n",
       "   'variants': ['FER2013'],\n",
       "   'title': 'Challenges in Representation Learning: A report on three machine learning contests',\n",
       "   'url': 'https://paperswithcode.com/paper/challenges-in-representation-learning-a'},\n",
       "  'Pinterest': {'full_name': None,\n",
       "   'variants': ['Pinterest'],\n",
       "   'title': 'Learning Image and User Features for Recommendation in Social Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-image-and-user-features-for'},\n",
       "  'LOL': {'full_name': 'LOw-Light dataset',\n",
       "   'variants': ['LOL'],\n",
       "   'title': 'Deep Retinex Decomposition for Low-Light Enhancement',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-retinex-decomposition-for-low-light'},\n",
       "  'HRF': {'full_name': 'High-Resolution Fundus',\n",
       "   'variants': ['HRF'],\n",
       "   'title': 'Robust Vessel Segmentation in Fundus Images',\n",
       "   'url': 'https://doi.org/10.1155/2013/154860'},\n",
       "  'DBRD': {'full_name': 'Dutch Book Reviews Dataset',\n",
       "   'variants': ['DBRD'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Kaggle-Credit Card Fraud Dataset': {'full_name': '',\n",
       "   'variants': ['Kaggle-Credit Card Fraud Dataset'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Thyroid': {'full_name': 'Thyroid Disease',\n",
       "   'variants': ['Thyroid'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Argoverse': {'full_name': '',\n",
       "   'variants': ['Argoverse', 'Argoverse CVPR 2020'],\n",
       "   'title': 'Argoverse: 3D Tracking and Forecasting with Rich Maps',\n",
       "   'url': 'https://paperswithcode.com/paper/argoverse-3d-tracking-and-forecasting-with-1'},\n",
       "  'CLEVR': {'full_name': 'Compositional Language and Elementary Visual Reasoning',\n",
       "   'variants': ['CLEVR', 'CLEVR-Dialog'],\n",
       "   'title': 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/clevr-a-diagnostic-dataset-for-compositional'},\n",
       "  'PROBA-V': {'full_name': 'PROBA-V Super-Resolution dataset',\n",
       "   'variants': ['PROBA-V'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Tai-Chi-HD': {'full_name': '',\n",
       "   'variants': ['Tai-Chi-HD (256)', 'Tai-Chi-HD (512)'],\n",
       "   'title': 'First Order Motion Model for Image Animation',\n",
       "   'url': 'https://paperswithcode.com/paper/first-order-motion-model-for-image-animation-1'},\n",
       "  'CMU-MOSEI': {'full_name': '',\n",
       "   'variants': ['CMU-MOSEI'],\n",
       "   'title': 'Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph',\n",
       "   'url': 'https://paperswithcode.com/paper/multimodal-language-analysis-in-the-wild-cmu'},\n",
       "  'AffectNet': {'full_name': '',\n",
       "   'variants': ['AffectNet'],\n",
       "   'title': 'AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/affectnet-a-database-for-facial-expression'},\n",
       "  'FER+': {'full_name': 'Face Expression Recognition Plus dataset',\n",
       "   'variants': ['FER+', 'FERPlus'],\n",
       "   'title': 'Training Deep Networks for Facial Expression Recognition with Crowd-Sourced Label Distribution',\n",
       "   'url': 'https://paperswithcode.com/paper/training-deep-networks-for-facial-expression'},\n",
       "  'CommonGen': {'full_name': '',\n",
       "   'variants': ['CommonGen'],\n",
       "   'title': 'CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/commongen-a-constrained-text-generation'},\n",
       "  'The China Physiological Signal Challenge 2018': {'full_name': '',\n",
       "   'variants': ['The China Physiological Signal Challenge 2018'],\n",
       "   'title': 'An Open Access Database for Evaluating the Algorithms of Electrocardiogram Rhythm and Morphology Abnormality Detection',\n",
       "   'url': 'https://paperswithcode.com/paper/an-open-access-database-for-evaluating-the'},\n",
       "  'University-1652': {'full_name': '',\n",
       "   'variants': ['University-1652'],\n",
       "   'title': 'University-1652: A Multi-view Multi-source Benchmark for Drone-based Geo-localization',\n",
       "   'url': 'https://paperswithcode.com/paper/university-1652-a-multi-view-multi-source'},\n",
       "  'FQuAD': {'full_name': 'French Question Answering Dataset',\n",
       "   'variants': ['FQuAD'],\n",
       "   'title': 'FQuAD: French Question Answering Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/fquad-french-question-answering-dataset'},\n",
       "  'HARD': {'full_name': 'Hotel Arabic-Reviews Dataset',\n",
       "   'variants': ['HARD'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  '3DFAW': {'full_name': None,\n",
       "   'variants': ['3DFAW'],\n",
       "   'title': 'The First 3D Face Alignment in the Wild (3DFAW) Challenge',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-48881-3_35'},\n",
       "  'Breakfast': {'full_name': 'The Breakfast Actions Dataset',\n",
       "   'variants': ['Breakfast'],\n",
       "   'title': 'The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities',\n",
       "   'url': 'https://paperswithcode.com/paper/the-language-of-actions-recovering-the-syntax'},\n",
       "  'NELL-995': {'full_name': '',\n",
       "   'variants': ['NELL-995'],\n",
       "   'title': 'DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/deeppath-a-reinforcement-learning-method-for'},\n",
       "  'Composition-1K': {'full_name': '',\n",
       "   'variants': ['Composition-1K'],\n",
       "   'title': 'Deep Image Matting',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-image-matting'},\n",
       "  'KolektorSDD': {'full_name': 'Kolektor Surface-Defect Dataset',\n",
       "   'variants': ['KolektorSDD'],\n",
       "   'title': 'Segmentation-Based Deep-Learning Approach for Surface-Defect Detection',\n",
       "   'url': 'https://paperswithcode.com/paper/segmentation-based-deep-learning-approach-for'},\n",
       "  'ASLG-PC12': {'full_name': 'English-ASL Gloss Parallel Corpus 2012',\n",
       "   'variants': ['ASLG-PC12'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CIFAR10-DVS': {'full_name': 'CIFAR10-DVS',\n",
       "   'variants': ['CIFAR10-DVS'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Stanford Online Products': {'full_name': 'Stanford Online Products',\n",
       "   'variants': ['Stanford Online Products'],\n",
       "   'title': 'Deep Metric Learning via Lifted Structured Feature Embedding',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-metric-learning-via-lifted-structured'},\n",
       "  'In-Shop': {'full_name': 'In-shop Clothes Retrieval Benchmark',\n",
       "   'variants': ['In-Shop'],\n",
       "   'title': 'DeepFashion: Powering Robust Clothes Recognition and Retrieval With Rich Annotations',\n",
       "   'url': 'https://paperswithcode.com/paper/deepfashion-powering-robust-clothes'},\n",
       "  'Ecoli': {'full_name': None,\n",
       "   'variants': ['Ecoli'],\n",
       "   'title': 'A Probabilistic Classification System for Predicting the Cellular Localization Sites of Proteins',\n",
       "   'url': 'http://www.aaai.org/Library/ISMB/1996/ismb96-012.php'},\n",
       "  'Yeast': {'full_name': '',\n",
       "   'variants': ['Yeast'],\n",
       "   'title': 'Topological structure analysis of the protein-protein interaction network in budding yeast',\n",
       "   'url': 'http://www.imb-jena.de/jcb/ppi/PPI_PDF_free/bu2003.pdf'},\n",
       "  'MOT17': {'full_name': 'Multiple Object Tracking 17',\n",
       "   'variants': ['MOT17'],\n",
       "   'title': 'MOT16: A Benchmark for Multi-Object Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/mot16-a-benchmark-for-multi-object-tracking'},\n",
       "  'MOT20': {'full_name': 'MOT20',\n",
       "   'variants': ['MOT20'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SEMAINE': {'full_name': '',\n",
       "   'variants': ['SEMAINE'],\n",
       "   'title': 'The SEMAINE Database: Annotated Multimodal Records of Emotionally Colored Conversations between a Person and a Limited Agent',\n",
       "   'url': 'https://doi.org/10.1109/T-AFFC.2011.20'},\n",
       "  'R2R': {'full_name': 'Room-to-Room',\n",
       "   'variants': ['Room2Room', 'R2R'],\n",
       "   'title': 'Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments',\n",
       "   'url': 'https://paperswithcode.com/paper/vision-and-language-navigation-interpreting'},\n",
       "  'SceneNN': {'full_name': '',\n",
       "   'variants': ['SceneNN'],\n",
       "   'title': 'SceneNN: A Scene Meshes Dataset with aNNotations',\n",
       "   'url': 'https://doi.org/10.1109/3DV.2016.18'},\n",
       "  'EGTEA': {'full_name': 'EGTEA Gaze+',\n",
       "   'variants': [],\n",
       "   'title': 'In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video',\n",
       "   'url': 'https://paperswithcode.com/paper/in-the-eye-of-beholder-joint-learning-of-gaze'},\n",
       "  'GAP': {'full_name': 'GAP Benchmark Suite',\n",
       "   'variants': ['GAP'],\n",
       "   'title': 'The GAP Benchmark Suite',\n",
       "   'url': 'https://paperswithcode.com/paper/the-gap-benchmark-suite'},\n",
       "  'BIPED': {'full_name': 'Barcelona Images for Perceptual Edge Detection',\n",
       "   'variants': ['BIPED'],\n",
       "   'title': 'Dense Extreme Inception Network: Towards a Robust CNN Model for Edge Detection',\n",
       "   'url': 'https://paperswithcode.com/paper/dense-extreme-inception-network-towards-a'},\n",
       "  'StereoSet': {'full_name': '',\n",
       "   'variants': ['StereoSet'],\n",
       "   'title': 'StereoSet: Measuring stereotypical bias in pretrained language models',\n",
       "   'url': 'https://paperswithcode.com/paper/stereoset-measuring-stereotypical-bias-in'},\n",
       "  'MIT-States': {'full_name': '',\n",
       "   'variants': ['MIT-States', 'MIT-States, generalized split'],\n",
       "   'title': 'Discovering States and Transformations in Image Collections',\n",
       "   'url': 'https://paperswithcode.com/paper/discovering-states-and-transformations-in'},\n",
       "  'Caltech-256': {'full_name': '',\n",
       "   'variants': ['Caltech-256, 1024 Labels',\n",
       "    'Caltech-256',\n",
       "    'Caltech-256 5-way (1-shot)'],\n",
       "   'title': 'Caltech-256 object category dataset',\n",
       "   'url': 'http://authors.library.caltech.edu/7694'},\n",
       "  'SCDE': {'full_name': 'SCDE',\n",
       "   'variants': ['SCDE'],\n",
       "   'title': 'SCDE: Sentence Cloze Dataset with High Quality Distractors From Examinations',\n",
       "   'url': 'https://paperswithcode.com/paper/scde-sentence-cloze-dataset-with-high-quality'},\n",
       "  'VATEX': {'full_name': 'Video And TEXt',\n",
       "   'variants': ['VATEX'],\n",
       "   'title': 'VATEX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research',\n",
       "   'url': 'https://paperswithcode.com/paper/vatex-a-large-scale-high-quality-multilingual'},\n",
       "  'ViGGO': {'full_name': '',\n",
       "   'variants': ['ViGGO'],\n",
       "   'title': 'ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain Conversation',\n",
       "   'url': 'https://paperswithcode.com/paper/viggo-a-video-game-corpus-for-data-to-text'},\n",
       "  'REAL275': {'full_name': 'NOCS-REAL275',\n",
       "   'variants': ['REAL275'],\n",
       "   'title': 'Normalized Object Coordinate Space for Category-Level 6D Object Pose and Size Estimation',\n",
       "   'url': 'https://paperswithcode.com/paper/normalized-object-coordinate-space-for'},\n",
       "  'ISTD': {'full_name': '',\n",
       "   'variants': ['ISTD'],\n",
       "   'title': 'Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal',\n",
       "   'url': 'https://paperswithcode.com/paper/stacked-conditional-generative-adversarial'},\n",
       "  'LCQMC': {'full_name': 'Large-scale Chinese Question Matching Corpus',\n",
       "   'variants': [],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CoNLL-2009': {'full_name': 'CoNLL-2009',\n",
       "   'variants': ['CoNLL-2009'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Ciao': {'full_name': '',\n",
       "   'variants': ['Ciao'],\n",
       "   'title': 'mTrust: discerning multi-faceted trust in a connected world',\n",
       "   'url': 'https://doi.org/10.1145/2124295.2124309'},\n",
       "  'SICK': {'full_name': 'Sentences Involving Compositional Knowledge',\n",
       "   'variants': ['SICK'],\n",
       "   'title': 'A SICK cure for the evaluation of compositional distributional semantic models',\n",
       "   'url': 'https://paperswithcode.com/paper/a-sick-cure-for-the-evaluation-of'},\n",
       "  'FB15k': {'full_name': 'Freebase 15K',\n",
       "   'variants': [' FB15k', 'FB15k-237', 'FB15k', 'FB15k (filtered)'],\n",
       "   'title': 'Translating Embeddings for Modeling Multi-relational Data',\n",
       "   'url': 'https://paperswithcode.com/paper/translating-embeddings-for-modeling-multi'},\n",
       "  'CJRC': {'full_name': 'Chinese judicial reading comprehension',\n",
       "   'variants': ['CJRC Dev', 'CJRC'],\n",
       "   'title': 'CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial Reading Comprehension',\n",
       "   'url': 'https://paperswithcode.com/paper/cjrc-a-reliable-human-annotated-benchmark'},\n",
       "  'HyperLex': {'full_name': '',\n",
       "   'variants': ['HyperLex'],\n",
       "   'title': 'HyperLex: A Large-Scale Evaluation of Graded Lexical Entailment',\n",
       "   'url': 'https://paperswithcode.com/paper/hyperlex-a-large-scale-evaluation-of-graded'},\n",
       "  'DBLP': {'full_name': 'Citation Network Dataset',\n",
       "   'variants': ['DBLP (PACT) 14k', 'DBLP'],\n",
       "   'title': 'ArnetMiner: extraction and mining of academic social networks',\n",
       "   'url': 'https://doi.org/10.1145/1401890.1402008'},\n",
       "  'ACM': {'full_name': 'Association for Computing Machinery\\nActive Contour Model\\nalgebraic collective model\\nand-Compare Module\\nActive Contour Models',\n",
       "   'variants': ['ACM'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'FNC-1': {'full_name': 'Fake News Challenge Stage 1',\n",
       "   'variants': ['FNC-1'],\n",
       "   'title': 'The fake news challenge: Exploring how artificial intelligence technologies could be leveraged to combat fake news',\n",
       "   'url': 'http://www.fakenewschallenge.org/'},\n",
       "  'GYAFC': {'full_name': 'Grammarly’s Yahoo Answers Formality Corpus',\n",
       "   'variants': ['GYAFC'],\n",
       "   'title': 'Dear Sir or Madam, May I introduce the GYAFC Dataset: Corpus, Benchmarks and Metrics for Formality Style Transfer',\n",
       "   'url': 'https://paperswithcode.com/paper/dear-sir-or-madam-may-i-introduce-the-gyafc'},\n",
       "  'AIDS': {'full_name': 'AIDS',\n",
       "   'variants': ['AIDS'],\n",
       "   'title': 'IAM Graph Database Repository for Graph Based Pattern Recognition and Machine Learning',\n",
       "   'url': 'https://doi.org/10.1007/978-3-540-89689-0_33'},\n",
       "  'Sydney Urban Objects': {'full_name': None,\n",
       "   'variants': ['Sydney Urban Objects'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Digits': {'full_name': 'Optical Recognition of Handwritten Digits',\n",
       "   'variants': ['Optical Recognition of Handwritten Digits', 'Digits'],\n",
       "   'title': 'Optical recognition of handwritten digits data set',\n",
       "   'url': 'https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits'},\n",
       "  'Mutagenicity': {'full_name': None,\n",
       "   'variants': ['Mutagenicity'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SIDER': {'full_name': 'SIDER',\n",
       "   'variants': ['SIDER'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'RCV1': {'full_name': 'Reuters Corpus Volume 1',\n",
       "   'variants': ['RCV1-v2',\n",
       "    'Reuters RCV1/RCV2 English-to-German',\n",
       "    'Reuters RCV1/RCV2 German-to-English',\n",
       "    'RCV1'],\n",
       "   'title': 'RCV1: A New Benchmark Collection for Text Categorization Research',\n",
       "   'url': 'http://jmlr.org/papers/volume5/lewis04a/lewis04a.pdf'},\n",
       "  'CrossTask': {'full_name': 'CrossTask',\n",
       "   'variants': ['CrossTask'],\n",
       "   'title': 'Cross-task weakly supervised learning from instructional videos',\n",
       "   'url': 'https://paperswithcode.com/paper/cross-task-weakly-supervised-learning-from'},\n",
       "  'YouCook2': {'full_name': '',\n",
       "   'variants': ['YouCook2'],\n",
       "   'title': 'Towards Automatic Learning of Procedures from Web Instructional Videos',\n",
       "   'url': 'https://paperswithcode.com/paper/towards-automatic-learning-of-procedures-from'},\n",
       "  'FaceForensics': {'full_name': '',\n",
       "   'variants': ['FaceForensics'],\n",
       "   'title': 'FaceForensics: A Large-scale Video Dataset for Forgery Detection in Human Faces',\n",
       "   'url': 'https://paperswithcode.com/paper/faceforensics-a-large-scale-video-dataset-for'},\n",
       "  'Stacked MNIST': {'full_name': 'Stacked MNIST',\n",
       "   'variants': ['Stacked MNIST'],\n",
       "   'title': 'Unrolled Generative Adversarial Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/unrolled-generative-adversarial-networks'},\n",
       "  'CARPK': {'full_name': 'car parking lot dataset',\n",
       "   'variants': ['CARPK'],\n",
       "   'title': 'Drone-based Object Counting by Spatially Regularized Regional Proposal Network',\n",
       "   'url': 'https://paperswithcode.com/paper/drone-based-object-counting-by-spatially'},\n",
       "  'Pix3D': {'full_name': '',\n",
       "   'variants': ['Pix3D S2', 'Pix3D S1', 'Pix3D'],\n",
       "   'title': 'Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling',\n",
       "   'url': 'https://paperswithcode.com/paper/pix3d-dataset-and-methods-for-single-image-3d'},\n",
       "  'Cell': {'full_name': '',\n",
       "   'variants': ['Cell17', 'Cell', 'CellNet'],\n",
       "   'title': 'Multi-Domain Adversarial Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/multi-domain-adversarial-learning-1'},\n",
       "  'FBMS': {'full_name': 'Freiburg-Berkeley Motion Segmentation',\n",
       "   'variants': ['FBMS-59', 'FBMS'],\n",
       "   'title': 'Segmentation of Moving Objects by Long Term Video Analysis',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2013.242'},\n",
       "  'NVGesture': {'full_name': None,\n",
       "   'variants': [' NVGesture', 'NVGesture'],\n",
       "   'title': 'Online Detection and Classification of Dynamic Hand Gestures With Recurrent 3D Convolutional Neural Network',\n",
       "   'url': 'https://paperswithcode.com/paper/online-detection-and-classification-of'},\n",
       "  'SUN09': {'full_name': 'SUN09',\n",
       "   'variants': ['SUN09'],\n",
       "   'title': 'Exploiting hierarchical context on a large database of object categories',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2010.5540221'},\n",
       "  'COIN': {'full_name': '',\n",
       "   'variants': ['COIN'],\n",
       "   'title': 'COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/coin-a-large-scale-dataset-for-comprehensive'},\n",
       "  'Kinetics-600': {'full_name': '',\n",
       "   'variants': ['Kinetics-600 12 frames, 64x64',\n",
       "    'Kinetics-600 48 frames, 64x64',\n",
       "    'Kinetics-600 12 frames, 128x128',\n",
       "    'Kinetics-600'],\n",
       "   'title': 'A Short Note about Kinetics-600',\n",
       "   'url': 'https://paperswithcode.com/paper/a-short-note-about-kinetics-600'},\n",
       "  'AudioSet': {'full_name': '',\n",
       "   'variants': ['AudioSet'],\n",
       "   'title': 'Audio Set: An ontology and human-labeled dataset for audio events',\n",
       "   'url': 'https://doi.org/10.1109/ICASSP.2017.7952261'},\n",
       "  'DIVA-HisDB': {'full_name': '',\n",
       "   'variants': ['DIVA-HisDB'],\n",
       "   'title': 'DIVA-HisDB: A Precisely Annotated Large Dataset of Challenging Medieval Manuscripts',\n",
       "   'url': 'https://paperswithcode.com/paper/diva-hisdb-a-precisely-annotated-large'},\n",
       "  'TDIUC': {'full_name': 'Task Directed Image Understanding Challenge',\n",
       "   'variants': ['TDIUC'],\n",
       "   'title': 'An Analysis of Visual Question Answering Algorithms',\n",
       "   'url': 'https://paperswithcode.com/paper/an-analysis-of-visual-question-answering'},\n",
       "  'Mall': {'full_name': 'Mall Dataset',\n",
       "   'variants': ['Mall'],\n",
       "   'title': 'Feature Mining for Localised Crowd Counting',\n",
       "   'url': 'https://doi.org/10.5244/C.26.21'},\n",
       "  'A3D': {'full_name': 'AnAn Accident Detection',\n",
       "   'variants': ['A3D'],\n",
       "   'title': 'Unsupervised Traffic Accident Detection in First-Person Videos',\n",
       "   'url': 'https://paperswithcode.com/paper/unsupervised-traffic-accident-detection-in'},\n",
       "  'FRGC': {'full_name': 'Face Recognition Grand Challenge',\n",
       "   'variants': ['FRGC'],\n",
       "   'title': 'Overview of the Face Recognition Grand Challenge',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2005.268'},\n",
       "  'HAR': {'full_name': 'Human Activity Recognition Using Smartphones',\n",
       "   'variants': ['HAR'],\n",
       "   'title': 'A Public Domain Dataset for Human Activity Recognition using Smartphones',\n",
       "   'url': 'http://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf'},\n",
       "  'MOT15': {'full_name': 'Multiple Object Tracking 15',\n",
       "   'variants': ['2DMOT15', '2D MOT 2015', 'MOT15'],\n",
       "   'title': 'MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/motchallenge-2015-towards-a-benchmark-for'},\n",
       "  'CASIA-MFSD': {'full_name': 'CASIA-MFSD',\n",
       "   'variants': ['CASIA-MFSD'],\n",
       "   'title': 'A face antispoofing database with diverse attacks',\n",
       "   'url': 'https://doi.org/10.1109/ICB.2012.6199754'},\n",
       "  'Replay-Attack': {'full_name': '',\n",
       "   'variants': ['Replay-Attack'],\n",
       "   'title': 'On the effectiveness of local binary patterns in face anti-spoofing',\n",
       "   'url': 'https://dl.gi.de/20.500.12116/18295'},\n",
       "  'Delicious': {'full_name': 'Delicious',\n",
       "   'variants': ['Delicious'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'WeChat': {'full_name': None,\n",
       "   'variants': ['WeChat'],\n",
       "   'title': 'Weak Supervision for Fake News Detection via Reinforcement Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/weak-supervision-for-fake-news-detection-via'},\n",
       "  'RAF-DB': {'full_name': 'Real-world Affective Faces',\n",
       "   'variants': ['Real-World Affective Faces', 'RAF-DB'],\n",
       "   'title': 'Reliable Crowdsourcing and Deep Locality-Preserving Learning for Expression Recognition in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/reliable-crowdsourcing-and-deep-locality'},\n",
       "  'FERG': {'full_name': 'Facial Expression Research Group Database',\n",
       "   'variants': ['FERG'],\n",
       "   'title': 'Modeling Stylized Character Expressions via Deep Learning',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-54184-6_9'},\n",
       "  'COCO-Text': {'full_name': 'COCO-Text',\n",
       "   'variants': ['COCO-Text'],\n",
       "   'title': 'COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images',\n",
       "   'url': 'https://paperswithcode.com/paper/coco-text-dataset-and-benchmark-for-text'},\n",
       "  'DiscoFuse': {'full_name': 'DiscoFuse',\n",
       "   'variants': ['DiscoFuse'],\n",
       "   'title': 'DiscoFuse: A Large-Scale Dataset for Discourse-Based Sentence Fusion',\n",
       "   'url': 'https://paperswithcode.com/paper/discofuse-a-large-scale-dataset-for-discourse'},\n",
       "  'FIGER': {'full_name': 'Fine-Grained Entity Recognition',\n",
       "   'variants': ['FIGER'],\n",
       "   'title': 'Fine-Grained Entity Recognition',\n",
       "   'url': 'http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5152'},\n",
       "  'CUHK-SYSU': {'full_name': 'CUHK-SYSU Person Search Dataset',\n",
       "   'variants': ['CUHK-SYSU'],\n",
       "   'title': 'Joint Detection and Identification Feature Learning for Person Search',\n",
       "   'url': 'https://paperswithcode.com/paper/joint-detection-and-identification-feature'},\n",
       "  'Chairs': {'full_name': '',\n",
       "   'variants': ['Chairs'],\n",
       "   'title': 'Seeing 3D Chairs: Exemplar Part-based 2D-3D Alignment using a Large Dataset of CAD Models',\n",
       "   'url': 'https://paperswithcode.com/paper/seeing-3d-chairs-exemplar-part-based-2d-3d'},\n",
       "  'ZINC': {'full_name': 'ZINC',\n",
       "   'variants': ['ZINC', 'ZINC 100k', 'ZINC-500k'],\n",
       "   'title': 'ZINC: A Free Tool to Discover Chemistry for Biology',\n",
       "   'url': 'https://doi.org/10.1021/ci3001277'},\n",
       "  'QED': {'full_name': None,\n",
       "   'variants': ['QED'],\n",
       "   'title': 'QED: A Framework and Dataset for Explanations in Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/qed-a-framework-and-dataset-for-explanations'},\n",
       "  'MEF': {'full_name': 'Multi-exposure image fusion',\n",
       "   'variants': ['MEF'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'DICM': {'full_name': 'DICM',\n",
       "   'variants': ['DICM'],\n",
       "   'title': 'Contrast enhancement based on layered difference representation',\n",
       "   'url': 'https://doi.org/10.1109/ICIP.2012.6467022'},\n",
       "  'GuessWhat?!': {'full_name': '',\n",
       "   'variants': ['GuessWhat?!'],\n",
       "   'title': 'GuessWhat?! Visual object discovery through multi-modal dialogue',\n",
       "   'url': 'https://paperswithcode.com/paper/guesswhat-visual-object-discovery-through'},\n",
       "  'ObjectNet': {'full_name': '',\n",
       "   'variants': ['ObjectNet', 'ObjectNet (Bounding Box)'],\n",
       "   'title': 'ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models',\n",
       "   'url': 'https://paperswithcode.com/paper/objectnet-a-large-scale-bias-controlled'},\n",
       "  'ActivityNet Captions': {'full_name': '',\n",
       "   'variants': ['ActivityNet Captions'],\n",
       "   'title': 'Dense-Captioning Events in Videos',\n",
       "   'url': 'https://paperswithcode.com/paper/dense-captioning-events-in-videos'},\n",
       "  'smallNORB': {'full_name': '',\n",
       "   'variants': ['smallNORB'],\n",
       "   'title': 'Learning Methods for Generic Object Recognition with Invariance to Pose and Lighting',\n",
       "   'url': 'http://doi.ieeecomputersociety.org/10.1109/CVPR.2004.144'},\n",
       "  'DocRED': {'full_name': '',\n",
       "   'variants': ['DocRED'],\n",
       "   'title': 'DocRED: A Large-Scale Document-Level Relation Extraction Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/docred-a-large-scale-document-level-relation'},\n",
       "  'iMaterialist': {'full_name': '',\n",
       "   'variants': ['iMaterialist'],\n",
       "   'title': 'The iMaterialist Fashion Attribute Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/the-imaterialist-fashion-attribute-dataset'},\n",
       "  'ImageNet-C': {'full_name': 'ImageNet-C',\n",
       "   'variants': ['ImageNet-C'],\n",
       "   'title': 'Benchmarking Neural Network Robustness to Common Corruptions and Perturbations',\n",
       "   'url': 'https://paperswithcode.com/paper/benchmarking-neural-network-robustness-to-2'},\n",
       "  'ImageNet-A': {'full_name': '',\n",
       "   'variants': ['ImageNet-A'],\n",
       "   'title': 'Natural Adversarial Examples',\n",
       "   'url': 'https://paperswithcode.com/paper/natural-adversarial-examples'},\n",
       "  'BIOSSES': {'full_name': 'Biomedical Semantic Similarity Estimation System',\n",
       "   'variants': ['BIOSSES'],\n",
       "   'title': 'BIOSSES: A Semantic Sentence Similarity Estimation System for the Biomedical Domain',\n",
       "   'url': 'https://paperswithcode.com/paper/biosses-a-semantic-sentence-similarity'},\n",
       "  'MedNLI': {'full_name': 'Medical Natural Language Inference',\n",
       "   'variants': ['MedNLI'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'UCF-QNRF': {'full_name': '',\n",
       "   'variants': ['UCF-QNRF'],\n",
       "   'title': 'Composition Loss for Counting, Density Map Estimation and Localization in Dense Crowds',\n",
       "   'url': 'https://paperswithcode.com/paper/composition-loss-for-counting-density-map'},\n",
       "  'WiderPerson': {'full_name': '',\n",
       "   'variants': ['WiderPerson'],\n",
       "   'title': 'WiderPerson: A Diverse Dataset for Dense Pedestrian Detection in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/widerperson-a-diverse-dataset-for-dense'},\n",
       "  'CID': {'full_name': 'Campus Image Dataset',\n",
       "   'variants': ['CID'],\n",
       "   'title': 'Learning an Adaptive Model for Extreme Low-light Raw Image Processing',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-an-adaptive-model-for-extreme-low'},\n",
       "  'LeNER-Br': {'full_name': '',\n",
       "   'variants': ['LeNER-Br',\n",
       "    'lener_br',\n",
       "    'pierreguillou/lener_br_finetuning_language_model'],\n",
       "   'title': 'LeNER-Br: a Dataset for Named Entity Recognition in Brazilian Legal Text',\n",
       "   'url': 'https://paperswithcode.com/paper/lener-br-a-dataset-for-named-entity'},\n",
       "  'DAVIS': {'full_name': 'Densely Annotated VIdeo Segmentation',\n",
       "   'variants': ['DAVIS sigma50',\n",
       "    'DAVIS sigma40',\n",
       "    'DAVIS sigma30',\n",
       "    'DAVIS sigma20',\n",
       "    'DAVIS sigma10',\n",
       "    'DAVIS 2017',\n",
       "    'DAVIS'],\n",
       "   'title': 'A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/a-benchmark-dataset-and-evaluation'},\n",
       "  'VIST': {'full_name': 'Visual Storytelling',\n",
       "   'variants': ['VIST'],\n",
       "   'title': 'Visual Storytelling',\n",
       "   'url': 'https://paperswithcode.com/paper/visual-storytelling'},\n",
       "  'DTD': {'full_name': 'Describable Textures Dataset',\n",
       "   'variants': ['DTD'],\n",
       "   'title': 'Describing Textures in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/describing-textures-in-the-wild'},\n",
       "  'Adience': {'full_name': '',\n",
       "   'variants': ['Adience',\n",
       "    'Adience Age',\n",
       "    'Adience Gender',\n",
       "    'Adience (Online Open Set)'],\n",
       "   'title': 'Age and Gender Estimation of Unfiltered Faces',\n",
       "   'url': 'https://doi.org/10.1109/TIFS.2014.2359646'},\n",
       "  'Matterport3D': {'full_name': '',\n",
       "   'variants': ['Matterport3D'],\n",
       "   'title': 'Matterport3D: Learning from RGB-D Data in Indoor Environments',\n",
       "   'url': 'https://paperswithcode.com/paper/matterport3d-learning-from-rgb-d-data-in'},\n",
       "  'ToTTo': {'full_name': 'ToTTo',\n",
       "   'variants': ['ToTTo'],\n",
       "   'title': 'ToTTo: A Controlled Table-To-Text Generation Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/totto-a-controlled-table-to-text-generation'},\n",
       "  'PCam': {'full_name': 'PatchCamelyon',\n",
       "   'variants': ['PCam'],\n",
       "   'title': 'Rotation Equivariant CNNs for Digital Pathology',\n",
       "   'url': 'https://paperswithcode.com/paper/rotation-equivariant-cnns-for-digital'},\n",
       "  'Kumar': {'full_name': '',\n",
       "   'variants': ['Kumar'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'HellaSwag': {'full_name': '',\n",
       "   'variants': ['HellaSwag'],\n",
       "   'title': 'HellaSwag: Can a Machine Really Finish Your Sentence?',\n",
       "   'url': 'https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your'},\n",
       "  'LAMBADA': {'full_name': '',\n",
       "   'variants': ['LAMBADA'],\n",
       "   'title': 'The LAMBADA dataset: Word prediction requiring a broad discourse context',\n",
       "   'url': 'https://paperswithcode.com/paper/the-lambada-dataset-word-prediction-requiring'},\n",
       "  'PIQA': {'full_name': 'Physical Interaction: Question Answering',\n",
       "   'variants': ['PIQA'],\n",
       "   'title': 'PIQA: Reasoning about Physical Commonsense in Natural Language',\n",
       "   'url': 'https://paperswithcode.com/paper/piqa-reasoning-about-physical-commonsense-in'},\n",
       "  'OpenBookQA': {'full_name': '',\n",
       "   'variants': ['OpenBookQA'],\n",
       "   'title': 'Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/can-a-suit-of-armor-conduct-electricity-a-new'},\n",
       "  'WSC': {'full_name': 'Winograd Schema Challenge',\n",
       "   'variants': ['Winograd Schema Challenge', 'WSC'],\n",
       "   'title': 'The Winograd Schema Challenge',\n",
       "   'url': 'http://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492'},\n",
       "  'arXiv': {'full_name': 'Arxiv HEP-TH (high energy physics theory) citation graph',\n",
       "   'variants': ['arXiv-AstroPh 3-clique',\n",
       "    'arXiv-GrQc 4-clique',\n",
       "    'arXiv',\n",
       "    'arXiv-Long Val',\n",
       "    'arXiv-Long Test'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'PhyAAt': {'full_name': 'Physiology of Auditory Attention',\n",
       "   'variants': ['PhyAAt'],\n",
       "   'title': 'PhyAAt: Physiology of Auditory Attention to Speech Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/phyaat-physiology-of-auditory-attention-to'},\n",
       "  'LEVIR-CD': {'full_name': '',\n",
       "   'variants': ['LEVIR-CD'],\n",
       "   'title': 'A Spatial-Temporal Attention-Based Method and a New Dataset for Remote Sensing Image Change Detection',\n",
       "   'url': 'https://paperswithcode.com/paper/a-spatial-temporal-attention-based-method-and'},\n",
       "  'FEVER': {'full_name': 'Fact Extraction and VERification',\n",
       "   'variants': ['FEVER', 'FEVER (BEIR)'],\n",
       "   'title': 'FEVER: a large-scale dataset for Fact Extraction and VERification',\n",
       "   'url': 'https://paperswithcode.com/paper/fever-a-large-scale-dataset-for-fact'},\n",
       "  'MELD': {'full_name': 'Multimodal EmotionLines Dataset',\n",
       "   'variants': ['MELD'],\n",
       "   'title': 'MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations',\n",
       "   'url': 'https://paperswithcode.com/paper/meld-a-multimodal-multi-party-dataset-for'},\n",
       "  'EmoryNLP': {'full_name': '',\n",
       "   'variants': ['EmoryNLP'],\n",
       "   'title': 'Emotion Detection on TV Show Transcripts with Sequence-based Convolutional Neural Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/emotion-detection-on-tv-show-transcripts-with'},\n",
       "  '4D Light Field Dataset': {'full_name': '',\n",
       "   'variants': [],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Virtual KITTI 2': {'full_name': '',\n",
       "   'variants': ['Virtual KITTI 2'],\n",
       "   'title': 'Virtual KITTI 2',\n",
       "   'url': 'https://paperswithcode.com/paper/virtual-kitti-2'},\n",
       "  'WHAMR!': {'full_name': 'WHAM! with synthetic reverberated sources',\n",
       "   'variants': ['WHAMR!'],\n",
       "   'title': 'WHAMR!: Noisy and Reverberant Single-Channel Speech Separation',\n",
       "   'url': 'https://paperswithcode.com/paper/whamr-noisy-and-reverberant-single-channel'},\n",
       "  'DEMAND': {'full_name': 'Diverse Environments Multi-channel Acoustic Noise Database',\n",
       "   'variants': ['DEMAND'],\n",
       "   'title': 'The Diverse Environments Multi-channel Acoustic Noise Database (DEMAND): A database of multichannel environmental noise recordings',\n",
       "   'url': 'https://asa.scitation.org/doi/abs/10.1121/1.4799597'},\n",
       "  'BUFF': {'full_name': 'Bodies Under Flowing Fashion',\n",
       "   'variants': ['BUFF'],\n",
       "   'title': 'Detailed, accurate, human shape estimation from clothed 3D scan sequences',\n",
       "   'url': 'https://paperswithcode.com/paper/detailed-accurate-human-shape-estimation-from'},\n",
       "  'Taskonomy': {'full_name': '',\n",
       "   'variants': ['Taskonomy'],\n",
       "   'title': 'Taskonomy: Disentangling Task Transfer Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/taskonomy-disentangling-task-transfer'},\n",
       "  'Abalone': {'full_name': 'Abalone',\n",
       "   'variants': ['Abalone'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Letter': {'full_name': 'Letter Recognition Data Set',\n",
       "   'variants': ['LetterA-J', 'Letter'],\n",
       "   'title': 'Letter Recognition Using Holland-Style Adaptive Classifiers',\n",
       "   'url': 'https://doi.org/10.1007/BF00114162'},\n",
       "  'Electricity': {'full_name': 'Individual household electric power consumption Data Set',\n",
       "   'variants': ['Electricity'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'NetHack Learning Environment': {'full_name': 'NetHack Learning Environment',\n",
       "   'variants': ['NetHack Learning Environment'],\n",
       "   'title': 'The NetHack Learning Environment',\n",
       "   'url': 'https://paperswithcode.com/paper/the-nethack-learning-environment'},\n",
       "  'Kvasir-SEG': {'full_name': '',\n",
       "   'variants': ['Kvasir-SEG'],\n",
       "   'title': 'Kvasir-SEG: A Segmented Polyp Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/kvasir-seg-a-segmented-polyp-dataset'},\n",
       "  '2018 Data Science Bowl': {'full_name': '2018 Data Science Bowl Find the nuclei in divergent images to advance medical discovery',\n",
       "   'variants': ['2018 Data Science Bowl'],\n",
       "   'title': 'UNet++: A Nested U-Net Architecture for Medical Image Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/unet-a-nested-u-net-architecture-for-medical'},\n",
       "  'CVC-ClinicDB': {'full_name': None,\n",
       "   'variants': ['CVC-ClinicDB'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CAT2000': {'full_name': '',\n",
       "   'variants': ['CAT2000'],\n",
       "   'title': 'CAT2000: A Large Scale Fixation Dataset for Boosting Saliency Research',\n",
       "   'url': 'https://paperswithcode.com/paper/cat2000-a-large-scale-fixation-dataset-for'},\n",
       "  'FixaTons': {'full_name': '',\n",
       "   'variants': ['FixaTons'],\n",
       "   'title': 'FixaTons: A collection of Human Fixations Datasets and Metrics for Scanpath Similarity',\n",
       "   'url': 'https://paperswithcode.com/paper/fixatons-a-collection-of-human-fixations'},\n",
       "  'ImageNet-R': {'full_name': 'ImageNet-Rendition',\n",
       "   'variants': ['ImageNet-R'],\n",
       "   'title': 'The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization',\n",
       "   'url': 'https://paperswithcode.com/paper/the-many-faces-of-robustness-a-critical'},\n",
       "  '20 Newsgroups': {'full_name': '',\n",
       "   'variants': ['20 Newsgroups'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'HACS': {'full_name': 'Human Action Clips and Segments',\n",
       "   'variants': ['HACS'],\n",
       "   'title': 'HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization',\n",
       "   'url': 'https://paperswithcode.com/paper/hacs-human-action-clips-and-segments-dataset'},\n",
       "  'Kinetics-700': {'full_name': 'Kinetics-700',\n",
       "   'variants': ['Kinetics-700'],\n",
       "   'title': 'A Short Note on the Kinetics-700 Human Action Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/a-short-note-on-the-kinetics-700-human-action'},\n",
       "  'Completion3D': {'full_name': '',\n",
       "   'variants': ['Completion3D'],\n",
       "   'title': 'TopNet: Structural Point Cloud Decoder',\n",
       "   'url': 'https://paperswithcode.com/paper/topnet-structural-point-cloud-decoder'},\n",
       "  'QMNIST': {'full_name': None,\n",
       "   'variants': ['QMNIST'],\n",
       "   'title': 'Cold Case: The Lost MNIST Digits',\n",
       "   'url': 'https://paperswithcode.com/paper/cold-case-the-lost-mnist-digits'},\n",
       "  'ROCStories': {'full_name': '',\n",
       "   'variants': ['Story Cloze Test', 'ROCStories'],\n",
       "   'title': 'A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories',\n",
       "   'url': 'https://paperswithcode.com/paper/a-corpus-and-cloze-evaluation-for-deeper'},\n",
       "  'ePillID': {'full_name': None,\n",
       "   'variants': ['ePillID'],\n",
       "   'title': 'ePillID Dataset: A Low-Shot Fine-Grained Benchmark for Pill Identification',\n",
       "   'url': 'https://paperswithcode.com/paper/epillid-dataset-a-low-shot-fine-grained'},\n",
       "  'CodeSearchNet': {'full_name': '',\n",
       "   'variants': ['CodeSearchNet - Ruby',\n",
       "    'CodeSearchNet - Php',\n",
       "    'CodeSearchNet - JavaScript',\n",
       "    'CodeSearchNet - Java',\n",
       "    'CodeSearchNet - Go',\n",
       "    'CodeSearchNet - Python',\n",
       "    'CodeSearchNet'],\n",
       "   'title': 'CodeSearchNet Challenge: Evaluating the State of Semantic Code Search',\n",
       "   'url': 'https://paperswithcode.com/paper/codesearchnet-challenge-evaluating-the-state'},\n",
       "  'WikiTableQuestions': {'full_name': '',\n",
       "   'variants': ['WikiTableQuestions'],\n",
       "   'title': 'Compositional Semantic Parsing on Semi-Structured Tables',\n",
       "   'url': 'https://paperswithcode.com/paper/compositional-semantic-parsing-on-semi'},\n",
       "  'AViD': {'full_name': '',\n",
       "   'variants': ['AViD'],\n",
       "   'title': 'AViD Dataset: Anonymized Videos from Diverse Countries',\n",
       "   'url': 'https://paperswithcode.com/paper/avid-dataset-anonymized-videos-from-diverse'},\n",
       "  'MTL-AQA': {'full_name': '',\n",
       "   'variants': ['MTL-AQA'],\n",
       "   'title': 'What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment',\n",
       "   'url': 'https://paperswithcode.com/paper/what-and-how-well-you-performed-a-multitask'},\n",
       "  'AQA-7': {'full_name': '',\n",
       "   'variants': ['AQA-7'],\n",
       "   'title': 'Action Quality Assessment Across Multiple Actions',\n",
       "   'url': 'https://paperswithcode.com/paper/action-quality-assessment-across-multiple'},\n",
       "  'AGENDA': {'full_name': 'Abstract GENeration DAtaset',\n",
       "   'variants': ['AGENDA'],\n",
       "   'title': 'Text Generation from Knowledge Graphs with Graph Transformers',\n",
       "   'url': 'https://paperswithcode.com/paper/text-generation-from-knowledge-graphs-with'},\n",
       "  'GoPro': {'full_name': '',\n",
       "   'variants': ['GoPro linear subset', 'GoPro'],\n",
       "   'title': 'Deep Multi-scale Convolutional Neural Network for Dynamic Scene Deblurring',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-multi-scale-convolutional-neural-network'},\n",
       "  'AMZ Computers': {'full_name': 'amazon_electronics_computers',\n",
       "   'variants': ['AMZ Computers'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SVG-Icons8': {'full_name': '',\n",
       "   'variants': ['SVG-Icons8'],\n",
       "   'title': 'DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation',\n",
       "   'url': 'https://paperswithcode.com/paper/deepsvg-a-hierarchical-generative-network-for'},\n",
       "  'K2HPD': {'full_name': '',\n",
       "   'variants': ['K2HPD'],\n",
       "   'title': 'Human Pose Estimation from Depth Images via Inference Embedded Multi-task Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/human-pose-estimation-from-depth-images-via'},\n",
       "  'Binarized MNIST': {'full_name': '',\n",
       "   'variants': ['Binarized MNIST'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CAMO': {'full_name': 'Camouflaged Object',\n",
       "   'variants': ['CAMO'],\n",
       "   'title': 'Anabranch Network for Camouflaged Object Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/anabranch-network-for-camouflaged-object-1'},\n",
       "  'CAS-VSR-W1k (LRW-1000)': {'full_name': 'CAS-VSR-W1k (LRW-1000)',\n",
       "   'variants': ['CAS-VSR-W1k (LRW-1000)'],\n",
       "   'title': 'LRW-1000: A Naturally-Distributed Large-Scale Benchmark for Lip Reading in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/lrw-1000-a-naturally-distributed-large-scale'},\n",
       "  'LRS2': {'full_name': 'Lip Reading Sentences 2',\n",
       "   'variants': ['LRS2'],\n",
       "   'title': 'Lip Reading Sentences in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/lip-reading-sentences-in-the-wild'},\n",
       "  'Moving MNIST': {'full_name': '',\n",
       "   'variants': ['Moving MNIST'],\n",
       "   'title': 'Unsupervised Learning of Video Representations using LSTMs',\n",
       "   'url': 'https://paperswithcode.com/paper/unsupervised-learning-of-video'},\n",
       "  'Sprites': {'full_name': '2D Video Game Character Sprites',\n",
       "   'variants': ['Colored dSprites', 'Sprites'],\n",
       "   'title': 'Deep Visual Analogy-Making',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-visual-analogy-making'},\n",
       "  'BigPatent': {'full_name': '',\n",
       "   'variants': ['BigPatent'],\n",
       "   'title': 'BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization',\n",
       "   'url': 'https://paperswithcode.com/paper/bigpatent-a-large-scale-dataset-for'},\n",
       "  'NoW Benchmark': {'full_name': '',\n",
       "   'variants': ['NoW Benchmark'],\n",
       "   'title': 'Learning to Regress 3D Face Shape and Expression from an Image without 3D Supervision',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-to-regress-3d-face-shape-and'},\n",
       "  'WikiHow': {'full_name': '',\n",
       "   'variants': ['WikiHow'],\n",
       "   'title': 'WikiHow: A Large Scale Text Summarization Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/wikihow-a-large-scale-text-summarization'},\n",
       "  'Tobacco-3482': {'full_name': '',\n",
       "   'variants': ['Tobacco-3482'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Horse-10': {'full_name': '',\n",
       "   'variants': ['Horse-10'],\n",
       "   'title': 'Pretraining boosts out-of-domain robustness for pose estimation',\n",
       "   'url': 'https://paperswithcode.com/paper/pretraining-boosts-out-of-domain-robustness'},\n",
       "  'FreiHAND': {'full_name': 'FreiHAND',\n",
       "   'variants': ['FreiHAND'],\n",
       "   'title': 'FreiHAND: A Dataset for Markerless Capture of Hand Pose and Shape from Single RGB Images',\n",
       "   'url': 'https://paperswithcode.com/paper/freihand-a-dataset-for-markerless-capture-of'},\n",
       "  'DomainNet': {'full_name': 'DomainNet',\n",
       "   'variants': ['DomainNet'],\n",
       "   'title': 'Moment Matching for Multi-Source Domain Adaptation',\n",
       "   'url': 'https://paperswithcode.com/paper/moment-matching-for-multi-source-domain'},\n",
       "  'Skeleton-Mimetics': {'full_name': '',\n",
       "   'variants': ['Skeleton-Mimetics'],\n",
       "   'title': 'Quo Vadis, Skeleton Action Recognition ?',\n",
       "   'url': 'https://paperswithcode.com/paper/quo-vadis-skeleton-action-recognition'},\n",
       "  'Universal Dependencies': {'full_name': '',\n",
       "   'variants': ['Maltese Universal Dependencies Treebank (MUDT)',\n",
       "    'universal_dependencies sk_snk',\n",
       "    'Universal Dependencies v2.8',\n",
       "    'UD',\n",
       "    'Universal Dependency Treebank',\n",
       "    'Universal Dependencies'],\n",
       "   'title': 'Universal Dependencies v1: A Multilingual Treebank Collection',\n",
       "   'url': 'https://paperswithcode.com/paper/universal-dependencies-v1-a-multilingual'},\n",
       "  'TallyQA': {'full_name': '',\n",
       "   'variants': ['TallyQA', 'TallyQA-Simple', 'TallyQA-Complex'],\n",
       "   'title': 'TallyQA: Answering Complex Counting Questions',\n",
       "   'url': 'https://paperswithcode.com/paper/tallyqa-answering-complex-counting-questions'},\n",
       "  'CrisisMMD': {'full_name': '',\n",
       "   'variants': ['CrisisMMD'],\n",
       "   'title': 'CrisisMMD: Multimodal Twitter Datasets from Natural Disasters',\n",
       "   'url': 'https://paperswithcode.com/paper/crisismmd-multimodal-twitter-datasets-from'},\n",
       "  'UAVA': {'full_name': 'UAV Assistant',\n",
       "   'variants': ['UAVA'],\n",
       "   'title': 'DronePose: Photorealistic UAV-Assistant Dataset Synthesis for 3D Pose Estimation via a Smooth Silhouette Loss',\n",
       "   'url': 'https://paperswithcode.com/paper/dronepose-photorealistic-uav-assistant'},\n",
       "  'Panoptic': {'full_name': 'CMU Panoptic Studio',\n",
       "   'variants': ['Panoptic'],\n",
       "   'title': 'Panoptic Studio: A Massively Multiview System for Social Motion Capture',\n",
       "   'url': 'https://paperswithcode.com/paper/panoptic-studio-a-massively-multiview-system-1'},\n",
       "  'Set5': {'full_name': '',\n",
       "   'variants': ['Set5-2x',\n",
       "    'Set5 - 8x upscaling',\n",
       "    'Set5 - 4x upscaling',\n",
       "    'Set5 - 3x upscaling',\n",
       "    'Set5 - 2x upscaling',\n",
       "    'Set5'],\n",
       "   'title': 'Low-Complexity Single-Image Super-Resolution based on Nonnegative Neighbor Embedding',\n",
       "   'url': 'https://doi.org/10.5244/C.26.135'},\n",
       "  'ContactPose': {'full_name': '',\n",
       "   'variants': ['ContactPose'],\n",
       "   'title': 'ContactPose: A Dataset of Grasps with Object Contact and Hand Pose',\n",
       "   'url': 'https://paperswithcode.com/paper/contactpose-a-dataset-of-grasps-with-object'},\n",
       "  'DHF1K': {'full_name': '',\n",
       "   'variants': ['DHF1K'],\n",
       "   'title': 'Revisiting Video Saliency: A Large-scale Benchmark and a New Model',\n",
       "   'url': 'https://paperswithcode.com/paper/revisiting-video-saliency-a-large-scale'},\n",
       "  'How2': {'full_name': '',\n",
       "   'variants': ['How2', 'How2 300h'],\n",
       "   'title': 'How2: A Large-scale Dataset for Multimodal Language Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/how2-a-large-scale-dataset-for-multimodal'},\n",
       "  'ASSET': {'full_name': 'ASSET',\n",
       "   'variants': ['ASSET'],\n",
       "   'title': 'ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations',\n",
       "   'url': 'https://paperswithcode.com/paper/asset-a-dataset-for-tuning-and-evaluation-of'},\n",
       "  'TurkCorpus': {'full_name': '',\n",
       "   'variants': ['TurkCorpus'],\n",
       "   'title': 'Optimizing Statistical Machine Translation for Text Simplification',\n",
       "   'url': 'https://paperswithcode.com/paper/optimizing-statistical-machine-translation'},\n",
       "  'IRMA': {'full_name': '15,363 IRMA images of 193 categories for ImageCLEFmed 2009',\n",
       "   'variants': [],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MLFP': {'full_name': 'Multispectral Latex Mask based Video Face Presentation Attack',\n",
       "   'variants': ['MLFP'],\n",
       "   'title': 'Face Presentation Attack with Latex Masks in Multispectral Videos',\n",
       "   'url': 'https://doi.org/10.1109/CVPRW.2017.40'},\n",
       "  'CoNLL++': {'full_name': '',\n",
       "   'variants': ['CoNLL03', 'CoNLL++'],\n",
       "   'title': 'CrossWeigh: Training Named Entity Tagger from Imperfect Annotations',\n",
       "   'url': 'https://paperswithcode.com/paper/crossweigh-training-named-entity-tagger-from'},\n",
       "  'SOC': {'full_name': 'Salient Objects in Clutter',\n",
       "   'variants': ['SOC'],\n",
       "   'title': 'Salient Objects in Clutter: Bringing Salient Object Detection to the Foreground',\n",
       "   'url': 'https://paperswithcode.com/paper/salient-objects-in-clutter-bringing-salient'},\n",
       "  'CoSal2015': {'full_name': 'CoSal2015',\n",
       "   'variants': ['CoSal2015'],\n",
       "   'title': 'Detection of Co-salient Objects by Looking Deep and Wide',\n",
       "   'url': 'https://doi.org/10.1007/s11263-016-0907-4'},\n",
       "  'SIP': {'full_name': 'Salient Person',\n",
       "   'variants': ['SIP'],\n",
       "   'title': 'Rethinking RGB-D Salient Object Detection: Models, Data Sets, and Large-Scale Benchmarks',\n",
       "   'url': 'https://paperswithcode.com/paper/rethinking-rgb-d-salient-object-detection'},\n",
       "  'NJU2K': {'full_name': None,\n",
       "   'variants': ['NJU2K'],\n",
       "   'title': 'Depth saliency based on anisotropic center-surround difference',\n",
       "   'url': 'https://doi.org/10.1109/ICIP.2014.7025222'},\n",
       "  'NLPR': {'full_name': '',\n",
       "   'variants': ['NLPR'],\n",
       "   'title': 'RGBD Salient Object Detection: A Benchmark and Algorithms',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-10578-9_7'},\n",
       "  'LFSD': {'full_name': 'Light Field Saliency Database',\n",
       "   'variants': ['LFSD'],\n",
       "   'title': 'Saliency Detection on Light Field',\n",
       "   'url': 'https://paperswithcode.com/paper/saliency-detection-on-light-field'},\n",
       "  'Cam2BEV': {'full_name': '',\n",
       "   'variants': ['Cam2BEV'],\n",
       "   'title': \"A Sim2Real Deep Learning Approach for the Transformation of Images from Multiple Vehicle-Mounted Cameras to a Semantically Segmented Image in Bird's Eye View\",\n",
       "   'url': 'https://paperswithcode.com/paper/a-sim2real-deep-learning-approach-for-the'},\n",
       "  'ssTEM': {'full_name': '',\n",
       "   'variants': ['ssTEM'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'VeRi-776': {'full_name': 'VeRi-776',\n",
       "   'variants': ['VeRi-776'],\n",
       "   'title': 'A Deep Learning-Based Approach to Progressive Vehicle Re-identification for Urban Surveillance',\n",
       "   'url': 'https://doi.org/10.1007/978-3-319-46475-6_53'},\n",
       "  'UNSW-NB15': {'full_name': 'UNSQ-NB15',\n",
       "   'variants': ['UNSW-NB15'],\n",
       "   'title': 'UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)',\n",
       "   'url': 'https://doi.org/10.1109/MilCIS.2015.7348942'},\n",
       "  'FarsTail': {'full_name': '',\n",
       "   'variants': ['FarsTail'],\n",
       "   'title': 'FarsTail: A Persian Natural Language Inference Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/farstail-a-persian-natural-language-inference'},\n",
       "  'CUHK-PEDES': {'full_name': 'CUHK-PEDES',\n",
       "   'variants': ['CUHK-PEDES'],\n",
       "   'title': 'Person Search with Natural Language Description',\n",
       "   'url': 'https://paperswithcode.com/paper/person-search-with-natural-language'},\n",
       "  'AND Dataset': {'full_name': '',\n",
       "   'variants': ['AND Dataset'],\n",
       "   'title': 'Explanation based Handwriting Verification',\n",
       "   'url': 'https://paperswithcode.com/paper/explanation-based-handwriting-verification'},\n",
       "  'Multi-dSprites': {'full_name': '',\n",
       "   'variants': ['Multi-dSprites'],\n",
       "   'title': 'MONet: Unsupervised Scene Decomposition and Representation',\n",
       "   'url': 'https://paperswithcode.com/paper/monet-unsupervised-scene-decomposition-and'},\n",
       "  'Object Discovery': {'full_name': '',\n",
       "   'variants': ['Object Discovery'],\n",
       "   'title': 'Unsupervised Joint Object Discovery and Segmentation in Internet Images',\n",
       "   'url': 'https://paperswithcode.com/paper/unsupervised-joint-object-discovery-and'},\n",
       "  'Open Entity': {'full_name': '',\n",
       "   'variants': [' Open Entity', 'Open Entity'],\n",
       "   'title': 'Ultra-Fine Entity Typing',\n",
       "   'url': 'https://paperswithcode.com/paper/ultra-fine-entity-typing'},\n",
       "  'RITE': {'full_name': 'Retinal Images vessel Tree Extraction',\n",
       "   'variants': ['RITE'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Contract Discovery': {'full_name': '',\n",
       "   'variants': ['Contract Discovery'],\n",
       "   'title': 'Contract Discovery: Dataset and a Few-Shot Semantic Retrieval Challenge with Competitive Baselines',\n",
       "   'url': 'https://paperswithcode.com/paper/searching-for-legal-clauses-by-analogy-few'},\n",
       "  'UI-PRMD': {'full_name': 'University of Idaho – Physical Rehabilitation Movement Dataset',\n",
       "   'variants': ['UI-PRMD'],\n",
       "   'title': 'A Deep Learning Framework for Assessing Physical Rehabilitation Exercises',\n",
       "   'url': 'https://paperswithcode.com/paper/a-deep-learning-framework-for-assessing'},\n",
       "  'TVR': {'full_name': 'TV show Retrieval',\n",
       "   'variants': ['TVR'],\n",
       "   'title': 'TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval',\n",
       "   'url': 'https://paperswithcode.com/paper/tvr-a-large-scale-dataset-for-video-subtitle'},\n",
       "  'TVQA': {'full_name': 'TVQA',\n",
       "   'variants': ['TVQA'],\n",
       "   'title': 'TVQA: Localized, Compositional Video Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/tvqa-localized-compositional-video-question'},\n",
       "  'DialogRE': {'full_name': '',\n",
       "   'variants': ['DialogRE'],\n",
       "   'title': 'Dialogue-Based Relation Extraction',\n",
       "   'url': 'https://paperswithcode.com/paper/dialogue-based-relation-extraction'},\n",
       "  'Tweebank': {'full_name': '',\n",
       "   'variants': ['Tweebank'],\n",
       "   'title': 'Parsing Tweets into Universal Dependencies',\n",
       "   'url': 'https://paperswithcode.com/paper/parsing-tweets-into-universal-dependencies'},\n",
       "  'WD50K': {'full_name': 'Wikidata 50K',\n",
       "   'variants': ['WD50K'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ScanObjectNN': {'full_name': '',\n",
       "   'variants': ['ScanObjectNN'],\n",
       "   'title': 'Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data',\n",
       "   'url': 'https://paperswithcode.com/paper/revisiting-point-cloud-classification-a-new'},\n",
       "  'COMA': {'full_name': 'COMA',\n",
       "   'variants': ['COMA'],\n",
       "   'title': 'Generating 3D faces using Convolutional Mesh Autoencoders',\n",
       "   'url': 'https://paperswithcode.com/paper/generating-3d-faces-using-convolutional-mesh'},\n",
       "  'ToLD-Br': {'full_name': 'Toxic Language Detection for Brazilian Portuguese',\n",
       "   'variants': ['ToLD-Br'],\n",
       "   'title': 'Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/toxic-language-detection-in-social-media-for'},\n",
       "  'MIMIC-CXR': {'full_name': 'MIMIC-CXR',\n",
       "   'variants': ['MIMIC-CXR'],\n",
       "   'title': 'MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs',\n",
       "   'url': 'https://paperswithcode.com/paper/mimic-cxr-a-large-publicly-available-database'},\n",
       "  'CheXpert': {'full_name': 'CheXpert',\n",
       "   'variants': ['CheXpert'],\n",
       "   'title': 'CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison',\n",
       "   'url': 'https://paperswithcode.com/paper/chexpert-a-large-chest-radiograph-dataset'},\n",
       "  'DeepFix': {'full_name': '',\n",
       "   'variants': ['DeepFix'],\n",
       "   'title': 'DeepFix: Fixing Common C Language Errors by Deep Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/deepfix-fixing-common-c-language-errors-by'},\n",
       "  'DUC 2004': {'full_name': 'DUC 2004',\n",
       "   'variants': ['DUC 2004 Task 1', 'DUC 2004'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CL-SciSumm': {'full_name': '',\n",
       "   'variants': ['CL-SciSumm'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'UT-Interaction': {'full_name': '',\n",
       "   'variants': ['UT-Interaction'],\n",
       "   'title': 'UT-Interaction Dataset, ICPR contest on Semantic Description of Human Activities (SDHA)',\n",
       "   'url': 'http://cvrc.ece.utexas.edu/SDHA2010/Human˙Interaction.html'},\n",
       "  'AVSD': {'full_name': 'Audio-Visual Scene-Aware Dialog',\n",
       "   'variants': ['AVSD'],\n",
       "   'title': 'Audio Visual Scene-Aware Dialog (AVSD) Challenge at DSTC7',\n",
       "   'url': 'https://paperswithcode.com/paper/audio-visual-scene-aware-dialog-avsd'},\n",
       "  'eQASC': {'full_name': 'eQASC',\n",
       "   'variants': ['eQASC'],\n",
       "   'title': 'Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-to-explain-datasets-and-models-for'},\n",
       "  'ImageNet-LT': {'full_name': 'ImageNet Long-Tailed',\n",
       "   'variants': ['ImageNet-LT', 'ImageNet-LT-d'],\n",
       "   'title': 'Large-Scale Long-Tailed Recognition in an Open World',\n",
       "   'url': 'https://paperswithcode.com/paper/large-scale-long-tailed-recognition-in-an'},\n",
       "  'Places-LT': {'full_name': '',\n",
       "   'variants': ['Places-LT'],\n",
       "   'title': 'Large-Scale Long-Tailed Recognition in an Open World',\n",
       "   'url': 'https://paperswithcode.com/paper/large-scale-long-tailed-recognition-in-an'},\n",
       "  'Salinas': {'full_name': 'Salinas Scene',\n",
       "   'variants': ['Salinas Scene', 'Salinas'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Math23K': {'full_name': 'Math23K for Math Word Problem Solving',\n",
       "   'variants': ['Math23K'],\n",
       "   'title': 'Deep Neural Solver for Math Word Problems',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-neural-solver-for-math-word-problems'},\n",
       "  'RST-DT': {'full_name': 'RST Discourse Treebank',\n",
       "   'variants': ['RST-DT'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SQA': {'full_name': 'SequentialQA',\n",
       "   'variants': ['SQA'],\n",
       "   'title': 'Search-based Neural Structured Learning for Sequential Question Answering',\n",
       "   'url': 'https://paperswithcode.com/paper/search-based-neural-structured-learning-for'},\n",
       "  'BC4CHEMD': {'full_name': 'BioCreative IV Chemical compound and drug name recognition',\n",
       "   'variants': ['BC4CHEMD'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SherLIiC': {'full_name': 'SherLIiC',\n",
       "   'variants': ['SherLIiC'],\n",
       "   'title': 'SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference',\n",
       "   'url': 'https://paperswithcode.com/paper/sherliic-a-typed-event-focused-lexical'},\n",
       "  'XCOPA': {'full_name': None,\n",
       "   'variants': ['XCOPA'],\n",
       "   'title': 'XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/xcopa-a-multilingual-dataset-for-causal'},\n",
       "  'DebateSum': {'full_name': None,\n",
       "   'variants': ['DebateSum'],\n",
       "   'title': 'DebateSum: A large-scale argument mining and summarization dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/debatesum-a-large-scale-argument-mining-and'},\n",
       "  'iSAID': {'full_name': '',\n",
       "   'variants': ['iSAID'],\n",
       "   'title': 'iSAID: A Large-scale Dataset for Instance Segmentation in Aerial Images',\n",
       "   'url': 'https://paperswithcode.com/paper/isaid-a-large-scale-dataset-for-instance'},\n",
       "  'RuDaS': {'full_name': 'Synthetic Datasets for Rule Learning',\n",
       "   'variants': ['RuDaS'],\n",
       "   'title': 'RuDaS: Synthetic Datasets for Rule Learning and Evaluation Tools',\n",
       "   'url': 'https://paperswithcode.com/paper/rudas-synthetic-datasets-for-rule-learning'},\n",
       "  'ReClor': {'full_name': '',\n",
       "   'variants': ['ReClor'],\n",
       "   'title': 'ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/reclor-a-reading-comprehension-dataset-1'},\n",
       "  'SEN12MS-CR': {'full_name': '',\n",
       "   'variants': ['SEN12MS-CR'],\n",
       "   'title': 'Multi-Sensor Data Fusion for Cloud Removal in Global and All-Season Sentinel-2 Imagery',\n",
       "   'url': 'https://paperswithcode.com/paper/multi-sensor-data-fusion-for-cloud-removal-in'},\n",
       "  'ConvAI2': {'full_name': 'Conversational Intelligence Challenge 2',\n",
       "   'variants': ['ConvAI2'],\n",
       "   'title': 'The Second Conversational Intelligence Challenge (ConvAI2)',\n",
       "   'url': 'https://paperswithcode.com/paper/the-second-conversational-intelligence'},\n",
       "  'EmpatheticDialogues': {'full_name': '',\n",
       "   'variants': ['EmpatheticDialogues'],\n",
       "   'title': 'Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/i-know-the-feeling-learning-to-converse-with'},\n",
       "  'Wizard of Wikipedia': {'full_name': '',\n",
       "   'variants': ['Wizard of Wikipedia'],\n",
       "   'title': 'Wizard of Wikipedia: Knowledge-Powered Conversational agents',\n",
       "   'url': 'https://paperswithcode.com/paper/wizard-of-wikipedia-knowledge-powered'},\n",
       "  'PPM-100': {'full_name': '',\n",
       "   'variants': ['PPM-100'],\n",
       "   'title': 'MODNet: Real-Time Trimap-Free Portrait Matting via Objective Decomposition',\n",
       "   'url': 'https://paperswithcode.com/paper/is-a-green-screen-really-necessary-for-real'},\n",
       "  'GoEmotions': {'full_name': 'GoEmotions',\n",
       "   'variants': ['GoEmotions', 'go_emotions'],\n",
       "   'title': 'GoEmotions: A Dataset of Fine-Grained Emotions',\n",
       "   'url': 'https://paperswithcode.com/paper/goemotions-a-dataset-of-fine-grained-emotions'},\n",
       "  'RecipeNLG': {'full_name': '',\n",
       "   'variants': ['RecipeNLG'],\n",
       "   'title': 'RecipeNLG: A Cooking Recipes Dataset for Semi-Structured Text Generation',\n",
       "   'url': 'https://paperswithcode.com/paper/recipenlg-a-cooking-recipes-dataset-for-semi'},\n",
       "  'DroneDeploy': {'full_name': '',\n",
       "   'variants': ['DroneDeploy'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'fastMRI': {'full_name': '',\n",
       "   'variants': ['fastMRI',\n",
       "    'fastMRI Knee 4x',\n",
       "    'fastMRI Knee 8x',\n",
       "    'fastMRI Brain 4x',\n",
       "    'fastMRI Brain 8x'],\n",
       "   'title': 'fastMRI: An Open Dataset and Benchmarks for Accelerated MRI',\n",
       "   'url': 'https://paperswithcode.com/paper/fastmri-an-open-dataset-and-benchmarks-for'},\n",
       "  'WHO-COVID19 Dataset': {'full_name': '',\n",
       "   'variants': ['WHO-COVID19 Dataset'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MAMS': {'full_name': 'Multi Aspect Multi-Sentiment',\n",
       "   'variants': ['MAMS'],\n",
       "   'title': 'A Challenge Dataset and Effective Models for Aspect-Based Sentiment Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/a-challenge-dataset-and-effective-models-for'},\n",
       "  'PEMS-BAY': {'full_name': '', 'variants': [], 'title': None, 'url': None},\n",
       "  'DDRel': {'full_name': None,\n",
       "   'variants': ['DDRel'],\n",
       "   'title': 'DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues',\n",
       "   'url': 'https://paperswithcode.com/paper/ddrel-a-new-dataset-for-interpersonal'},\n",
       "  'SYSU-MM01': {'full_name': 'SYSU-MM01',\n",
       "   'variants': ['SYSU-MM01'],\n",
       "   'title': 'RGB-Infrared Cross-Modality Person Re-Identification',\n",
       "   'url': 'https://paperswithcode.com/paper/rgb-infrared-cross-modality-person-re'},\n",
       "  'MusicNet': {'full_name': '',\n",
       "   'variants': ['MusicNet'],\n",
       "   'title': 'Learning Features of Music from Scratch',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-features-of-music-from-scratch'},\n",
       "  'HateXplain': {'full_name': '',\n",
       "   'variants': ['HateXplain'],\n",
       "   'title': 'HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection',\n",
       "   'url': 'https://paperswithcode.com/paper/hatexplain-a-benchmark-dataset-for'},\n",
       "  'RECCON': {'full_name': '',\n",
       "   'variants': ['RECCON'],\n",
       "   'title': 'Recognizing Emotion Cause in Conversations',\n",
       "   'url': 'https://paperswithcode.com/paper/recognizing-emotion-cause-in-conversations-1'},\n",
       "  'CANARD': {'full_name': 'A Dataset for Question-in-Context Rewriting',\n",
       "   'variants': ['CANARD'],\n",
       "   'title': 'Can You Unpack That? Learning to Rewrite Questions-in-Context',\n",
       "   'url': 'https://paperswithcode.com/paper/can-you-unpack-that-learning-to-rewrite'},\n",
       "  'RegDB': {'full_name': 'Dongguk Body-based Person Recognition Database (DBPerson-Recog-DB1)',\n",
       "   'variants': ['RegDB'],\n",
       "   'title': 'Deep Learning for Person Re-identification: A Survey and Outlook',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-learning-for-person-re-identification-a'},\n",
       "  'Kennedy Space Center': {'full_name': 'Kennedy Space Center',\n",
       "   'variants': ['Kennedy Space Center'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'VLCS': {'full_name': '', 'variants': [], 'title': None, 'url': None},\n",
       "  'CholecT40': {'full_name': 'Cholecystectomy Action Triplet',\n",
       "   'variants': [],\n",
       "   'title': 'Recognition of Instrument-Tissue Interactions in Endoscopic Videos via Action Triplets',\n",
       "   'url': 'https://paperswithcode.com/paper/recognition-of-instrument-tissue-interactions'},\n",
       "  'Cholec80': {'full_name': 'Surgical Workflow Dataset',\n",
       "   'variants': ['Cholec80'],\n",
       "   'title': 'EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic Videos',\n",
       "   'url': 'https://paperswithcode.com/paper/endonet-a-deep-architecture-for-recognition'},\n",
       "  'Multi-PIE': {'full_name': '',\n",
       "   'variants': ['Multi-PIE'],\n",
       "   'title': 'Multi-PIE',\n",
       "   'url': 'https://doi.org/10.1109/AFGR.2008.4813399'},\n",
       "  'The Pile': {'full_name': 'The Pile',\n",
       "   'variants': ['The Pile'],\n",
       "   'title': 'The Pile: An 800GB Dataset of Diverse Text for Language Modeling',\n",
       "   'url': 'https://paperswithcode.com/paper/the-pile-an-800gb-dataset-of-diverse-text-for'},\n",
       "  'ECB+': {'full_name': 'extension to the EventCorefBank',\n",
       "   'variants': ['ECB+ test', 'ECB+'],\n",
       "   'title': 'Using a sledgehammer to crack a nut? Lexical diversity and event coreference resolution',\n",
       "   'url': 'https://paperswithcode.com/paper/using-a-sledgehammer-to-crack-a-nut-lexical'},\n",
       "  'S2ORC': {'full_name': 'S2ORC',\n",
       "   'variants': ['S2ORC'],\n",
       "   'title': 'S2ORC: The Semantic Scholar Open Research Corpus',\n",
       "   'url': 'https://paperswithcode.com/paper/gorc-a-large-contextual-citation-graph-of'},\n",
       "  'DSD100': {'full_name': '',\n",
       "   'variants': ['DSD100'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'WebEdit': {'full_name': '',\n",
       "   'variants': ['WebEdit'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'RotoEdit': {'full_name': '',\n",
       "   'variants': ['RotoEdit'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'WebVision': {'full_name': '',\n",
       "   'variants': ['WebVision-1000', 'WebVision', 'mini WebVision 1.0'],\n",
       "   'title': 'WebVision Database: Visual Learning and Understanding from Web Data',\n",
       "   'url': 'https://paperswithcode.com/paper/webvision-database-visual-learning-and'},\n",
       "  'NASA Worldview': {'full_name': 'Understanding Clouds from Satellite Images',\n",
       "   'variants': ['NASA Worldview'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'CDD Dataset (season-varying)': {'full_name': '',\n",
       "   'variants': ['CDD Dataset (season-varying)'],\n",
       "   'title': 'CHANGE DETECTION IN REMOTE SENSING IMAGES USING CONDITIONAL ADVERSARIAL NETWORKS',\n",
       "   'url': 'https://paperswithcode.com/paper/change-detection-in-remote-sensing-images'},\n",
       "  'LabelMe': {'full_name': '',\n",
       "   'variants': ['LabelMe'],\n",
       "   'title': 'LabelMe: A Database and Web-Based Tool for Image Annotation',\n",
       "   'url': 'https://people.csail.mit.edu/brussell/research/AIM-2005-025-new.pdf'},\n",
       "  'ICT-3DHP': {'full_name': '',\n",
       "   'variants': ['ICT-3DHP'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ETH': {'full_name': 'ETH Pedestrian',\n",
       "   'variants': ['ETH BIWI Walking Pedestrians dataset', 'ETH/UCY', 'ETH'],\n",
       "   'title': 'Depth and Appearance for Mobile Scene Analysis',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2007.4409092'},\n",
       "  'UCY': {'full_name': '',\n",
       "   'variants': ['UCY'],\n",
       "   'title': 'Crowds by Example',\n",
       "   'url': 'https://doi.org/10.1111/j.1467-8659.2007.01089.x'},\n",
       "  'IAM': {'full_name': 'IAM Handwriting',\n",
       "   'variants': ['IAM'],\n",
       "   'title': 'The IAM-database: an English sentence database for offline handwriting recognition',\n",
       "   'url': 'https://doi.org/10.1007/s100320200071'},\n",
       "  'WebKB': {'full_name': 'WebKB',\n",
       "   'variants': ['WebKB', 'Cornell', 'Texas', 'Wisconsin'],\n",
       "   'title': 'Learning to Extract Symbolic Knowledge from the World Wide Web',\n",
       "   'url': 'http://www.aaai.org/Library/AAAI/1998/aaai98-072.php'},\n",
       "  'MemeTracker': {'full_name': 'MemeTracker',\n",
       "   'variants': ['MemeTracker'],\n",
       "   'title': 'Meme-tracking and the dynamics of the news cycle',\n",
       "   'url': 'https://doi.org/10.1145/1557019.1557077'},\n",
       "  'English Web Treebank': {'full_name': 'English Web Treebank',\n",
       "   'variants': ['English Web Treebank'],\n",
       "   'title': 'English web treebank',\n",
       "   'url': 'http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=L%DC2012T13'},\n",
       "  'Silhouettes': {'full_name': 'CalTech 101 Silhouettes',\n",
       "   'variants': ['Silhouettes'],\n",
       "   'title': 'Inductive Principles for Restricted Boltzmann Machine Learning',\n",
       "   'url': 'http://proceedings.mlr.press/v9/marlin10a.html'},\n",
       "  'ETH SfM': {'full_name': 'ETH Structure-from-Motion',\n",
       "   'variants': ['ETH SfM'],\n",
       "   'title': 'Comparative Evaluation of Hand-Crafted and Learned Local Features',\n",
       "   'url': 'https://paperswithcode.com/paper/comparative-evaluation-of-hand-crafted-and-1'},\n",
       "  'INRIA Person': {'full_name': '',\n",
       "   'variants': ['INRIA Person'],\n",
       "   'title': 'Histograms of Oriented Gradients for Human Detection',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2005.177'},\n",
       "  'INRIA-Horse': {'full_name': 'INRIA-Horse',\n",
       "   'variants': ['INRIA-Horse'],\n",
       "   'title': 'Scale-Invariant Shape Features for Recognition of Object Categories',\n",
       "   'url': 'http://doi.ieeecomputersociety.org/10.1109/CVPR.2004.218'},\n",
       "  'INRIA Aerial Image Labeling': {'full_name': 'INRIA Aerial Image Labeling',\n",
       "   'variants': ['INRIA Aerial Image Labeling'],\n",
       "   'title': 'Very Deep Convolutional Networks for Large-Scale Image Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/very-deep-convolutional-networks-for-large'},\n",
       "  'Office-Caltech-10': {'full_name': 'Office-Caltech-10',\n",
       "   'variants': ['Office-Caltech-10'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Poser': {'full_name': 'Poser',\n",
       "   'variants': ['Poser'],\n",
       "   'title': 'Recovering 3D Human Pose from Monocular Images',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2006.21'},\n",
       "  'UKP': {'full_name': 'UKP Argument Annotated Essays',\n",
       "   'variants': ['UKP'],\n",
       "   'title': 'Annotating Argument Components and Relations in Persuasive Essays',\n",
       "   'url': 'https://paperswithcode.com/paper/annotating-argument-components-and-relations'},\n",
       "  'ETH BIWI Walking Pedestrians': {'full_name': 'ETH BIWI Walking Pedestrians',\n",
       "   'variants': ['ETH BIWI Walking Pedestrians'],\n",
       "   'title': \"You'll never walk alone: Modeling social behavior for multi-target tracking\",\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2009.5459260'},\n",
       "  'WASABI': {'full_name': 'WASABI',\n",
       "   'variants': ['WASABI'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Multilingual Reuters': {'full_name': 'Multilingual Reuters Collection',\n",
       "   'variants': ['Multilingual Reuters'],\n",
       "   'title': 'Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-from-multiple-partially-observed'},\n",
       "  'Pan+ChiPhoto': {'full_name': 'Pan+ChiPhoto',\n",
       "   'variants': ['Pan+ChiPhoto'],\n",
       "   'title': 'Multilingual scene character recognition with co-occurrence of histogram of oriented gradients',\n",
       "   'url': 'https://doi.org/10.1016/j.patcog.2015.07.009'},\n",
       "  'ISI_Bengali_Character': {'full_name': 'ISI_Bengali_Character',\n",
       "   'variants': ['ISI_Bengali_Character'],\n",
       "   'title': 'Multilingual scene character recognition with co-occurrence of histogram of oriented gradients',\n",
       "   'url': 'https://doi.org/10.1016/j.patcog.2015.07.009'},\n",
       "  'Florentine': {'full_name': 'Florentine',\n",
       "   'variants': ['Florentine'],\n",
       "   'title': 'Combining Multiple Kernel Methods on Riemannian Manifold for Emotion Recognition in the Wild',\n",
       "   'url': 'https://doi.org/10.1145/2663204.2666274'},\n",
       "  'INRIA DLFD': {'full_name': 'INRIA Dense Light Field',\n",
       "   'variants': ['INRIA DLFD'],\n",
       "   'title': 'A Framework for Learning Depth From a Flexible Subset of Dense and Sparse Light Field Views',\n",
       "   'url': 'https://doi.org/10.1109/TIP.2019.2923323'},\n",
       "  'INRIA SLFD': {'full_name': 'INRIA Sparse Light Field',\n",
       "   'variants': ['INRIA SLFD'],\n",
       "   'title': 'A Framework for Learning Depth From a Flexible Subset of Dense and Sparse Light Field Views',\n",
       "   'url': 'https://doi.org/10.1109/TIP.2019.2923323'},\n",
       "  'AIDS Antiviral Screen': {'full_name': 'AIDS Antiviral Screen',\n",
       "   'variants': ['HIV dataset', 'AIDS Antiviral Screen'],\n",
       "   'title': 'IAM Graph Database Repository for Graph Based Pattern Recognition and Machine Learning',\n",
       "   'url': 'https://doi.org/10.1007/978-3-540-89689-0_33'},\n",
       "  'Retinal Microsurgery': {'full_name': 'Retinal Microsurgery',\n",
       "   'variants': ['Retinal Microsurgery'],\n",
       "   'title': 'Real-time localization of articulated surgical instruments in retinal microsurgery',\n",
       "   'url': 'https://doi.org/10.1016/j.media.2016.05.003'},\n",
       "  'Daimler Monocular Pedestrian Detection': {'full_name': 'Daimler Monocular Pedestrian Detection',\n",
       "   'variants': ['Daimler Monocular Pedestrian Detection'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ETHZ-Shape': {'full_name': 'ETHZ-Shape',\n",
       "   'variants': ['ETHZ-Shape'],\n",
       "   'title': 'Groups of Adjacent Contour Segments for Object Detection',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2007.1144'},\n",
       "  'L-Bird': {'full_name': 'Large-Bird',\n",
       "   'variants': ['L-Bird'],\n",
       "   'title': 'The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/the-unreasonable-effectiveness-of-noisy-data'},\n",
       "  'Extended BBC Pose': {'full_name': 'Extended BBC Pose',\n",
       "   'variants': ['Extended BBC Pose'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Short BBC Pose': {'full_name': 'Short BBC Pose',\n",
       "   'variants': ['Short BBC Pose'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ChaLearn Pose': {'full_name': 'ChaLearn Pose',\n",
       "   'variants': ['ChaLearn Pose'],\n",
       "   'title': 'Multi-modal Gesture Recognition Challenge 2013: Dataset and Results',\n",
       "   'url': 'http://refbase.cvc.uab.es/files/EGB2013.pdf'},\n",
       "  'VoxCeleb2': {'full_name': 'VoxCeleb2',\n",
       "   'variants': ['VoxCeleb2 - 1-shot learning',\n",
       "    'VoxCeleb2 - 8-shot learning',\n",
       "    'VoxCeleb2 - 32-shot learning',\n",
       "    'VoxCeleb2'],\n",
       "   'title': 'VoxCeleb2: Deep Speaker Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/voxceleb2-deep-speaker-recognition'},\n",
       "  'VCTK': {'full_name': 'CSTR VCTK Corpus',\n",
       "   'variants': ['Voice Bank corpus (VCTK)', 'VCTK Multi-Speaker', 'VCTK'],\n",
       "   'title': 'CSTR VCTK corpus: English multi-speaker corpus for CSTR voice cloning toolkit',\n",
       "   'url': 'http://dx.doi.org/10.7488/ds/1994'},\n",
       "  'DIRHA': {'full_name': 'Distant-speech Interaction for Robust Home Applications',\n",
       "   'variants': ['DIRHA English WSJ', 'DIRHA'],\n",
       "   'title': 'The DIRHA-English corpus and related tasks for distant-speech recognition in domestic environments',\n",
       "   'url': 'https://paperswithcode.com/paper/the-dirha-english-corpus-and-related-tasks'},\n",
       "  'VoxForge': {'full_name': 'VoxForge',\n",
       "   'variants': ['VoxForge American-Canadian',\n",
       "    'VoxForge Commonwealth',\n",
       "    'VoxForge European',\n",
       "    'VoxForge Indian',\n",
       "    'VoxForge'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Penn Action': {'full_name': '',\n",
       "   'variants': ['UPenn Action', 'Penn Action'],\n",
       "   'title': 'From Actemes to Action: A Strongly-Supervised Representation for Detailed Action Understanding',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2013.280'},\n",
       "  'TVSum': {'full_name': 'Title-based Video Summarization Dataset',\n",
       "   'variants': ['TvSum', 'TVSum'],\n",
       "   'title': 'TVSum: Summarizing Web Videos Using Titles',\n",
       "   'url': 'https://paperswithcode.com/paper/tvsum-summarizing-web-videos-using-titles'},\n",
       "  'FLIC': {'full_name': 'Frames Labelled in Cinema',\n",
       "   'variants': ['FLIC Elbows', 'FLIC Wrists', 'FLIC'],\n",
       "   'title': 'MODEC: Multimodal Decomposable Models for Human Pose Estimation',\n",
       "   'url': 'https://paperswithcode.com/paper/modec-multimodal-decomposable-models-for'},\n",
       "  'WikiArt': {'full_name': '',\n",
       "   'variants': ['Wikiart (Fine-grained 6 Tasks)', 'WikiArt'],\n",
       "   'title': 'Large-scale Classification of Fine-Art Paintings: Learning The Right Metric on The Right Feature',\n",
       "   'url': 'https://paperswithcode.com/paper/large-scale-classification-of-fine-art'},\n",
       "  'Sim10k': {'full_name': '',\n",
       "   'variants': ['SIM10K to Cityscapes', 'SIM10K to BDD100K', 'Sim10k'],\n",
       "   'title': 'Driving in the Matrix: Can Virtual Worlds Replace Human-Generated Annotations for Real World Tasks?',\n",
       "   'url': 'https://paperswithcode.com/paper/driving-in-the-matrix-can-virtual-worlds'},\n",
       "  'EYEDIAP': {'full_name': '',\n",
       "   'variants': ['EYEDIAP (screen target)',\n",
       "    'EYEDIAP (floating target)',\n",
       "    'EYEDIAP'],\n",
       "   'title': 'EYEDIAP: a database for the development and evaluation of gaze estimation algorithms from RGB and RGB-D cameras',\n",
       "   'url': 'https://doi.org/10.1145/2578153.2578190'},\n",
       "  'G3D': {'full_name': 'Gaming 3D Dataset',\n",
       "   'variants': ['Gaming 3D (G3D)', 'G3D'],\n",
       "   'title': 'G3D: A gaming action dataset and real time action recognition evaluation framework',\n",
       "   'url': 'https://doi.org/10.1109/CVPRW.2012.6239175'},\n",
       "  'O-HAZE': {'full_name': '',\n",
       "   'variants': ['O-Haze', 'O-HAZE'],\n",
       "   'title': 'O-HAZE: a dehazing benchmark with real hazy and haze-free outdoor images',\n",
       "   'url': 'https://paperswithcode.com/paper/o-haze-a-dehazing-benchmark-with-real-hazy'},\n",
       "  'UMIST': {'full_name': None,\n",
       "   'variants': ['UMist', 'UMIST'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'FC100': {'full_name': 'Fewshot-CIFAR100',\n",
       "   'variants': ['Fewshot-CIFAR100 - 5-Shot Learning',\n",
       "    'Fewshot-CIFAR100 - 10-Shot Learning',\n",
       "    'Fewshot-CIFAR100 - 1-Shot Learning',\n",
       "    'FC100 5-way (10-shot)',\n",
       "    'FC100',\n",
       "    'FC100 5-way (5-shot)',\n",
       "    'FC100 5-way (1-shot)'],\n",
       "   'title': 'TADAM: Task dependent adaptive metric for improved few-shot learning',\n",
       "   'url': 'https://paperswithcode.com/paper/tadam-task-dependent-adaptive-metric-for'},\n",
       "  'PASCAL-5i': {'full_name': '',\n",
       "   'variants': ['Pascal5i', 'PASCAL-5i'],\n",
       "   'title': 'One-Shot Learning for Semantic Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/one-shot-learning-for-semantic-segmentation'},\n",
       "  'TrajNet': {'full_name': '',\n",
       "   'variants': ['TrajNet++', 'TrajNet'],\n",
       "   'title': 'An Evaluation of Trajectory Prediction Approaches and Notes on the TrajNet Benchmark',\n",
       "   'url': 'https://paperswithcode.com/paper/an-evaluation-of-trajectory-prediction'},\n",
       "  'Set12': {'full_name': '',\n",
       "   'variants': ['Set12',\n",
       "    'Set12 sigma70',\n",
       "    'Set12 sigma50',\n",
       "    'Set12 sigma30',\n",
       "    'Set12 sigma25',\n",
       "    'Set12 sigma15'],\n",
       "   'title': 'Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising',\n",
       "   'url': 'https://paperswithcode.com/paper/beyond-a-gaussian-denoiser-residual-learning'},\n",
       "  'TotalCapture': {'full_name': '',\n",
       "   'variants': ['Total Capture', 'TotalCapture'],\n",
       "   'title': 'Total capture: 3D human pose estimation fusing video and inertial sensors',\n",
       "   'url': 'https://paperswithcode.com/paper/total-capture-3d-human-pose-estimation-fusing'},\n",
       "  'I-HAZE': {'full_name': None,\n",
       "   'variants': ['I-Haze', 'I-HAZE'],\n",
       "   'title': 'I-HAZE: a dehazing benchmark with real hazy and haze-free indoor images',\n",
       "   'url': 'https://paperswithcode.com/paper/i-haze-a-dehazing-benchmark-with-real-hazy'},\n",
       "  'SEED': {'full_name': 'SJTU Emotion EEG Dataset',\n",
       "   'variants': ['SEED-IV', '\\u3000SEED', 'SEED'],\n",
       "   'title': 'Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks',\n",
       "   'url': 'https://paperswithcode.com/paper/investigating-critical-frequency-bands-and'},\n",
       "  'SHREC': {'full_name': 'SHape REtrieval Contest',\n",
       "   'variants': ['DHG-28',\n",
       "    'DHG-14',\n",
       "    'SHREC11, Split16-4',\n",
       "    'SHREC',\n",
       "    'SHREC 2017',\n",
       "    'SHREC15',\n",
       "    'SHREC 2017 track on 3D Hand Gesture Recognition'],\n",
       "   'title': 'A comparison of 3D shape retrieval methods based on a large-scale benchmark supporting multimodal queries',\n",
       "   'url': 'https://doi.org/10.1016/j.cviu.2014.10.006'},\n",
       "  'Florence3D': {'full_name': '',\n",
       "   'variants': ['Florence 3D', 'Florence3D'],\n",
       "   'title': 'Recognizing Actions from Depth Cameras as Weakly Aligned Multi-part Bag-of-Poses',\n",
       "   'url': 'https://doi.org/10.1109/CVPRW.2013.77'},\n",
       "  'SNAP': {'full_name': 'Stanford Large Network Dataset Collection',\n",
       "   'variants': ['SNAP'],\n",
       "   'title': 'SNAP Datasets: Stanford large network dataset collection',\n",
       "   'url': 'http://snap.stanford.edu/data'},\n",
       "  'BioASQ': {'full_name': 'Biomedical Semantic Indexing and Question Answering',\n",
       "   'variants': ['BioASQ', 'BioASQ (BEIR)'],\n",
       "   'title': 'An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition',\n",
       "   'url': 'https://doi.org/10.1186/s12859-015-0564-6'},\n",
       "  'STRING': {'full_name': 'STRING',\n",
       "   'variants': ['STRING'],\n",
       "   'title': 'STRING v10: protein-protein interaction networks, integrated over the tree of life',\n",
       "   'url': 'https://doi.org/10.1093/nar/gku1003'},\n",
       "  'OpenWebText': {'full_name': '',\n",
       "   'variants': ['OpenWebText'],\n",
       "   'title': 'OpenWebText corpus',\n",
       "   'url': 'http://Skylion007.github.io/OpenWebTextCorpus'},\n",
       "  'Foursquare': {'full_name': None,\n",
       "   'variants': ['Foursquare'],\n",
       "   'title': 'Participatory Cultural Mapping Based on Collective Behavior Data in Location-Based Social Networks',\n",
       "   'url': 'https://doi.org/10.1145/2814575'},\n",
       "  'PeerRead': {'full_name': None,\n",
       "   'variants': ['PeerRead'],\n",
       "   'title': 'A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications',\n",
       "   'url': 'https://paperswithcode.com/paper/a-dataset-of-peer-reviews-peerread-collection'},\n",
       "  'Kinship': {'full_name': None,\n",
       "   'variants': ['Kinship'],\n",
       "   'title': 'Learning distributed representations of concepts',\n",
       "   'url': 'https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.408.7684&rep=rep1&type=pdf'},\n",
       "  'Mindboggle': {'full_name': '',\n",
       "   'variants': ['Mindboggle'],\n",
       "   'title': 'Mindboggling morphometry of human brains',\n",
       "   'url': 'https://doi.org/10.1371/journal.pcbi.1005350'},\n",
       "  'Learning to Rank Challenge': {'full_name': 'Yahoo! Learning to Rank Challenge',\n",
       "   'variants': ['Learning to Rank Challenge'],\n",
       "   'title': 'Yahoo! Learning to Rank Challenge Overview',\n",
       "   'url': 'http://proceedings.mlr.press/v14/chapelle11a.html'},\n",
       "  'Linux': {'full_name': 'Linux Program Dependence Graphs',\n",
       "   'variants': ['Linux'],\n",
       "   'title': 'An Efficient Graph Indexing Method',\n",
       "   'url': 'https://doi.org/10.1109/ICDE.2012.28'},\n",
       "  'AMiner': {'full_name': '',\n",
       "   'variants': ['AMiner'],\n",
       "   'title': 'ArnetMiner: extraction and mining of academic social networks',\n",
       "   'url': 'https://doi.org/10.1145/1401890.1402008'},\n",
       "  'Email-EU': {'full_name': None,\n",
       "   'variants': ['Email-EU'],\n",
       "   'title': 'Local Higher-Order Graph Clustering',\n",
       "   'url': 'https://doi.org/10.1145/3097983.3098069'},\n",
       "  'IMDB-BINARY': {'full_name': '',\n",
       "   'variants': ['IMDb-B', 'IMDB-BINARY'],\n",
       "   'title': 'Deep Graph Kernels',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-graph-kernels'},\n",
       "  'NCBI Disease': {'full_name': '',\n",
       "   'variants': ['NCBI-disease', 'NCBI Disease', 'ncbi_disease'],\n",
       "   'title': 'NCBI disease corpus: A resource for disease name recognition and concept normalization',\n",
       "   'url': 'http://dx.doi.org/10.1016/j.jbi.2013.12.006'},\n",
       "  'arXiv Astro-Ph': {'full_name': 'arXiv Astro Physics',\n",
       "   'variants': ['arXiv-AstroPh 2-clique',\n",
       "    'arXiv-AstroPh 4-clique',\n",
       "    'arXiv Astro-Ph'],\n",
       "   'title': 'SNAP Datasets: Stanford large network dataset collection',\n",
       "   'url': 'http://snap.stanford.edu/data'},\n",
       "  'MSLR-WEB10K': {'full_name': '',\n",
       "   'variants': ['MSLR-WEB10K'],\n",
       "   'title': 'Introducing LETOR 4.0 Datasets',\n",
       "   'url': 'https://paperswithcode.com/paper/13062597'},\n",
       "  'BeerAdvocate': {'full_name': '',\n",
       "   'variants': ['BeerAdvocate'],\n",
       "   'title': 'From Amateurs to Connoisseurs: Modeling the Evolution of User Expertise through Online Reviews',\n",
       "   'url': 'https://paperswithcode.com/paper/from-amateurs-to-connoisseurs-modeling-the'},\n",
       "  'Epinion': {'full_name': None,\n",
       "   'variants': ['Epinions-Extend', 'Epinion'],\n",
       "   'title': 'eTrust: understanding trust evolution in an online world',\n",
       "   'url': 'https://doi.org/10.1145/2339530.2339574'},\n",
       "  'Stanford Light Field': {'full_name': '',\n",
       "   'variants': ['Stanford Light Field'],\n",
       "   'title': 'The (New) Stanford Light Field Archive',\n",
       "   'url': 'http://lightfield.stanford.edu/'},\n",
       "  'Arxiv GR-QC': {'full_name': 'General Relativity and Quantum Cosmology collaboration network',\n",
       "   'variants': ['arXiv-GrQc 2-clique', 'arXiv-GrQc 3-clique', 'Arxiv GR-QC'],\n",
       "   'title': 'Graph evolution: Densification and shrinking diameters',\n",
       "   'url': 'https://doi.org/10.1145/1217299.1217301'},\n",
       "  'Orkut': {'full_name': '',\n",
       "   'variants': ['Orkut'],\n",
       "   'title': 'Defining and Evaluating Network Communities based on Ground-truth',\n",
       "   'url': 'https://paperswithcode.com/paper/defining-and-evaluating-network-communities'},\n",
       "  'Friendster': {'full_name': '',\n",
       "   'variants': ['Friendster'],\n",
       "   'title': 'Defining and Evaluating Network Communities based on Ground-truth',\n",
       "   'url': 'https://paperswithcode.com/paper/defining-and-evaluating-network-communities'},\n",
       "  'MQ2008': {'full_name': '',\n",
       "   'variants': ['MQ2008'],\n",
       "   'title': 'Introducing LETOR 4.0 Datasets',\n",
       "   'url': 'https://paperswithcode.com/paper/13062597'},\n",
       "  'IMDB-MULTI': {'full_name': '',\n",
       "   'variants': ['IMDb-M', 'IMDB-MULTI'],\n",
       "   'title': 'Deep Graph Kernels',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-graph-kernels'},\n",
       "  'REDDIT-12K': {'full_name': '',\n",
       "   'variants': ['REDDIT-12K'],\n",
       "   'title': 'Deep Graph Kernels',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-graph-kernels'},\n",
       "  'REDDIT-BINARY': {'full_name': '',\n",
       "   'variants': ['REDDIT-BINARY'],\n",
       "   'title': 'Deep Graph Kernels',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-graph-kernels'},\n",
       "  'MQ2007': {'full_name': '',\n",
       "   'variants': ['MQ2007'],\n",
       "   'title': 'Introducing LETOR 4.0 Datasets',\n",
       "   'url': 'https://paperswithcode.com/paper/13062597'},\n",
       "  'Amazon Fine Foods': {'full_name': '',\n",
       "   'variants': ['Amazon Fine Foods'],\n",
       "   'title': 'From Amateurs to Connoisseurs: Modeling the Evolution of User Expertise through Online Reviews',\n",
       "   'url': 'https://paperswithcode.com/paper/from-amateurs-to-connoisseurs-modeling-the'},\n",
       "  'REDDIT-5K': {'full_name': 'REDDIT-MULTI-5K',\n",
       "   'variants': ['REDDIT-MULTI-5k', 'REDDIT-5K'],\n",
       "   'title': 'Deep Graph Kernels',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-graph-kernels'},\n",
       "  'LastFM Asia': {'full_name': '',\n",
       "   'variants': ['LastFM Asia'],\n",
       "   'title': 'Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models',\n",
       "   'url': 'https://paperswithcode.com/paper/characteristic-functions-on-graphs-birds-of-a'},\n",
       "  'EMNIST': {'full_name': 'Extended MNIST',\n",
       "   'variants': ['EMNIST-Bymerge',\n",
       "    'EMNIST-Byclass',\n",
       "    'EMNIST',\n",
       "    'EMNIST-Digits',\n",
       "    'EMNIST-Balanced',\n",
       "    'EMNIST-Letters'],\n",
       "   'title': 'EMNIST: an extension of MNIST to handwritten letters',\n",
       "   'url': 'https://paperswithcode.com/paper/emnist-an-extension-of-mnist-to-handwritten'},\n",
       "  'Arcade Learning Environment': {'full_name': 'Arcade Learning Environment',\n",
       "   'variants': ['Atari 2600 Breakout',\n",
       "    'Arcade Learning Environment',\n",
       "    'Atari 2600 Yars Revenge',\n",
       "    'Atari 2600 Wizard of Wor',\n",
       "    'Atari 2600 Video Pinball',\n",
       "    'Atari 2600 Up and Down',\n",
       "    'Atari 2600 Tutankham',\n",
       "    'Atari 2600 Time Pilot',\n",
       "    'Atari 2600 Surround',\n",
       "    'Atari 2600 Space Invaders',\n",
       "    'Atari 2600 Seaquest',\n",
       "    'Atari 2600 Robotank',\n",
       "    'Atari 2600 Road Runner',\n",
       "    'Atari 2600 River Raid',\n",
       "    'Atari 2600 Private Eye',\n",
       "    'Atari 2600 Pitfall!',\n",
       "    'Atari 2600 Name This Game',\n",
       "    'Atari 2600 Ms. Pacman',\n",
       "    \"Atari 2600 Montezuma's Revenge\",\n",
       "    'Atari 2600 Kung-Fu Master',\n",
       "    'Atari 2600 Kangaroo',\n",
       "    'Atari 2600 Journey Escape',\n",
       "    'Atari 2600 James Bond',\n",
       "    'Atari 2600 Ice Hockey',\n",
       "    'Atari 2600 Gravitar',\n",
       "    'Atari 2600 Frostbite',\n",
       "    'Atari 2600 Freeway',\n",
       "    'Atari 2600 Fishing Derby',\n",
       "    'Atari 2600 Elevator Action',\n",
       "    'Atari 2600 Double Dunk',\n",
       "    'Atari 2600 Demon Attack',\n",
       "    'Atari 2600 Crazy Climber',\n",
       "    'Atari 2600 Chopper Command',\n",
       "    'Atari 2600 Centipede',\n",
       "    'Atari 2600 Carnival',\n",
       "    'Atari 2600 Beam Rider',\n",
       "    'Atari 2600 Battle Zone',\n",
       "    'Atari 2600 Bank Heist',\n",
       "    'Atari 2600 Atlantis',\n",
       "    'Atari 2600 Asteroids',\n",
       "    'Atari 2600 Assault',\n",
       "    'Atari-57',\n",
       "    'Atari 2600 Zaxxon',\n",
       "    'Atari 2600 Venture',\n",
       "    'Atari 2600 Tennis',\n",
       "    'Atari 2600 Skiing',\n",
       "    'Atari 2600 Q*Bert',\n",
       "    'Atari 2600 Pooyan',\n",
       "    'Atari 2600 Pong',\n",
       "    'Atari 2600 Phoenix',\n",
       "    'Atari 2600 Krull',\n",
       "    'Atari 2600 HERO',\n",
       "    'Atari 2600 Gopher',\n",
       "    'Atari 2600 Bowling',\n",
       "    'Atari 2600 Berzerk',\n",
       "    'Atari 2600 Amidar',\n",
       "    'Atari 2600 Alien'],\n",
       "   'title': 'The Arcade Learning Environment: An Evaluation Platform for General Agents',\n",
       "   'url': 'https://paperswithcode.com/paper/the-arcade-learning-environment-an-evaluation'},\n",
       "  'MedleyDB': {'full_name': '',\n",
       "   'variants': ['MedleyDB'],\n",
       "   'title': 'MedleyDB: A Multitrack Dataset for Annotation-Intensive MIR Research',\n",
       "   'url': 'http://www.terasoft.com.tw/conf/ismir2014/proceedings/T028_322_Paper.pdf'},\n",
       "  'MedleyDB 2.0': {'full_name': None,\n",
       "   'variants': ['MedleyDB 2.0'],\n",
       "   'title': 'MedleyDB 2.0: New Data and a System for Sustainable Data Collection',\n",
       "   'url': 'https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/bittner-medleydb.pdf'},\n",
       "  'MIR-1K': {'full_name': '',\n",
       "   'variants': ['MIR-1K'],\n",
       "   'title': 'On the Improvement of Singing Voice Separation for Monaural Recordings Using the MIR-1K Dataset',\n",
       "   'url': 'https://doi.org/10.1109/TASL.2009.2026503'},\n",
       "  'MagnaTagATune': {'full_name': '',\n",
       "   'variants': ['MagnaTagATune'],\n",
       "   'title': 'Evaluation of Algorithms Using Games: The Case of Music Tagging',\n",
       "   'url': 'http://ismir2009.ismir.net/proceedings/OS5-5.pdf'},\n",
       "  'Lakh MIDI Dataset': {'full_name': '',\n",
       "   'variants': ['Lakh MIDI Dataset'],\n",
       "   'title': 'Learning-Based Methods for Comparing Sequences, with Applications to Audio-to-MIDI Alignment and Matching',\n",
       "   'url': 'http://colinraffel.com/publications/thesis.pdf'},\n",
       "  'iKala': {'full_name': '',\n",
       "   'variants': ['iKala'],\n",
       "   'title': 'Vocal activity informed singing voice separation with the iKala dataset',\n",
       "   'url': 'https://doi.org/10.1109/ICASSP.2015.7178063'},\n",
       "  'CAL500': {'full_name': 'Computer Audition Lab 500',\n",
       "   'variants': ['CAL500'],\n",
       "   'title': 'Semantic Annotation and Retrieval of Music and Sound Effects',\n",
       "   'url': 'https://doi.org/10.1109/TASL.2007.913750'},\n",
       "  'URMP': {'full_name': 'University of Rochester Multi-Modal Musical Performance',\n",
       "   'variants': ['URMP'],\n",
       "   'title': 'Creating a Multitrack Classical Music Performance Dataset for Multimodal Music Analysis: Challenges, Insights, and Applications',\n",
       "   'url': 'https://doi.org/10.1109/TMM.2018.2856090'},\n",
       "  'FMA': {'full_name': 'Free Music Archive',\n",
       "   'variants': ['Free Music Archive', 'FMA'],\n",
       "   'title': 'FMA: A Dataset For Music Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/fma-a-dataset-for-music-analysis'},\n",
       "  'CCMixter': {'full_name': None,\n",
       "   'variants': ['CCMixter'],\n",
       "   'title': 'Kernel Additive Models for Source Separation',\n",
       "   'url': 'https://doi.org/10.1109/TSP.2014.2332434'},\n",
       "  'GoodSounds': {'full_name': None,\n",
       "   'variants': ['GoodSounds'],\n",
       "   'title': 'A real-time system for measuring sound goodness in instrumental sounds',\n",
       "   'url': 'http://mtg.upf.edu/node/3197'},\n",
       "  'Jamendo Corpus': {'full_name': None,\n",
       "   'variants': ['Jamendo Corpus'],\n",
       "   'title': 'Vocal detection in music with support vector machines',\n",
       "   'url': 'https://perso.telecom-paristech.fr/grichard/Publications/Icassp08_ramona.pdf'},\n",
       "  'ForeDeCk': {'full_name': None,\n",
       "   'variants': ['ForeDeCk'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'M4': {'full_name': '',\n",
       "   'variants': ['M4'],\n",
       "   'title': 'The M4 competition: Results, findings, conclusion and way forward',\n",
       "   'url': 'https://doi.org/10.1016/j.ijforecast.2018.06.001'},\n",
       "  'MUSDB18-HQ': {'full_name': None,\n",
       "   'variants': ['MUSDB18-HQ'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Slakh2100': {'full_name': 'Synthesized Lakh Dataset',\n",
       "   'variants': ['Slakh2100'],\n",
       "   'title': 'Cutting Music Source Separation Some Slakh: A Dataset to Study the Impact of Training Data Quality and Quantity',\n",
       "   'url': 'https://paperswithcode.com/paper/cutting-music-source-separation-some-slakh-a'},\n",
       "  'GuitarSet': {'full_name': None,\n",
       "   'variants': ['GuitarSet'],\n",
       "   'title': 'GuitarSet: A Dataset for Guitar Transcription',\n",
       "   'url': 'https://guitarset.weebly.com/uploads/1/2/1/6/121620128/xi_ismir_2018.pdf'},\n",
       "  'Mixing Secrets': {'full_name': None,\n",
       "   'variants': ['Mixing Secrets'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'OpenMIC-2018': {'full_name': None,\n",
       "   'variants': ['OpenMIC-2018'],\n",
       "   'title': 'OpenMIC-2018: An Open Data-set for Multiple Instrument Recognition',\n",
       "   'url': 'http://ismir2018.ircam.fr/doc/pdfs/248_Paper.pdf'},\n",
       "  'CAL500exp': {'full_name': 'CAL500 Expansion',\n",
       "   'variants': ['CAL500exp'],\n",
       "   'title': 'Towards time-varying music auto-tagging based on CAL500 expansion',\n",
       "   'url': 'https://doi.org/10.1109/ICME.2014.6890290'},\n",
       "  'CAL10K': {'full_name': 'Computer Audition Lab 10000',\n",
       "   'variants': ['CAL10K'],\n",
       "   'title': 'Exploring automatic music annotation with “acoustically-objectiv” tags',\n",
       "   'url': 'http://modelai.gettysburg.edu/2012/music/docs/Tingle_Autotag_MIR10.pdf'},\n",
       "  'MuseScore': {'full_name': '',\n",
       "   'variants': ['MuseScore'],\n",
       "   'title': 'Multitask learning for frame-level instrument recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/multitask-learning-for-frame-level-instrument'},\n",
       "  'MTG-Jamendo': {'full_name': None,\n",
       "   'variants': ['MTG-Jamendo'],\n",
       "   'title': 'The MTG-Jamendo Dataset for Automatic Music Tagging',\n",
       "   'url': 'http://hdl.handle.net/10230/42015'},\n",
       "  'LibriCount': {'full_name': None,\n",
       "   'variants': ['LibriCount'],\n",
       "   'title': 'LibriCount, a dataset for speaker count estimation (Version v1.0.0)',\n",
       "   'url': 'http://doi.org/10.5281/zenodo.1216072'},\n",
       "  'MultiWOZ': {'full_name': 'Multi-domain Wizard-of-Oz',\n",
       "   'variants': ['MULTIWOZ 2.4',\n",
       "    'MULTIWOZ 2.3',\n",
       "    'MULTIWOZ 2.2',\n",
       "    'MULTIWOZ 2.0',\n",
       "    'MultiWOZ',\n",
       "    'MULTIWOZ 2.1'],\n",
       "   'title': 'MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling',\n",
       "   'url': 'https://paperswithcode.com/paper/multiwoz-a-large-scale-multi-domain-wizard-of'},\n",
       "  'ReVerb Challenge': {'full_name': 'REverberant Voice Enhancement and Recognition Benchmark',\n",
       "   'variants': ['Reverb', 'ReVerb Challenge'],\n",
       "   'title': 'The REVERB challenge: A common evaluation framework for dereverberation and recognition of reverberant speech',\n",
       "   'url': 'https://ieeexplore.ieee.org/document/6701894'},\n",
       "  'MPQA Opinion Corpus': {'full_name': 'Multi-Perspective Question Answering',\n",
       "   'variants': ['MPQA', 'MPQA Opinion Corpus'],\n",
       "   'title': 'Annotating Expressions of Opinions and Emotions in Language',\n",
       "   'url': 'https://doi.org/10.1007/s10579-005-7880-9'},\n",
       "  'DROP': {'full_name': 'Discrete Reasoning Over Paragraphs',\n",
       "   'variants': ['DROP Test', 'DROP'],\n",
       "   'title': 'DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs',\n",
       "   'url': 'https://paperswithcode.com/paper/drop-a-reading-comprehension-benchmark'},\n",
       "  'New York Times Annotated Corpus': {'full_name': '',\n",
       "   'variants': ['New York Times Corpus', 'New York Times Annotated Corpus'],\n",
       "   'title': 'The New York Times Annotated Corpus',\n",
       "   'url': 'http://catalog.ldc.upenn.edu/LDC2008T19'},\n",
       "  'VisDial': {'full_name': 'Visual Dialog',\n",
       "   'variants': ['Visual Dialog v1.0',\n",
       "    'Visual Dialog v0.9',\n",
       "    'VisDial v1.0 test-std',\n",
       "    'VisDial v0.9 val',\n",
       "    'Visual Dialog v1.0 test-std',\n",
       "    'Visual Dialog  v0.9',\n",
       "    'VisDial'],\n",
       "   'title': 'Visual Dialog',\n",
       "   'url': 'https://paperswithcode.com/paper/visual-dialog'},\n",
       "  'AMR Bank': {'full_name': 'Abstract Meaning Representation',\n",
       "   'variants': ['AMR (english, MRP 2020)', 'AMR Bank'],\n",
       "   'title': 'Abstract Meaning Representation for Sembanking',\n",
       "   'url': 'https://paperswithcode.com/paper/abstract-meaning-representation-for'},\n",
       "  'WMT 2016': {'full_name': '',\n",
       "   'variants': ['wmt16 ro-en',\n",
       "    'newstest2016-ende eng-deu',\n",
       "    'newstest2016-deen deu-eng',\n",
       "    'newstest2016-ende',\n",
       "    'newstest2016-deen',\n",
       "    'wmt16',\n",
       "    'WMT2016 En-Ro',\n",
       "    'WMT 2016',\n",
       "    'WMT2016 Russian-English',\n",
       "    'WMT2016 Finnish-English',\n",
       "    'WMT2016 English-Russian',\n",
       "    'WMT2016 English-French',\n",
       "    'WMT2016 English-Czech',\n",
       "    'WMT2016 Czech-English',\n",
       "    'WMT2016 Romanian-English',\n",
       "    'WMT2016 German-English',\n",
       "    'WMT2016 English-Romanian',\n",
       "    'WMT2016 English-German',\n",
       "    'WMT2016 English--Romanian'],\n",
       "   'title': 'Findings of the 2016 Conference on Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2016-conference-on-machine'},\n",
       "  'WMT 2016 News': {'full_name': 'WMT 2016 News Translation Task',\n",
       "   'variants': ['WMT2016 Russian-English',\n",
       "    'WMT2016 Romanian-English',\n",
       "    'WMT2016 Finnish-English',\n",
       "    'WMT2016 English-Russian',\n",
       "    'WMT2016 English--Romanian',\n",
       "    'WMT2016 English-Romanian',\n",
       "    'WMT 2016 News'],\n",
       "   'title': 'Findings of the 2016 Conference on Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2016-conference-on-machine'},\n",
       "  'WMT 2016 IT': {'full_name': 'WMT 2016 IT Translation Task',\n",
       "   'variants': ['WMT 2016 IT'],\n",
       "   'title': 'Findings of the 2016 Conference on Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2016-conference-on-machine'},\n",
       "  'WMT 2016 Biomedical': {'full_name': 'WMT 2016 Biomedical Translation Task',\n",
       "   'variants': ['WMT 2016 Biomedical'],\n",
       "   'title': 'Findings of the 2016 Conference on Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2016-conference-on-machine'},\n",
       "  'XSum': {'full_name': None,\n",
       "   'variants': ['BBC XSum', 'XSum', 'X-Sum'],\n",
       "   'title': \"Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization\",\n",
       "   'url': 'https://paperswithcode.com/paper/dont-give-me-the-details-just-the-summary'},\n",
       "  'WMT 2014': {'full_name': '',\n",
       "   'variants': ['newstest2014-deen eng-deu',\n",
       "    'newstest2014-deen deu-eng',\n",
       "    'newstest2014-deen',\n",
       "    'wmt14',\n",
       "    'WMT 2014',\n",
       "    'WMT2014 German-English',\n",
       "    'WMT2014 English-Czech',\n",
       "    'WMT 2014 EN-FR',\n",
       "    'WMT 2014 EN-DE',\n",
       "    'WMT2014 English-German',\n",
       "    'WMT2014 French-English',\n",
       "    'WMT2014 English-French'],\n",
       "   'title': 'Findings of the 2014 Workshop on Statistical Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2014-workshop-on-statistical'},\n",
       "  'WMT 2014 Medical': {'full_name': 'WMT 2014 Medical Translation Task',\n",
       "   'variants': ['WMT 2014 Medical'],\n",
       "   'title': 'Findings of the 2014 Workshop on Statistical Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2014-workshop-on-statistical'},\n",
       "  'WMT 2015': {'full_name': '',\n",
       "   'variants': ['newstest2015-ende eng-deu',\n",
       "    'newstest2015-deen deu-eng',\n",
       "    'newstest2015-ende',\n",
       "    'newstest2015-deen',\n",
       "    'WMT 2015',\n",
       "    'WMT2015 English-Russian',\n",
       "    'WMT2015 English-German'],\n",
       "   'title': 'Findings of the 2015 Workshop on Statistical Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2015-workshop-on-statistical'},\n",
       "  'WMT 2015 News': {'full_name': 'WMT 2015 News Translation Task',\n",
       "   'variants': ['WMT 2015 News'],\n",
       "   'title': 'Findings of the 2015 Workshop on Statistical Machine Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2015-workshop-on-statistical'},\n",
       "  'SHAPES': {'full_name': 'Swarm Heuristics based Adaptive and Penalized Estimation of Splines',\n",
       "   'variants': ['SHAPES'],\n",
       "   'title': 'Neural Module Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/neural-module-networks'},\n",
       "  'AG’s Corpus': {'full_name': \"AG's corpus of news articlesNews\",\n",
       "   'variants': ['AG’s Corpus'],\n",
       "   'title': \"AG's corpus of news articles\",\n",
       "   'url': 'http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html'},\n",
       "  'QUASAR-S': {'full_name': 'QUestion Answering by Search And Reading – Stack Overflow',\n",
       "   'variants': ['QUASAR-S'],\n",
       "   'title': 'Quasar: Datasets for Question Answering by Search and Reading',\n",
       "   'url': 'https://paperswithcode.com/paper/quasar-datasets-for-question-answering-by'},\n",
       "  'QUASAR-T': {'full_name': 'QUestion Answering by Search And Reading – Trivia',\n",
       "   'variants': ['Quasar', 'Quasart-T', 'QUASAR-T'],\n",
       "   'title': 'Quasar: Datasets for Question Answering by Search and Reading',\n",
       "   'url': 'https://paperswithcode.com/paper/quasar-datasets-for-question-answering-by'},\n",
       "  'MLDoc': {'full_name': 'Multilingual Document Classification Corpus',\n",
       "   'variants': ['MLDoc',\n",
       "    'MLDoc Zero-Shot German-to-French',\n",
       "    'MLDoc Zero-Shot English-to-Spanish',\n",
       "    'MLDoc Zero-Shot English-to-Russian',\n",
       "    'MLDoc Zero-Shot English-to-Japanese',\n",
       "    'MLDoc Zero-Shot English-to-Italian',\n",
       "    'MLDoc Zero-Shot English-to-German',\n",
       "    'MLDoc Zero-Shot English-to-French',\n",
       "    'MLDoc Zero-Shot English-to-Chinese'],\n",
       "   'title': 'A Corpus for Multilingual Document Classification in Eight Languages',\n",
       "   'url': 'https://paperswithcode.com/paper/a-corpus-for-multilingual-document'},\n",
       "  'WMT 2018': {'full_name': '',\n",
       "   'variants': ['newstest2018-ende eng-deu',\n",
       "    'newstest2018-deen deu-eng',\n",
       "    'newstest2018-ende',\n",
       "    'newstest2018-deen',\n",
       "    'WMT 2018 Estonian-English',\n",
       "    'WMT 2018 English-Estonian',\n",
       "    'WMT 2018',\n",
       "    'WMT 2018 Finnish-English',\n",
       "    'WMT 2018 English-Finnish'],\n",
       "   'title': 'Findings of the 2018 Conference on Machine Translation (WMT18)',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2018-conference-on-machine'},\n",
       "  'WMT 2018 News': {'full_name': 'WMT 2018 News Translation Task',\n",
       "   'variants': ['WMT 2018 News'],\n",
       "   'title': 'Findings of the 2018 Conference on Machine Translation (WMT18)',\n",
       "   'url': 'https://paperswithcode.com/paper/findings-of-the-2018-conference-on-machine'},\n",
       "  'ArxivPapers': {'full_name': '',\n",
       "   'variants': ['ArxivPapers'],\n",
       "   'title': 'AxCell: Automatic Extraction of Results from Machine Learning Papers',\n",
       "   'url': 'https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from'},\n",
       "  'SegmentedTables': {'full_name': '',\n",
       "   'variants': ['SegmentedTables'],\n",
       "   'title': 'AxCell: Automatic Extraction of Results from Machine Learning Papers',\n",
       "   'url': 'https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from'},\n",
       "  'LinkedResults': {'full_name': '',\n",
       "   'variants': ['LinkedResults'],\n",
       "   'title': 'AxCell: Automatic Extraction of Results from Machine Learning Papers',\n",
       "   'url': 'https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from'},\n",
       "  'PWC Leaderboards': {'full_name': 'Papers with Code Leaderboards',\n",
       "   'variants': ['PWC Leaderboards (restricted)', 'PWC Leaderboards'],\n",
       "   'title': 'AxCell: Automatic Extraction of Results from Machine Learning Papers',\n",
       "   'url': 'https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from'},\n",
       "  'SKU110K': {'full_name': 'SKU110K',\n",
       "   'variants': ['SKU-110K', 'SKU110K'],\n",
       "   'title': 'Precise Detection in Densely Packed Scenes',\n",
       "   'url': 'https://paperswithcode.com/paper/precise-detection-in-densely-packed-scenes'},\n",
       "  'UBIRIS.v2': {'full_name': 'UBIRIS.v2',\n",
       "   'variants': ['UBIRIS.v2'],\n",
       "   'title': 'The UBIRIS.v2: A database of visible wavelength images captured on-the-move and at-a-distance',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2009.66'},\n",
       "  'VIVA': {'full_name': 'Vision for Intelligent Vehicles and Applications',\n",
       "   'variants': ['VIVA Hand Gestures Dataset', 'VIVA'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'ITOP': {'full_name': 'Invariant-Top View Dataset',\n",
       "   'variants': [' ITOP front-view',\n",
       "    'ITOP top-view',\n",
       "    'ITOP front-view',\n",
       "    'ITOP'],\n",
       "   'title': 'Towards Viewpoint Invariant 3D Human Pose Estimation',\n",
       "   'url': 'https://paperswithcode.com/paper/towards-viewpoint-invariant-3d-human-pose'},\n",
       "  'Dayton': {'full_name': 'Dayton',\n",
       "   'variants': ['Dayton (64×64) - aerial-to-ground',\n",
       "    'Dayton (64x64) - ground-to-aerial',\n",
       "    'Dayton (256×256) - aerial-to-ground',\n",
       "    'Dayton (256×256) - ground-to-aerial',\n",
       "    'Dayton'],\n",
       "   'title': 'Localizing and Orienting Street Views Using Overhead Imagery',\n",
       "   'url': 'https://paperswithcode.com/paper/localizing-and-orienting-street-views-using'},\n",
       "  'AOLP': {'full_name': 'Application-oriented License Plate',\n",
       "   'variants': ['AOLP-RP', 'AOLP'],\n",
       "   'title': 'Application-Oriented License Plate Recognition',\n",
       "   'url': 'https://doi.org/10.1109/TVT.2012.2226218'},\n",
       "  'Set11': {'full_name': 'Set11',\n",
       "   'variants': ['Set11 cs=50%', 'Set11'],\n",
       "   'title': 'ReconNet: Non-Iterative Reconstruction of Images From Compressively Sensed Measurements',\n",
       "   'url': 'https://paperswithcode.com/paper/reconnet-non-iterative-reconstruction-of-1'},\n",
       "  'SALICON': {'full_name': 'Salicency in Context',\n",
       "   'variants': ['SALICON->WebpageSaliency - 1-shot',\n",
       "    'SALICON->WebpageSaliency - 5-shot ',\n",
       "    'SALICON->WebpageSaliency - 10-shot ',\n",
       "    'SALICON->WebpageSaliency - EUB',\n",
       "    'SALICON'],\n",
       "   'title': 'SALICON: Saliency in Context',\n",
       "   'url': 'https://paperswithcode.com/paper/salicon-saliency-in-context'},\n",
       "  'GRID Dataset': {'full_name': '',\n",
       "   'variants': ['GRID corpus (mixed-speech)', 'GRID Dataset'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Flickr30K Entities': {'full_name': '',\n",
       "   'variants': ['Flickr30k Entities Dev',\n",
       "    'Flickr30k Entities Test',\n",
       "    'Flickr30K Entities'],\n",
       "   'title': 'Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models',\n",
       "   'url': 'https://paperswithcode.com/paper/flickr30k-entities-collecting-region-to'},\n",
       "  'FGVC-Aircraft': {'full_name': '',\n",
       "   'variants': ['FGVC Aircraft', 'FGVC-Aircraft'],\n",
       "   'title': 'Fine-Grained Visual Classification of Aircraft',\n",
       "   'url': 'https://paperswithcode.com/paper/fine-grained-visual-classification-of'},\n",
       "  'DUTS': {'full_name': '',\n",
       "   'variants': ['DUTS-test', 'DUTS-TE', 'DUTS'],\n",
       "   'title': 'Learning to Detect Salient Objects With Image-Level Supervision',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-to-detect-salient-objects-with-image'},\n",
       "  'LIP': {'full_name': 'Look into Person',\n",
       "   'variants': ['LIP val', 'LIP'],\n",
       "   'title': 'Look into Person: Self-supervised Structure-sensitive Learning and A New Benchmark for Human Parsing',\n",
       "   'url': 'https://paperswithcode.com/paper/look-into-person-self-supervised-structure'},\n",
       "  'ApolloScape': {'full_name': '',\n",
       "   'variants': ['ApolloScape'],\n",
       "   'title': 'The ApolloScape Open Dataset for Autonomous Driving and its Application',\n",
       "   'url': 'https://paperswithcode.com/paper/the-apolloscape-open-dataset-for-autonomous'},\n",
       "  'PoseTrack': {'full_name': '',\n",
       "   'variants': ['PoseTrack2017', 'PoseTrack2018', 'PoseTrack'],\n",
       "   'title': 'PoseTrack: A Benchmark for Human Pose Estimation and Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/posetrack-a-benchmark-for-human-pose'},\n",
       "  'ICVL Hand Posture': {'full_name': 'ICVL Hand Posture Dataset',\n",
       "   'variants': ['ICVL Hand Posture'],\n",
       "   'title': 'Latent Regression Forest: Structured Estimation of 3D Articulated Hand Posture',\n",
       "   'url': 'https://paperswithcode.com/paper/latent-regression-forest-structured'},\n",
       "  'SegTrack-v2': {'full_name': '',\n",
       "   'variants': ['SegTrack v2', 'SegTrack-v2'],\n",
       "   'title': 'Video Segmentation by Tracking Many Figure-Ground Segments',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2013.273'},\n",
       "  'Foggy Cityscapes': {'full_name': '',\n",
       "   'variants': ['Cityscapes to Foggy Cityscapes',\n",
       "    'Cityscapes-to-Foggy Cityscapes',\n",
       "    'Foggy Cityscapes'],\n",
       "   'title': 'Semantic Foggy Scene Understanding with Synthetic Data',\n",
       "   'url': 'https://paperswithcode.com/paper/semantic-foggy-scene-understanding-with'},\n",
       "  'Vimeo90K': {'full_name': '',\n",
       "   'variants': ['Vimeo90K'],\n",
       "   'title': 'Video Enhancement with Task-Oriented Flow',\n",
       "   'url': 'https://paperswithcode.com/paper/video-enhancement-with-task-oriented-flow'},\n",
       "  'MPIIGaze': {'full_name': '',\n",
       "   'variants': ['MPII Gaze', 'MPIIGaze'],\n",
       "   'title': 'Appearance-Based Gaze Estimation in the Wild',\n",
       "   'url': 'https://paperswithcode.com/paper/appearance-based-gaze-estimation-in-the-wild'},\n",
       "  'ReferItGame': {'full_name': 'ReferItGame',\n",
       "   'variants': ['ReferItGame'],\n",
       "   'title': 'ReferItGame: Referring to Objects in Photographs of Natural Scenes',\n",
       "   'url': 'https://paperswithcode.com/paper/referitgame-referring-to-objects-in'},\n",
       "  'MultiTHUMOS': {'full_name': '',\n",
       "   'variants': ['Multi-THUMOS', 'MultiTHUMOS'],\n",
       "   'title': 'Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos',\n",
       "   'url': 'https://paperswithcode.com/paper/every-moment-counts-dense-detailed-labeling'},\n",
       "  'CrowdHuman': {'full_name': '',\n",
       "   'variants': ['CrowdHuman (full body)', 'CrowdHuman'],\n",
       "   'title': 'CrowdHuman: A Benchmark for Detecting Human in a Crowd',\n",
       "   'url': 'https://paperswithcode.com/paper/crowdhuman-a-benchmark-for-detecting-human-in'},\n",
       "  'MSRDailyActivity3D': {'full_name': '',\n",
       "   'variants': ['MSR Daily Activity3D',\n",
       "    'MSR Daily Activity3D dataset',\n",
       "    'MSRDailyActivity3D'],\n",
       "   'title': 'Mining actionlet ensemble for action recognition with depth cameras',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2012.6247813'},\n",
       "  'McMaster': {'full_name': '',\n",
       "   'variants': ['McMaster',\n",
       "    'McMaster sigma75',\n",
       "    'McMaster sigma50',\n",
       "    'McMaster sigma35',\n",
       "    'McMaster sigma25',\n",
       "    'McMaster sigma15'],\n",
       "   'title': 'Color demosaicking by local directional interpolation and nonlocal adaptive thresholding',\n",
       "   'url': 'https://doi.org/10.1117/1.3600632'},\n",
       "  'Sketch': {'full_name': '',\n",
       "   'variants': ['Sketch (Fine-grained 6 Tasks)', 'Sketch'],\n",
       "   'title': 'How do humans sketch objects?',\n",
       "   'url': 'https://doi.org/10.1145/2185520.2185540'},\n",
       "  'Wireframe': {'full_name': '',\n",
       "   'variants': ['wireframe dataset', 'Wireframe'],\n",
       "   'title': 'Learning to Parse Wireframes in Images of Man-Made Environments',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-to-parse-wireframes-in-images-of-man-1'},\n",
       "  'MNIST-M': {'full_name': '',\n",
       "   'variants': ['MNIST-to-MNIST-M', 'MNIST-M'],\n",
       "   'title': 'Domain-Adversarial Training of Neural Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/domain-adversarial-training-of-neural'},\n",
       "  'SPIDER': {'full_name': 'SPIDER',\n",
       "   'variants': ['spider', 'SPIDER'],\n",
       "   'title': 'Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task',\n",
       "   'url': 'https://paperswithcode.com/paper/spider-a-large-scale-human-labeled-dataset'},\n",
       "  'tieredImageNet': {'full_name': 'tieredImageNet',\n",
       "   'variants': ['Tiered ImageNet 5-way (1-shot)',\n",
       "    'Tiered ImageNet 5-way (5-shot)',\n",
       "    'tieredImageNet',\n",
       "    'Tiered ImageNet 10-way (1-shot)',\n",
       "    'Tiered ImageNet 10-way (5-shot)'],\n",
       "   'title': 'Meta-Learning for Semi-Supervised Few-Shot Classification',\n",
       "   'url': 'https://paperswithcode.com/paper/meta-learning-for-semi-supervised-few-shot'},\n",
       "  'aPY': {'full_name': 'Attribute Pascal and Yahoo',\n",
       "   'variants': ['aPY - 0-Shot', 'aPY'],\n",
       "   'title': 'Describing objects by their attributes',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2009.5206772'},\n",
       "  'VisDA-2017': {'full_name': 'VisDA-2017',\n",
       "   'variants': ['VisDA2017', 'VisDA-2017'],\n",
       "   'title': 'VisDA: The Visual Domain Adaptation Challenge',\n",
       "   'url': 'https://paperswithcode.com/paper/visda-the-visual-domain-adaptation-challenge'},\n",
       "  'PDBBind': {'full_name': 'PDBBind',\n",
       "   'variants': ['PDBbind', 'PDBBind'],\n",
       "   'title': 'PDB-wide collection of binding data: current status of the PDBbind database',\n",
       "   'url': 'https://doi.org/10.1093/bioinformatics/btu626'},\n",
       "  'ImageNet-32': {'full_name': '',\n",
       "   'variants': ['ImageNet32', 'ImageNet-32'],\n",
       "   'title': 'A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets',\n",
       "   'url': 'https://paperswithcode.com/paper/a-downsampled-variant-of-imagenet-as-an'},\n",
       "  'MVTecAD': {'full_name': 'MVTEC ANOMALY DETECTION DATASET',\n",
       "   'variants': ['MVTec AD', 'MVTecAD'],\n",
       "   'title': 'MVTec AD -- A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection',\n",
       "   'url': 'https://paperswithcode.com/paper/mvtec-ad-a-comprehensive-real-world-dataset'},\n",
       "  'Kvasir': {'full_name': 'The Kvasir Dataset',\n",
       "   'variants': ['Kvasir-SEG', 'Kvasir'],\n",
       "   'title': 'KVASIR: A Multi-Class Image Dataset for Computer Aided Gastrointestinal Disease Detection',\n",
       "   'url': 'https://doi.org/10.1145/3083187.3083212'},\n",
       "  'Syn2Real': {'full_name': 'Syn2Real',\n",
       "   'variants': ['Syn2Real-C', 'Syn2Real'],\n",
       "   'title': 'Syn2Real: A New Benchmark forSynthetic-to-Real Visual Domain Adaptation',\n",
       "   'url': 'https://paperswithcode.com/paper/syn2real-a-new-benchmark-forsynthetic-to-real'},\n",
       "  'ANLI': {'full_name': 'Adversarial NLI',\n",
       "   'variants': ['ANLI test', 'ANLI', 'ANLI-all', 'ANLI-r3'],\n",
       "   'title': 'Adversarial NLI: A New Benchmark for Natural Language Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/adversarial-nli-a-new-benchmark-for-natural'},\n",
       "  'Cityscapes': {'full_name': '',\n",
       "   'variants': ['Cityscapes 10% labeled',\n",
       "    'Cityscapes',\n",
       "    'Cityscapes-5K 256x512',\n",
       "    'Cityscapes-25K 256x512',\n",
       "    'Cityscapes val',\n",
       "    'Cityscapes test',\n",
       "    'Cityscapes Photo-to-Labels',\n",
       "    'Cityscapes Labels-to-Photo',\n",
       "    'Cityscapes 50% labeled',\n",
       "    'Cityscapes 25% labeled',\n",
       "    'Cityscapes 12.5% labeled',\n",
       "    'Cityscapes 100 samples labeled'],\n",
       "   'title': 'The Cityscapes Dataset for Semantic Urban Scene Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/the-cityscapes-dataset-for-semantic-urban'},\n",
       "  'PASCAL VOC': {'full_name': 'PASCAL Visual Object Classes Challenge',\n",
       "   'variants': ['VOC12',\n",
       "    'PASCAL VOC 2012',\n",
       "    'PASCAL VOC',\n",
       "    'Pascal VOC 2012 5% labeled',\n",
       "    'Pascal VOC 2012 2% labeled',\n",
       "    'Pascal VOC 2012 12.5% labeled',\n",
       "    'Pascal VOC 2012 1% labeled',\n",
       "    'Pascal VOC 2007 count-test',\n",
       "    'PASCAL VOC 2012, 60 proposals per image',\n",
       "    'PASCAL VOC 2012 val',\n",
       "    'PASCAL VOC 2012 test',\n",
       "    'PASCAL VOC 2012 25% labeled',\n",
       "    'PASCAL VOC 2011 test',\n",
       "    'PASCAL VOC 2011',\n",
       "    'PASCAL VOC 2007'],\n",
       "   'title': 'Location-aware Single Image Reflection Removal',\n",
       "   'url': 'https://paperswithcode.com/paper/location-aware-single-image-reflection'},\n",
       "  'VGG Face': {'full_name': '',\n",
       "   'variants': ['VGG Face'],\n",
       "   'title': 'Deep Face Recognition',\n",
       "   'url': 'https://doi.org/10.5244/C.29.41'},\n",
       "  'LibriSpeech': {'full_name': '',\n",
       "   'variants': ['Librispeech (other)',\n",
       "    'Librispeech (clean)',\n",
       "    'LibriSpeech ASR',\n",
       "    'LibriSpeechLibri-Light test-othertest-other',\n",
       "    'LibriSpeech',\n",
       "    'LibriSpeechDuplicate',\n",
       "    'LibriSpeech test-other',\n",
       "    'LibriSpeech test-clean'],\n",
       "   'title': 'Librispeech: An ASR corpus based on public domain audio books',\n",
       "   'url': 'https://doi.org/10.1109/ICASSP.2015.7178964'},\n",
       "  'CASIA-WebFace': {'full_name': '',\n",
       "   'variants': ['WebFace', 'WebFace - 8x upscaling', 'CASIA-WebFace'],\n",
       "   'title': 'Learning Face Representation from Scratch',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-face-representation-from-scratch'},\n",
       "  'Set14': {'full_name': '',\n",
       "   'variants': ['Set14 - 4x upscaling',\n",
       "    'Set14 - 2x upscaling',\n",
       "    'Set14 - 3x upscaling',\n",
       "    'Set14 - 8x upscaling',\n",
       "    'Set14'],\n",
       "   'title': 'On Single Image Scale-Up Using Sparse-Representations',\n",
       "   'url': 'https://doi.org/10.1007/978-3-642-27413-8_47'},\n",
       "  'MS-Celeb-1M': {'full_name': '',\n",
       "   'variants': ['MS-Celeb-1M'],\n",
       "   'title': 'MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/ms-celeb-1m-a-dataset-and-benchmark-for-large'},\n",
       "  'UCI Machine Learning Repository': {'full_name': None,\n",
       "   'variants': ['UCI localization data',\n",
       "    'UCI POWER',\n",
       "    'UCI MINIBOONE',\n",
       "    'UCI HEPMASS',\n",
       "    'UCI GAS',\n",
       "    'UCI Epileptic Seizure Recognition',\n",
       "    'UCI Machine Learning Repository'],\n",
       "   'title': 'Endgame Analysis of Dou Shou Qi',\n",
       "   'url': 'https://paperswithcode.com/paper/endgame-analysis-of-dou-shou-qi'},\n",
       "  'SYNTHIA': {'full_name': 'SYNTHetic Collection of Imagery and Annotations',\n",
       "   'variants': ['SYNTHIA Fall-to-Winter',\n",
       "    'SYNTHIA-to-Cityscapes',\n",
       "    'Synthia Novel View Synthesis',\n",
       "    'SYNTHIA-CVPR’16',\n",
       "    'SYNTHIA'],\n",
       "   'title': 'The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes',\n",
       "   'url': 'https://paperswithcode.com/paper/the-synthia-dataset-a-large-collection-of'},\n",
       "  'NYUv2': {'full_name': 'NYU-Depth V2',\n",
       "   'variants': ['NYU-Depth V2',\n",
       "    'NYU Depth v2',\n",
       "    'NYU-Depth V2 Surface Normals',\n",
       "    'NYUv2'],\n",
       "   'title': 'Indoor Segmentation and Support Inference from RGBD Images',\n",
       "   'url': 'http://arxiv.org/pdf/1301.3572.pdf'},\n",
       "  'Urban100': {'full_name': '',\n",
       "   'variants': ['Urban100',\n",
       "    'Urban100 sigma70',\n",
       "    'Urban100 sigma50',\n",
       "    'Urban100 sigma30',\n",
       "    'Urban100 sigma25',\n",
       "    'urban100 sigma15',\n",
       "    'Urban100 sigma10',\n",
       "    'Urban100 - 8x upscaling',\n",
       "    'Urban100 - 4x upscaling',\n",
       "    'Urban100 - 3x upscaling',\n",
       "    'Urban100 - 2x upscaling',\n",
       "    'Urban100 - 16x upscaling'],\n",
       "   'title': 'Single Image Super-Resolution From Transformed Self-Exemplars',\n",
       "   'url': 'https://paperswithcode.com/paper/single-image-super-resolution-from'},\n",
       "  'VGGFace2': {'full_name': '',\n",
       "   'variants': ['VggFace2',\n",
       "    'VGGFace2 (2.3M)',\n",
       "    'VggFace2 - 8x upscaling',\n",
       "    'VGGFace2'],\n",
       "   'title': 'VGGFace2: A dataset for recognising faces across pose and age',\n",
       "   'url': 'https://paperswithcode.com/paper/vggface2-a-dataset-for-recognising-faces'},\n",
       "  'PASCAL3D+': {'full_name': '',\n",
       "   'variants': [' Pascal3D+', 'PASCAL3D+'],\n",
       "   'title': 'Beyond PASCAL: A benchmark for 3D object detection in the wild',\n",
       "   'url': 'https://doi.org/10.1109/WACV.2014.6836101'},\n",
       "  'SUN RGB-D': {'full_name': 'SUN RGB-D',\n",
       "   'variants': ['SUN-RGBD', 'SUN-RGBD val', 'SUN RGB-D'],\n",
       "   'title': 'SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite',\n",
       "   'url': 'https://paperswithcode.com/paper/sun-rgb-d-a-rgb-d-scene-understanding'},\n",
       "  'SUNCG': {'full_name': 'SUNCG',\n",
       "   'variants': ['SUNCG'],\n",
       "   'title': 'Semantic Scene Completion from a Single Depth Image',\n",
       "   'url': 'https://paperswithcode.com/paper/semantic-scene-completion-from-a-single-depth'},\n",
       "  'Places205': {'full_name': '',\n",
       "   'variants': ['Places205', 'Places'],\n",
       "   'title': 'Learning Deep Features for Scene Recognition using Places Database',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-deep-features-for-scene-recognition'},\n",
       "  'ModelNet': {'full_name': '',\n",
       "   'variants': ['ModelNet40', 'ModelNet10', 'ModelNet'],\n",
       "   'title': '3D ShapeNets: A Deep Representation for Volumetric Shapes',\n",
       "   'url': 'https://paperswithcode.com/paper/3d-shapenets-a-deep-representation-for'},\n",
       "  'YAGO': {'full_name': 'Yet Another Great Ontology',\n",
       "   'variants': ['YAGO3-10', 'YAGO', 'Yago11k', 'YAGO15k', 'YAGO39K', 'YAGO37'],\n",
       "   'title': 'Yago: a core of semantic knowledge',\n",
       "   'url': 'https://doi.org/10.1145/1242572.1242667'},\n",
       "  'MPI Sintel': {'full_name': '',\n",
       "   'variants': ['Sintel-final - unsupervised',\n",
       "    'Sintel-final',\n",
       "    'Sintel-clean',\n",
       "    'Sintel Final unsupervised',\n",
       "    'Sintel Clean unsupervised',\n",
       "    'MPI Sintel'],\n",
       "   'title': 'A Naturalistic Open Source Movie for Optical Flow Evaluation',\n",
       "   'url': 'https://doi.org/10.1007/978-3-642-33783-3_44'},\n",
       "  'Helen': {'full_name': '',\n",
       "   'variants': ['Helen'],\n",
       "   'title': 'Interactive Facial Feature Localization',\n",
       "   'url': 'https://doi.org/10.1007/978-3-642-33712-3_49'},\n",
       "  'Omniglot': {'full_name': '',\n",
       "   'variants': ['OMNIGLOT - 5-Shot Learning',\n",
       "    'OMNIGLOT - 1-Shot Learning',\n",
       "    'OMNIGLOT-EMNIST 5-way (5-shot)',\n",
       "    'OMNIGLOT-EMNIST 5-way (1-shot)',\n",
       "    'OMNIGLOT - 5-Shot, 423 way',\n",
       "    'OMNIGLOT - 5-Shot, 1000 way',\n",
       "    'OMNIGLOT - 1-Shot, 423 way',\n",
       "    'OMNIGLOT - 1-Shot, 1000 way',\n",
       "    'OMNIGLOT - 5-Shot, 5-way',\n",
       "    'OMNIGLOT - 5-Shot, 20-way',\n",
       "    'OMNIGLOT - 1-Shot, 5-way',\n",
       "    'OMNIGLOT - 1-Shot, 20-way',\n",
       "    'Omniglot',\n",
       "    'OMNIGLOT',\n",
       "    'Cluttered Omniglot'],\n",
       "   'title': 'The Omniglot challenge: a 3-year progress report',\n",
       "   'url': 'https://paperswithcode.com/paper/the-omniglot-challenge-a-3-year-progress'},\n",
       "  'FrameNet': {'full_name': '',\n",
       "   'variants': ['FrameNet'],\n",
       "   'title': 'The Berkeley FrameNet Project',\n",
       "   'url': 'https://www.aclweb.org/anthology/P98-1013/'},\n",
       "  'LSUN': {'full_name': 'Large-scale Scene UNderstanding Challenge',\n",
       "   'variants': ['LSUN Roon Layout',\n",
       "    'LSUN Bedroom 128 x 128',\n",
       "    'LSUN Bedroom',\n",
       "    'LSUN',\n",
       "    'LSUN Horse 256 x 256',\n",
       "    'LSUN Churches 256 x 256',\n",
       "    'LSUN Cat 256 x 256',\n",
       "    'LSUN Car 512 x 384',\n",
       "    'LSUN Car 256 x 256',\n",
       "    'LSUN Bedroom 64 x 64',\n",
       "    'LSUN Bedroom 256 x 256'],\n",
       "   'title': 'LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop',\n",
       "   'url': 'https://paperswithcode.com/paper/lsun-construction-of-a-large-scale-image'},\n",
       "  'LFPW': {'full_name': 'Labeled Face Parts in the Wild',\n",
       "   'variants': ['LFPW'],\n",
       "   'title': 'Localizing Parts of Faces Using a Consensus of Exemplars',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2011.5995602'},\n",
       "  'CARLA': {'full_name': 'Car Learning to Act',\n",
       "   'variants': ['CARLA', 'CARLA Leaderboard'],\n",
       "   'title': 'CARLA: An Open Urban Driving Simulator',\n",
       "   'url': 'https://paperswithcode.com/paper/carla-an-open-urban-driving-simulator'},\n",
       "  'OTB': {'full_name': '',\n",
       "   'variants': ['OTB-2015', 'OTB-2013', 'OTB-50', 'OTB'],\n",
       "   'title': 'Object Tracking Benchmark',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2014.2388226'},\n",
       "  'Places365': {'full_name': '',\n",
       "   'variants': ['Places365-Standard', 'Places365'],\n",
       "   'title': 'Semantic-Aware Scene Recognition',\n",
       "   'url': 'https://paperswithcode.com/paper/semantic-aware-scene-recognition'},\n",
       "  'Extended Yale B': {'full_name': '',\n",
       "   'variants': ['Extended Yale-B', 'Extended Yale B'],\n",
       "   'title': 'From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose',\n",
       "   'url': 'https://doi.org/10.1109/34.927464'},\n",
       "  'IMDb Movie Reviews': {'full_name': '',\n",
       "   'variants': ['IMDb', 'IMDb Movie Reviews', 'User and product information'],\n",
       "   'title': 'Learning Word Vectors for Sentiment Analysis',\n",
       "   'url': 'https://www.aclweb.org/anthology/P11-1015/'},\n",
       "  'BookCorpus': {'full_name': '',\n",
       "   'variants': ['BookCorpus'],\n",
       "   'title': 'Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books',\n",
       "   'url': 'https://paperswithcode.com/paper/aligning-books-and-movies-towards-story-like'},\n",
       "  'FaceWarehouse': {'full_name': '',\n",
       "   'variants': ['FaceWarehouse'],\n",
       "   'title': 'FaceWarehouse: A 3D Facial Expression Database for Visual Computing',\n",
       "   'url': 'https://doi.org/10.1109/TVCG.2013.249'},\n",
       "  'LSP': {'full_name': 'Leeds Sports Pose',\n",
       "   'variants': ['Leeds Sports Poses', ' Leeds Sports Pose', 'LSP'],\n",
       "   'title': 'Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation',\n",
       "   'url': 'https://doi.org/10.5244/C.24.12'},\n",
       "  'KTH': {'full_name': 'KTH Action dataset',\n",
       "   'variants': ['KTH'],\n",
       "   'title': 'Recognizing Human Actions: A Local SVM Approach',\n",
       "   'url': 'https://doi.org/10.1109/ICPR.2004.1334462'},\n",
       "  'Places': {'full_name': 'Places',\n",
       "   'variants': ['Places2', 'Places2 val', 'Places205', 'Places'],\n",
       "   'title': 'Places: A 10 Million Image Database for Scene Recognition',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2017.2723009'},\n",
       "  'MoCap': {'full_name': 'CMU Graphics Lab Motion Capture Database',\n",
       "   'variants': ['MoCap'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'KIT Whole-Body Human Motion': {'full_name': '',\n",
       "   'variants': ['KIT Whole-Body Human Motion'],\n",
       "   'title': 'The KIT whole-body human motion database',\n",
       "   'url': 'https://doi.org/10.1109/ICAR.2015.7251476'},\n",
       "  'Meta-Dataset': {'full_name': '',\n",
       "   'variants': ['Meta-Dataset', 'Meta-Dataset Rank'],\n",
       "   'title': 'Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples',\n",
       "   'url': 'https://paperswithcode.com/paper/meta-dataset-a-dataset-of-datasets-for'},\n",
       "  'USF': {'full_name': 'Human ID Gait Challenge Dataset',\n",
       "   'variants': ['USF'],\n",
       "   'title': 'The HumanID Gait Challenge Problem: Data Sets, Performance, and Analysis',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2005.39'},\n",
       "  'BirdSong': {'full_name': '',\n",
       "   'variants': ['BirdSong'],\n",
       "   'title': 'Rank-loss support instance machines for MIML instance annotation',\n",
       "   'url': 'https://doi.org/10.1145/2339530.2339616'},\n",
       "  'Oxford5k': {'full_name': 'Oxford Buildings',\n",
       "   'variants': ['Oxford5k'],\n",
       "   'title': 'Object retrieval with large vocabularies and fast spatial matching',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2007.383172'},\n",
       "  'CBSD68': {'full_name': 'Color BSD68',\n",
       "   'variants': ['CBSD68 sigma70',\n",
       "    'CBSD68 sigma65',\n",
       "    'CBSD68 sigma60',\n",
       "    'CBSD68 sigma55',\n",
       "    'CBSD68 sigma5',\n",
       "    'CBSD68 sigma45',\n",
       "    'CBSD68 sigma40',\n",
       "    'CBSD68 sigma30',\n",
       "    'CBSD68 sigma20',\n",
       "    'CBSD68 sigma10',\n",
       "    'CBSD68 sigma75',\n",
       "    'CBSD68 sigma50',\n",
       "    'CBSD68 sigma35',\n",
       "    'CBSD68 sigma25',\n",
       "    'CBSD68 sigma15',\n",
       "    'CBSD68'],\n",
       "   'title': 'A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics',\n",
       "   'url': 'http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=937655'},\n",
       "  'ScribbleSup': {'full_name': 'PASCAL-Scribble Dataset',\n",
       "   'variants': ['ScribbleSup'],\n",
       "   'title': 'ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation',\n",
       "   'url': 'https://paperswithcode.com/paper/scribblesup-scribble-supervised-convolutional'},\n",
       "  'Stanford Background': {'full_name': 'Standford Background Dataset',\n",
       "   'variants': ['Stanford Background'],\n",
       "   'title': 'Decomposing a scene into geometric and semantically consistent regions',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2009.5459211'},\n",
       "  'New College': {'full_name': '',\n",
       "   'variants': ['New College'],\n",
       "   'title': 'The New College Vision and Laser Data Set',\n",
       "   'url': 'https://doi.org/10.1177/0278364909103911'},\n",
       "  'MALF': {'full_name': 'Multi-Attribute Labelled Faces',\n",
       "   'variants': ['MALF'],\n",
       "   'title': 'Fine-grained evaluation on face detection in the wild',\n",
       "   'url': 'https://doi.org/10.1109/FG.2015.7163158'},\n",
       "  'Oxford-Affine': {'full_name': None,\n",
       "   'variants': ['Oxford-Affine'],\n",
       "   'title': 'A Comparison of Affine Region Detectors',\n",
       "   'url': 'https://doi.org/10.1007/s11263-005-3848-x'},\n",
       "  'Oxford105k': {'full_name': '',\n",
       "   'variants': ['Oxford105k'],\n",
       "   'title': 'Object retrieval with large vocabularies and fast spatial matching',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2007.383172'},\n",
       "  'DispScenes': {'full_name': None,\n",
       "   'variants': ['DispScenes'],\n",
       "   'title': 'Deep Spectral Correspondence for Matching Disparate Image Pairs',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-spectral-correspondence-for-matching'},\n",
       "  'Retrieval-SfM': {'full_name': None,\n",
       "   'variants': ['Retrieval-SfM'],\n",
       "   'title': 'CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples',\n",
       "   'url': 'https://paperswithcode.com/paper/cnn-image-retrieval-learns-from-bow'},\n",
       "  'VGG Cell': {'full_name': None,\n",
       "   'variants': ['VGG Cell'],\n",
       "   'title': 'Microscopy cell counting and detection with fully convolutional regression networks',\n",
       "   'url': 'https://doi.org/10.1080/21681163.2016.1149104'},\n",
       "  'Tiny Images': {'full_name': '',\n",
       "   'variants': ['Tiny Images'],\n",
       "   'title': '80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition',\n",
       "   'url': 'https://doi.org/10.1109/TPAMI.2008.128'},\n",
       "  'Permuted MNIST': {'full_name': '',\n",
       "   'variants': ['Permuted MNIST'],\n",
       "   'title': 'An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks',\n",
       "   'url': 'https://paperswithcode.com/paper/an-empirical-investigation-of-catastrophic'},\n",
       "  'MNIST-8M': {'full_name': 'Infinite MNIST',\n",
       "   'variants': ['MNIST-8M'],\n",
       "   'title': 'Training invariant support vector machines using selective sampling',\n",
       "   'url': 'http://leon.bottou.org/papers/loosli-canu-bottou-2006'},\n",
       "  'SUN3D': {'full_name': 'SUN3D',\n",
       "   'variants': ['SUN3D'],\n",
       "   'title': 'SUN3D: A Database of Big Spaces Reconstructed Using SfM and Object Labels',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2013.458'},\n",
       "  'TUM RGB-D': {'full_name': 'TUM RGB-D',\n",
       "   'variants': ['TUM RGB-D'],\n",
       "   'title': 'A benchmark for the evaluation of RGB-D SLAM systems',\n",
       "   'url': 'https://doi.org/10.1109/IROS.2012.6385773'},\n",
       "  'SceneNet': {'full_name': 'SceneNet',\n",
       "   'variants': ['SceneNet'],\n",
       "   'title': 'SceneNet: Understanding Real World Indoor Scenes With Synthetic Data',\n",
       "   'url': 'https://paperswithcode.com/paper/scenenet-understanding-real-world-indoor'},\n",
       "  'SceneNet RGB-D': {'full_name': 'SceneNet RGB-D',\n",
       "   'variants': ['SceneNet RGB-D'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'SUN Attribute': {'full_name': 'SUN Attribute',\n",
       "   'variants': ['SUN Attribute'],\n",
       "   'title': 'The SUN Attribute Database: Beyond Categories for Deeper Scene Understanding',\n",
       "   'url': 'https://doi.org/10.1007/s11263-013-0695-z'},\n",
       "  'iSUN': {'full_name': 'iSUN',\n",
       "   'variants': ['iSUN'],\n",
       "   'title': 'TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking',\n",
       "   'url': 'https://paperswithcode.com/paper/turkergaze-crowdsourcing-saliency-with-webcam'},\n",
       "  'BMS-26': {'full_name': 'Berkeley Motion Segmentation',\n",
       "   'variants': ['BMS-26'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Freiburg Groceries': {'full_name': 'Freiburg Groceries',\n",
       "   'variants': ['Freiburg Groceries'],\n",
       "   'title': 'The Freiburg Groceries Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/the-freiburg-groceries-dataset'},\n",
       "  'Freiburg Spatial Relations': {'full_name': 'Freiburg Spatial Relations',\n",
       "   'variants': ['Freiburg Spatial Relations'],\n",
       "   'title': 'Metric Learning for Generalizing Spatial Relations to New Objects',\n",
       "   'url': 'https://paperswithcode.com/paper/metric-learning-for-generalizing-spatial'},\n",
       "  'Freiburg Street Crossing': {'full_name': 'Freiburg Street Crossing',\n",
       "   'variants': ['Freiburg Street Crossing'],\n",
       "   'title': 'Multimodal Interaction-aware Motion Prediction for Autonomous Street Crossing',\n",
       "   'url': 'https://paperswithcode.com/paper/multimodal-interaction-aware-motion'},\n",
       "  'Freiburg Campus 3D Scan': {'full_name': 'Freiburg Campus 3D Scan',\n",
       "   'variants': ['Freiburg Campus 3D Scan'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Plant Centroids': {'full_name': 'Plant Centroids',\n",
       "   'variants': ['Plant Centroids'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Freiburg Across Seasons': {'full_name': 'Freiburg Across Seasons',\n",
       "   'variants': ['Freiburg Across Seasons'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Freiburg Terrains': {'full_name': 'Freiburg Terrains',\n",
       "   'variants': ['Freiburg Terrains'],\n",
       "   'title': 'Self-Supervised Visual Terrain Classification from Unsupervised Acoustic Feature Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/self-supervised-visual-terrain-classification'},\n",
       "  'Freiburg Block Tasks': {'full_name': 'Freiburg Block Tasks',\n",
       "   'variants': ['Freiburg Block Tasks'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Cityscapes-Motion': {'full_name': 'Cityscapes-Motion',\n",
       "   'variants': ['Cityscapes-Motion'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'KITTI-Motion': {'full_name': 'KITTI-Motion',\n",
       "   'variants': ['KITTI-Motion'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MobilityAids': {'full_name': 'MobilityAids',\n",
       "   'variants': ['MobilityAids'],\n",
       "   'title': 'Deep Detection of People and their Mobility Aids for a Hospital Robot',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-detection-of-people-and-their-mobility'},\n",
       "  'RobotPush': {'full_name': 'RobotPush',\n",
       "   'variants': ['RobotPush'],\n",
       "   'title': 'Learning to Singulate Objects using a Push Proposal Network',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-to-singulate-objects-using-a-push'},\n",
       "  'DeepLocCross': {'full_name': 'DeepLocCross',\n",
       "   'variants': ['DeepLocCross'],\n",
       "   'title': 'VLocNet++: Deep Multitask Learning for Semantic Visual Localization and Odometry',\n",
       "   'url': 'https://paperswithcode.com/paper/vlocnet-deep-multitask-learning-for-semantic'},\n",
       "  'DeepLoc': {'full_name': 'DeepLoc',\n",
       "   'variants': ['DeepLoc'],\n",
       "   'title': 'VLocNet++: Deep Multitask Learning for Semantic Visual Localization and Odometry',\n",
       "   'url': 'https://paperswithcode.com/paper/vlocnet-deep-multitask-learning-for-semantic'},\n",
       "  'Freiburg Lighting Adaptable Map Tracking': {'full_name': 'Freiburg Lighting Adaptable Map Tracking',\n",
       "   'variants': ['Freiburg Lighting Adaptable Map Tracking'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Freiburg Poking': {'full_name': 'Freiburg Poking',\n",
       "   'variants': ['Freiburg Poking'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  '7-Scenes': {'full_name': '7-Scenes',\n",
       "   'variants': ['7-Scenes'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Cross-Dataset Testbed': {'full_name': 'Cross-Dataset Testbed',\n",
       "   'variants': ['Cross-Dataset Testbed'],\n",
       "   'title': 'A Testbed for Cross-Dataset Analysis',\n",
       "   'url': 'https://paperswithcode.com/paper/a-testbed-for-cross-dataset-analysis'},\n",
       "  'Washington RGB-D': {'full_name': 'Washington RGB-D',\n",
       "   'variants': ['Washington RGB-D'],\n",
       "   'title': 'A large-scale hierarchical multi-view RGB-D object dataset',\n",
       "   'url': 'https://doi.org/10.1109/ICRA.2011.5980382'},\n",
       "  'TUM Kitchen': {'full_name': 'TUM Kitchen',\n",
       "   'variants': ['TUM Kitchen'],\n",
       "   'title': 'The TUM Kitchen Data Set of everyday manipulation activities for motion tracking and action recognition',\n",
       "   'url': 'https://doi.org/10.1109/ICCVW.2009.5457583'},\n",
       "  'HIC': {'full_name': 'Hands in Action',\n",
       "   'variants': ['HIC'],\n",
       "   'title': 'Capturing Hands in Action using Discriminative Salient Points and Physics Simulation',\n",
       "   'url': 'https://paperswithcode.com/paper/capturing-hands-in-action-using'},\n",
       "  'George Washington': {'full_name': 'George Washington',\n",
       "   'variants': ['George Washington'],\n",
       "   'title': 'Lexicon-free handwritten word spotting using character HMMs',\n",
       "   'url': 'https://doi.org/10.1016/j.patrec.2011.09.009'},\n",
       "  'Watch-n-Patch': {'full_name': 'Watch-n-Patch',\n",
       "   'variants': ['Watch-n-Patch'],\n",
       "   'title': 'Watch-n-Patch: Unsupervised Understanding of Actions and Relations',\n",
       "   'url': 'https://paperswithcode.com/paper/watch-n-patch-unsupervised-understanding-of'},\n",
       "  'Parzival': {'full_name': 'Parzival',\n",
       "   'variants': ['Parzival'],\n",
       "   'title': 'Language Model Integration for the Recognition of Handwritten Medieval Documents',\n",
       "   'url': 'https://doi.org/10.1109/ICDAR.2009.17'},\n",
       "  'CDTB': {'full_name': 'Color-and-Depth Tracking',\n",
       "   'variants': ['CDTB'],\n",
       "   'title': 'CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark',\n",
       "   'url': 'https://paperswithcode.com/paper/cdtb-a-color-and-depth-visual-object-tracking'},\n",
       "  'EgoDexter': {'full_name': 'EgoDexter',\n",
       "   'variants': ['EgoDexter'],\n",
       "   'title': 'Real-time Hand Tracking under Occlusion from an Egocentric RGB-D Sensor',\n",
       "   'url': 'https://paperswithcode.com/paper/real-time-hand-tracking-under-occlusion-from'},\n",
       "  'SynthHands': {'full_name': 'SynthHands',\n",
       "   'variants': ['SynthHands'],\n",
       "   'title': 'Real-time Hand Tracking under Occlusion from an Egocentric RGB-D Sensor',\n",
       "   'url': 'https://paperswithcode.com/paper/real-time-hand-tracking-under-occlusion-from'},\n",
       "  'Washington RGB-D Scenes v2': {'full_name': 'Washington RGB-D Scenes v2',\n",
       "   'variants': ['Washington RGB-D Scenes v2'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Washington RGB-D Scenes': {'full_name': 'Washington RGB-D Scenes',\n",
       "   'variants': ['Washington RGB-D Scenes'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'MannequinChallenge': {'full_name': 'MannequinChallenge',\n",
       "   'variants': ['MannequinChallenge'],\n",
       "   'title': 'Learning the Depths of Moving People by Watching Frozen People',\n",
       "   'url': 'https://paperswithcode.com/paper/learning-the-depths-of-moving-people-by'},\n",
       "  'Freiburg RGB-D People': {'full_name': 'Freiburg RGB-D People',\n",
       "   'variants': ['Freiburg RGB-D People'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Fraunhofer IPA Bin-Picking': {'full_name': 'Fraunhofer IPA Bin-Picking',\n",
       "   'variants': ['Fraunhofer IPA Bin-Picking'],\n",
       "   'title': 'Large-scale 6D Object Pose Estimation Dataset for Industrial Bin-Picking',\n",
       "   'url': 'https://paperswithcode.com/paper/large-scale-6d-object-pose-estimation-dataset'},\n",
       "  'PAVIS RGB-D': {'full_name': 'PAVIS RGB-D',\n",
       "   'variants': ['PAVIS RGB-D'],\n",
       "   'title': 'Re-identification with RGB-D Sensors',\n",
       "   'url': 'https://doi.org/10.1007/978-3-642-33863-2_43'},\n",
       "  'Couples Therapy': {'full_name': 'Couples Therapy Corpus',\n",
       "   'variants': ['Couples Therapy'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Raider': {'full_name': 'Raider',\n",
       "   'variants': ['Raider'],\n",
       "   'title': 'A common, high-dimensional model of the representational space in human ventral temporal cortex',\n",
       "   'url': 'http://dx.doi.org/10.1016/j.neuron.2011.08.026'},\n",
       "  'VizDoom': {'full_name': 'VizDoom',\n",
       "   'variants': ['ViZDoom Basic Scenario', 'VizDoom'],\n",
       "   'title': 'ViZDoom: A Doom-based AI Research Platform for Visual Reinforcement Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/vizdoom-a-doom-based-ai-research-platform-for'},\n",
       "  'StarCraft II Learning Environment': {'full_name': 'StarCraft II Learning Environment',\n",
       "   'variants': ['StarCraft II Learning Environment'],\n",
       "   'title': 'StarCraft II: A New Challenge for Reinforcement Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/starcraft-ii-a-new-challenge-for'},\n",
       "  'AI2-THOR': {'full_name': 'AI2-THOR',\n",
       "   'variants': ['AI2-THOR'],\n",
       "   'title': 'AI2-THOR: An Interactive 3D Environment for Visual AI',\n",
       "   'url': 'https://paperswithcode.com/paper/ai2-thor-an-interactive-3d-environment-for'},\n",
       "  'TORCS': {'full_name': 'The Open Racing Car Simulator',\n",
       "   'variants': ['TORCS'],\n",
       "   'title': 'Torcs, the open racing car simulator',\n",
       "   'url': 'http://torcs.sourceforge.net'},\n",
       "  'DeepMind Control Suite': {'full_name': 'DeepMind Control Suite',\n",
       "   'variants': ['DeepMind Walker Walk (Images)',\n",
       "    'DeepMind Finger Spin (Images)',\n",
       "    'DeepMind Cup Catch (Images)',\n",
       "    'DeepMind Cheetah Run (Images)',\n",
       "    'DeepMind Cartpole Swingup (Images)',\n",
       "    'DeepMind Cartpole Balance (Images)',\n",
       "    'DeepMind Control Suite'],\n",
       "   'title': 'DeepMind Control Suite',\n",
       "   'url': 'https://paperswithcode.com/paper/deepmind-control-suite'},\n",
       "  'GVGAI': {'full_name': 'General Video Game AI',\n",
       "   'variants': ['GVGAI'],\n",
       "   'title': 'General Video Game AI: Competition, Challenges and Opportunities',\n",
       "   'url': 'http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11853'},\n",
       "  'StarData': {'full_name': 'StarData',\n",
       "   'variants': ['StarData'],\n",
       "   'title': 'STARDATA: A StarCraft AI Research Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/stardata-a-starcraft-ai-research-dataset'},\n",
       "  'Atari-HEAD': {'full_name': None,\n",
       "   'variants': ['Atari-HEAD'],\n",
       "   'title': 'Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/atari-head-atari-human-eye-tracking-and'},\n",
       "  'Mario AI': {'full_name': 'Mario AI',\n",
       "   'variants': ['Mario AI'],\n",
       "   'title': 'The 2009 Mario AI Competition',\n",
       "   'url': 'https://doi.org/10.1109/CEC.2010.5586133'},\n",
       "  'D4RL': {'full_name': 'D4RL',\n",
       "   'variants': ['D4RL'],\n",
       "   'title': 'D4RL: Datasets for Deep Data-Driven Reinforcement Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/datasets-for-data-driven-reinforcement'},\n",
       "  'AtariARI': {'full_name': 'Atari Annotated RAM Interface',\n",
       "   'variants': ['AtariARI'],\n",
       "   'title': 'Unsupervised State Representation Learning in Atari',\n",
       "   'url': 'https://paperswithcode.com/paper/unsupervised-state-representation-learning-in'},\n",
       "  'Lani': {'full_name': None,\n",
       "   'variants': ['Lani'],\n",
       "   'title': 'Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction',\n",
       "   'url': 'https://paperswithcode.com/paper/mapping-instructions-to-actions-in-3d'},\n",
       "  'CHALET': {'full_name': 'Cornell House Agent Learning Environment',\n",
       "   'variants': ['CHALET'],\n",
       "   'title': 'CHALET: Cornell House Agent Learning Environment',\n",
       "   'url': 'https://paperswithcode.com/paper/chalet-cornell-house-agent-learning'},\n",
       "  'Griddly': {'full_name': 'Griddly',\n",
       "   'variants': ['Griddly'],\n",
       "   'title': 'Griddly: A platform for AI research in games',\n",
       "   'url': 'https://paperswithcode.com/paper/griddly-a-platform-for-ai-research-in-games'},\n",
       "  'NomBank': {'full_name': 'NomBank',\n",
       "   'variants': ['NomBank'],\n",
       "   'title': 'The NomBank Project: An Interim Report',\n",
       "   'url': 'https://www.aclweb.org/anthology/W04-2705/'},\n",
       "  'QA-SRL': {'full_name': 'QA-SRL',\n",
       "   'variants': ['QA-SRL'],\n",
       "   'title': 'Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language',\n",
       "   'url': 'https://paperswithcode.com/paper/question-answer-driven-semantic-role-labeling'},\n",
       "  'SParC': {'full_name': 'Semantic Parsing in Context',\n",
       "   'variants': ['SParC'],\n",
       "   'title': 'SParC: Cross-Domain Semantic Parsing in Context',\n",
       "   'url': 'https://paperswithcode.com/paper/sparc-cross-domain-semantic-parsing-in'},\n",
       "  'CoNLL 2002': {'full_name': '',\n",
       "   'variants': ['CoNLL 2002 (Spanish)',\n",
       "    'CoNLL 2002 (Dutch)',\n",
       "    'CoNLL 2002',\n",
       "    'conll2002'],\n",
       "   'title': 'Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition',\n",
       "   'url': 'https://www.aclweb.org/anthology/W02-2024/'},\n",
       "  'Panlex': {'full_name': '',\n",
       "   'variants': ['Panlex'],\n",
       "   'title': 'PanLex: Building a Resource for Panlingual Lexical Translation',\n",
       "   'url': 'https://paperswithcode.com/paper/panlex-building-a-resource-for-panlingual'},\n",
       "  'MCScript': {'full_name': 'MCScript',\n",
       "   'variants': ['MCScript'],\n",
       "   'title': 'MCScript: A Novel Dataset for Assessing Machine Comprehension Using Script Knowledge',\n",
       "   'url': 'https://paperswithcode.com/paper/mcscript-a-novel-dataset-for-assessing'},\n",
       "  'KP20k': {'full_name': 'KP20k',\n",
       "   'variants': ['KP20k'],\n",
       "   'title': 'Deep Keyphrase Generation',\n",
       "   'url': 'https://paperswithcode.com/paper/deep-keyphrase-generation'},\n",
       "  'Semantic Scholar': {'full_name': 'Semantic Scholar',\n",
       "   'variants': ['Semantic Scholar'],\n",
       "   'title': 'Construction of the Literature Graph in Semantic Scholar',\n",
       "   'url': 'https://paperswithcode.com/paper/construction-of-the-literature-graph-in'},\n",
       "  'EVALution': {'full_name': 'EVALution',\n",
       "   'variants': ['EVALution'],\n",
       "   'title': 'EVALution 1.0: an Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models',\n",
       "   'url': 'https://paperswithcode.com/paper/evalution-10-an-evolving-semantic-dataset-for'},\n",
       "  'Senseval-2': {'full_name': 'Senseval-2',\n",
       "   'variants': ['Senseval-2'],\n",
       "   'title': 'SENSEVAL-2: Overview',\n",
       "   'url': 'https://www.aclweb.org/anthology/S01-1001/'},\n",
       "  'RoboCup': {'full_name': 'RoboCup',\n",
       "   'variants': ['RoboCup'],\n",
       "   'title': 'Learning to sportscast: a test of grounded language acquisition',\n",
       "   'url': 'https://doi.org/10.1145/1390156.1390173'},\n",
       "  'ShARC': {'full_name': 'Shaping Answers with Rules through Conversation',\n",
       "   'variants': ['ShARC'],\n",
       "   'title': 'Interpretation of Natural Language Rules in Conversational Machine Reading',\n",
       "   'url': 'https://paperswithcode.com/paper/interpretation-of-natural-language-rules-in'},\n",
       "  'Social IQA': {'full_name': 'Social Interaction QA',\n",
       "   'variants': ['Social IQA'],\n",
       "   'title': 'Social IQa: Commonsense Reasoning about Social Interactions',\n",
       "   'url': 'https://paperswithcode.com/paper/social-iqa-commonsense-reasoning-about-social'},\n",
       "  'OLID': {'full_name': 'Offensive Language Identification Dataset',\n",
       "   'variants': ['OLID'],\n",
       "   'title': 'Predicting the Type and Target of Offensive Posts in Social Media',\n",
       "   'url': 'https://paperswithcode.com/paper/predicting-the-type-and-target-of-offensive'},\n",
       "  'Multi-News': {'full_name': 'Multi-News',\n",
       "   'variants': ['MultiNews val', 'MultiNews test', 'Multi-News', 'multi_news'],\n",
       "   'title': 'Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model',\n",
       "   'url': 'https://paperswithcode.com/paper/multi-news-a-large-scale-multi-document'},\n",
       "  'CLOTH': {'full_name': 'CLOze test by TeacHers',\n",
       "   'variants': ['CLOTH'],\n",
       "   'title': 'Large-scale Cloze Test Dataset Created by Teachers',\n",
       "   'url': 'https://paperswithcode.com/paper/large-scale-cloze-test-dataset-created-by'},\n",
       "  'CosmosQA': {'full_name': '',\n",
       "   'variants': ['CosmosQA'],\n",
       "   'title': 'Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/cosmos-qa-machine-reading-comprehension-with'},\n",
       "  'WinoBias': {'full_name': 'WinoBias',\n",
       "   'variants': ['WinoBias'],\n",
       "   'title': 'Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods',\n",
       "   'url': 'https://paperswithcode.com/paper/gender-bias-in-coreference-resolution-1'},\n",
       "  'Spades': {'full_name': 'Semantic PArsing of DEclarative Sentences',\n",
       "   'variants': ['Spades'],\n",
       "   'title': 'Evaluating Induced CCG Parsers on Grounded Semantic Parsing',\n",
       "   'url': 'https://paperswithcode.com/paper/evaluating-induced-ccg-parsers-on-grounded'},\n",
       "  'WikiSum': {'full_name': 'WikiSum',\n",
       "   'variants': ['WikiSum'],\n",
       "   'title': 'Generating Wikipedia by Summarizing Long Sequences',\n",
       "   'url': 'https://paperswithcode.com/paper/generating-wikipedia-by-summarizing-long'},\n",
       "  'DRCD': {'full_name': 'Delta Reading Comprehension Dataset',\n",
       "   'variants': ['DRCD (Traditional Chinese) Dev',\n",
       "    'DRCD (Traditional Chinese)',\n",
       "    'DRCD'],\n",
       "   'title': 'DRCD: a Chinese Machine Reading Comprehension Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/drcd-a-chinese-machine-reading-comprehension'},\n",
       "  'EmotionLines': {'full_name': 'EmotionLines',\n",
       "   'variants': ['EmotionPush', 'EmotionLines'],\n",
       "   'title': 'EmotionLines: An Emotion Corpus of Multi-Party Conversations',\n",
       "   'url': 'https://paperswithcode.com/paper/emotionlines-an-emotion-corpus-of-multi-party'},\n",
       "  'Chinese Gigaword': {'full_name': 'Chinese Gigaword',\n",
       "   'variants': ['Chinese Gigaword'],\n",
       "   'title': 'LDC Catalog No.: LDC2003T09, ISBN',\n",
       "   'url': 'https://catalog.ldc.upenn.edu/LDC2011T13'},\n",
       "  'CELEX': {'full_name': 'CELEX',\n",
       "   'variants': ['CELEX'],\n",
       "   'title': 'The CELEX lexical database',\n",
       "   'url': 'https://catalog.ldc.upenn.edu/LDC96L14'},\n",
       "  'MuST-C': {'full_name': '',\n",
       "   'variants': ['MuST-C EN->DE', 'MuST-C'],\n",
       "   'title': 'MuST-C: a Multilingual Speech Translation Corpus',\n",
       "   'url': 'https://paperswithcode.com/paper/must-c-a-multilingual-speech-translation'},\n",
       "  'Who-did-What': {'full_name': 'Who did What',\n",
       "   'variants': ['Who-did-What'],\n",
       "   'title': 'Who did What: A Large-Scale Person-Centered Cloze Dataset',\n",
       "   'url': 'https://paperswithcode.com/paper/who-did-what-a-large-scale-person-centered'},\n",
       "  'MetaQA': {'full_name': 'MoviE Text Audio QA',\n",
       "   'variants': ['MetaQA'],\n",
       "   'title': 'Variational Reasoning for Question Answering with Knowledge Graph',\n",
       "   'url': 'https://paperswithcode.com/paper/variational-reasoning-for-question-answering'},\n",
       "  'FakeNewsNet': {'full_name': 'FakeNewsNet',\n",
       "   'variants': ['FakeNewsNet'],\n",
       "   'title': 'FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media',\n",
       "   'url': 'https://paperswithcode.com/paper/fakenewsnet-a-data-repository-with-news'},\n",
       "  'STS 2014': {'full_name': 'STS 2014',\n",
       "   'variants': ['STS 2014'],\n",
       "   'title': 'SemEval-2014 Task 10: Multilingual Semantic Textual Similarity',\n",
       "   'url': 'https://paperswithcode.com/paper/semeval-2014-task-10-multilingual-semantic'},\n",
       "  'MEDIA': {'full_name': 'MEDIA',\n",
       "   'variants': ['MEDIA'],\n",
       "   'title': 'The French MEDIA/EVALDA Project: the Evaluation of the Understanding Capability of Spoken Language Dialogue Systems',\n",
       "   'url': 'http://www.lrec-conf.org/proceedings/lrec2004/summaries/356.htm'},\n",
       "  'ASPEC': {'full_name': 'Asian Scientific Paper Excerpt Corpus',\n",
       "   'variants': ['ASPEC'],\n",
       "   'title': 'ASPEC: Asian Scientific Paper Excerpt Corpus',\n",
       "   'url': 'https://paperswithcode.com/paper/aspec-asian-scientific-paper-excerpt-corpus'},\n",
       "  'OMICS': {'full_name': 'Open Mind Indoor Common Sense',\n",
       "   'variants': ['OMICS'],\n",
       "   'title': 'Common Sense Data Acquisition for Indoor Mobile Robots',\n",
       "   'url': 'http://www.aaai.org/Library/AAAI/2004/aaai04-096.php'},\n",
       "  'QUASAR': {'full_name': 'QUestion Answering by Search And Reading',\n",
       "   'variants': ['Quasar', 'QUASAR'],\n",
       "   'title': 'Quasar: Datasets for Question Answering by Search and Reading',\n",
       "   'url': 'https://paperswithcode.com/paper/quasar-datasets-for-question-answering-by'},\n",
       "  'Dialogue State Tracking Challenge': {'full_name': 'Dialogue State Tracking Challenge',\n",
       "   'variants': ['Second dialogue state tracking challenge',\n",
       "    'Dialogue State Tracking Challenge'],\n",
       "   'title': 'The Dialog State Tracking Challenge',\n",
       "   'url': 'https://paperswithcode.com/paper/the-dialog-state-tracking-challenge'},\n",
       "  'ISEAR': {'full_name': 'International Survey on Emotion Antecedents and Reactions',\n",
       "   'variants': ['ISEAR'],\n",
       "   'title': 'Evidence for universality and cultural variation of differential emotion response patterning',\n",
       "   'url': 'https://doi.org/10.1037/0022-3514.67.1.55'},\n",
       "  'CMRC': {'full_name': 'Chinese Machine Reading Comprehension 2018',\n",
       "   'variants': ['CMRC 2018 (Simplified Chinese)', 'CMRC'],\n",
       "   'title': 'A Span-Extraction Dataset for Chinese Machine Reading Comprehension',\n",
       "   'url': 'https://paperswithcode.com/paper/a-span-extraction-dataset-for-chinese-machine'},\n",
       "  'PubMed RCT': {'full_name': 'PubMed 200k RCT',\n",
       "   'variants': ['PubMed RCT'],\n",
       "   'title': 'PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts',\n",
       "   'url': 'https://paperswithcode.com/paper/pubmed-200k-rct-a-dataset-for-sequential'},\n",
       "  'NSIDES': {'full_name': 'Offsides and Twosides (NSIDES v0.1)',\n",
       "   'variants': ['NSIDES'],\n",
       "   'title': 'Data-driven prediction of drug effects and interactions',\n",
       "   'url': 'http://doi.org/10.1126/scitranslmed.3003377'},\n",
       "  'DDI': {'full_name': '',\n",
       "   'variants': ['DDI extraction 2013 corpus', 'DDI'],\n",
       "   'title': 'Semeval-2013 task 9: Extraction of drug-drug interactions from biomedical texts (ddiextraction 2013)',\n",
       "   'url': 'https://www.aclweb.org/anthology/S13-2056.pdf'},\n",
       "  'Stylized ImageNet': {'full_name': 'Stylized ImageNet',\n",
       "   'variants': ['Stylized ImageNet'],\n",
       "   'title': 'ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness',\n",
       "   'url': 'https://paperswithcode.com/paper/imagenet-trained-cnns-are-biased-towards'},\n",
       "  'MuTual': {'full_name': 'MuTual',\n",
       "   'variants': ['MuTual'],\n",
       "   'title': 'MuTual: A Dataset for Multi-Turn Dialogue Reasoning',\n",
       "   'url': 'https://paperswithcode.com/paper/mutual-a-dataset-for-multi-turn-dialogue'},\n",
       "  'CRIM13': {'full_name': 'Caltech Resident-Intruder Mouse 13',\n",
       "   'variants': ['CRIM13'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'Imagewoof': {'full_name': 'Imagewoof',\n",
       "   'variants': ['Imagewoof'],\n",
       "   'title': 'fastai: A Layered API for Deep Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/fastai-a-layered-api-for-deep-learning'},\n",
       "  'Imagenette': {'full_name': 'Imagenette',\n",
       "   'variants': ['Imagenette'],\n",
       "   'title': 'fastai: A Layered API for Deep Learning',\n",
       "   'url': 'https://paperswithcode.com/paper/fastai-a-layered-api-for-deep-learning'},\n",
       "  'Stanford-ECM': {'full_name': 'Stanford-ECM',\n",
       "   'variants': ['Stanford-ECM'],\n",
       "   'title': 'Jointly Learning Energy Expenditures and Activities Using Egocentric Multimodal Signals',\n",
       "   'url': 'https://paperswithcode.com/paper/jointly-learning-energy-expenditures-and'},\n",
       "  'BSD': {'full_name': 'Berkeley Segmentation Dataset',\n",
       "   'variants': ['BSD68 sigma65',\n",
       "    'BSD68 sigma60',\n",
       "    'BSD68 sigma55',\n",
       "    'BSD68 sigma45',\n",
       "    'BSD68 sigma40',\n",
       "    'BSD68 sigma20',\n",
       "    'BSD68 CS=50%',\n",
       "    'BSDS300',\n",
       "    'BSDS100 - 8x upscaling',\n",
       "    'BSDS100 - 4x upscaling',\n",
       "    'BSDS100 - 2x upscaling',\n",
       "    'BSD68 sigma75',\n",
       "    'BSD68 sigma70',\n",
       "    'BSD68 sigma50',\n",
       "    'BSD68 sigma5',\n",
       "    'BSD68 sigma35',\n",
       "    'BSD68 sigma30',\n",
       "    'BSD68 sigma25',\n",
       "    'BSD68 sigma15',\n",
       "    'BSD68 sigma10',\n",
       "    'BSD200 sigma70',\n",
       "    'BSD200 sigma50',\n",
       "    'BSD200 sigma30',\n",
       "    'BSD200 sigma10',\n",
       "    'BSD200 - 2x upscaling',\n",
       "    'BSD',\n",
       "    'BSD300 sigma70',\n",
       "    'BSD300 sigma50',\n",
       "    'BSD300 sigma30',\n",
       "    'BSD300 Noise Level 70%',\n",
       "    'BSD300 Noise Level 50%',\n",
       "    'BSD300 Noise Level 30%',\n",
       "    'BSD100 - 8x upscaling',\n",
       "    'BSD100 - 4x upscaling',\n",
       "    'BSD100 - 3x upscaling',\n",
       "    'BSD100 - 2x upscaling',\n",
       "    'BSD100 - 16x upscaling'],\n",
       "   'title': 'A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics',\n",
       "   'url': 'http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=937655'},\n",
       "  'THUMOS14': {'full_name': 'THUMOS 2014',\n",
       "   'variants': [\"THUMOS' 14\",\n",
       "    'THUMOS 2014',\n",
       "    'THUMOS’14',\n",
       "    \"THUMOS'14\",\n",
       "    'THUMOS14'],\n",
       "   'title': 'THUMOS challenge: Action recognition with a large number of classes',\n",
       "   'url': 'http://www.thumos.info/'},\n",
       "  'MSRA Hand': {'full_name': 'MSRA Hand',\n",
       "   'variants': ['MSRA Hands', 'MSRA Hand'],\n",
       "   'title': 'Realtime and Robust Hand Tracking from Depth',\n",
       "   'url': 'https://paperswithcode.com/paper/realtime-and-robust-hand-tracking-from-depth'},\n",
       "  'MSRA10K': {'full_name': 'MSRA10K Salient Object Database',\n",
       "   'variants': ['MSRA10K'],\n",
       "   'title': None,\n",
       "   'url': None},\n",
       "  'JHMDB': {'full_name': 'Joint-annotated Human Motion Data Base',\n",
       "   'variants': ['JHMDB',\n",
       "    'J-HMBD Early Action',\n",
       "    'JHMDB Pose Tracking',\n",
       "    'JHMDB (2D poses only)',\n",
       "    'J-HMDB',\n",
       "    'J-HMDB-21'],\n",
       "   'title': 'Towards Understanding Action Recognition',\n",
       "   'url': 'https://doi.org/10.1109/ICCV.2013.396'},\n",
       "  'UCF-CC-50': {'full_name': 'UCF-CC-50',\n",
       "   'variants': ['UCF-CC-50'],\n",
       "   'title': 'Multi-source Multi-scale Counting in Extremely Dense Crowd Images',\n",
       "   'url': 'https://paperswithcode.com/paper/multi-source-multi-scale-counting-in'},\n",
       "  'AwA2': {'full_name': 'Animals with Attributes 2',\n",
       "   'variants': ['AWA2 - 0-Shot', 'AwA2'],\n",
       "   'title': 'Zero-Shot Learning -- A Comprehensive Evaluation of the Good, the Bad and the Ugly',\n",
       "   'url': 'https://paperswithcode.com/paper/zero-shot-learning-a-comprehensive-evaluation'},\n",
       "  'AwA': {'full_name': 'Animals with Attributes',\n",
       "   'variants': ['AWA1 - 0-Shot', 'AWA - 0-Shot', 'AwA', 'AwA2', 'AWA-LT'],\n",
       "   'title': 'Learning to detect unseen object classes by between-class attribute transfer',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.2009.5206594'},\n",
       "  'ARC': {'full_name': 'AI2 Reasoning Challenge',\n",
       "   'variants': ['ARC (Easy)', 'ARC (Challenge)', 'ARC'],\n",
       "   'title': 'Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge',\n",
       "   'url': 'https://paperswithcode.com/paper/think-you-have-solved-question-answering-try'},\n",
       "  'PASCAL VOC 2011': {'full_name': 'PASCAL VOC 2011',\n",
       "   'variants': ['PASCAL VOC 2011 test', 'PASCAL VOC 2011'],\n",
       "   'title': 'The PASCAL Visual Object Classes Challenge 2011 (VOC2011) Results',\n",
       "   'url': 'http://www.pascal-network.org/challenges/VOC/voc2011/workshop/index.html'},\n",
       "  '2D-3D-S': {'full_name': '2D-3D-Semantic',\n",
       "   'variants': ['2D-3D-S'],\n",
       "   'title': 'Joint 2D-3D-Semantic Data for Indoor Scene Understanding',\n",
       "   'url': 'https://paperswithcode.com/paper/joint-2d-3d-semantic-data-for-indoor-scene'},\n",
       "  'Color FERET': {'full_name': 'Color FERET',\n",
       "   'variants': ['Color FERET (Online Open Set)', 'Color FERET'],\n",
       "   'title': 'The FERET Evaluation Methodology for Face-Recognition Algorithms',\n",
       "   'url': 'https://doi.org/10.1109/CVPR.1997.609311'},\n",
       "  'ICDAR 2017': {'full_name': 'ICDAR 2017',\n",
       "   'variants': [' ICDAR 2017 MLT', 'ICDAR 2017 MLT', 'ICDAR 2017'],\n",
       "   'title': 'ICDAR2017 Robust Reading Challenge on COCO-Text',\n",
       "   'url': 'https://doi.org/10.1109/ICDAR.2017.234'},\n",
       "  ...},\n",
       " 'method_entities': {'Coresets': {'full_name': 'Coresets',\n",
       "   'url': 'http://arxiv.org/abs/1708.00489v4',\n",
       "   'title': 'Active Learning for Convolutional Neural Networks: A Core-Set Approach'},\n",
       "  'WaveGrad': {'full_name': 'WaveGrad',\n",
       "   'url': 'https://arxiv.org/abs/2009.00713v2',\n",
       "   'title': 'WaveGrad: Estimating Gradients for Waveform Generation'},\n",
       "  'Siamese Network': {'full_name': 'Siamese Network',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'NoisyNet-A3C': {'full_name': 'NoisyNet-A3C',\n",
       "   'url': 'https://arxiv.org/abs/1706.10295v3',\n",
       "   'title': 'Noisy Networks for Exploration'},\n",
       "  'NPID': {'full_name': 'NPID',\n",
       "   'url': 'http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html',\n",
       "   'title': 'Unsupervised Feature Learning via Non-Parametric Instance Discrimination'},\n",
       "  'Concatenation Affinity': {'full_name': 'Concatenation Affinity',\n",
       "   'url': 'http://arxiv.org/abs/1711.07971v3',\n",
       "   'title': 'Non-local Neural Networks'},\n",
       "  'A3C': {'full_name': 'A3C',\n",
       "   'url': 'http://arxiv.org/abs/1602.01783v2',\n",
       "   'title': 'Asynchronous Methods for Deep Reinforcement Learning'},\n",
       "  'GAP-Layer': {'full_name': 'Spectral Gap Rewiring Layer',\n",
       "   'url': 'https://arxiv.org/abs/2206.07369v1',\n",
       "   'title': 'DiffWire: Inductive Graph Rewiring via the Lovász Bound'},\n",
       "  'Split Attention': {'full_name': 'Split Attention',\n",
       "   'url': 'https://arxiv.org/abs/2004.08955v2',\n",
       "   'title': 'ResNeSt: Split-Attention Networks'},\n",
       "  'Sparse Convolutions': {'full_name': 'Sparse Convolutions',\n",
       "   'url': 'http://arxiv.org/abs/1409.6070v1',\n",
       "   'title': 'Spatially-sparse convolutional neural networks'},\n",
       "  'SPS': {'full_name': 'Semi-Pseudo-Label',\n",
       "   'url': 'https://arxiv.org/abs/2207.09869v1',\n",
       "   'title': 'A Novel Neural Network Training Method for Autonomous Driving Using Semi-Pseudo-Labels and 3D Data Augmentations'},\n",
       "  '1x1 Convolution': {'full_name': '1x1 Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1312.4400v3',\n",
       "   'title': 'Network In Network'},\n",
       "  'Nyströmformer': {'full_name': 'Nyströmformer',\n",
       "   'url': 'https://arxiv.org/abs/2102.03902v3',\n",
       "   'title': 'Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention'},\n",
       "  'PRNet+': {'full_name': 'PRNet+',\n",
       "   'url': 'https://arxiv.org/abs/2108.10613v1',\n",
       "   'title': 'Outdoor Position Recovery from HeterogeneousTelco Cellular Data'},\n",
       "  'Non-Linear-Bounding-Function': {'full_name': 'Lower Bound on Transmission Using Non-Linear Bounding Function in Single Image Dehazing',\n",
       "   'url': 'https://ieeexplore.ieee.org/document/9018379',\n",
       "   'title': 'Lower Bound on Transmission Using Non-Linear Bounding Function in Single Image Dehazing'},\n",
       "  'Self-Learning': {'full_name': None, 'url': None, 'title': None},\n",
       "  'KOVA': {'full_name': 'Kalman Optimization for Value Approximation',\n",
       "   'url': 'https://arxiv.org/abs/2002.07171v1',\n",
       "   'title': 'Kalman meets Bellman: Improving Policy Evaluation through Value Tracking'},\n",
       "  'Varifocal Loss': {'full_name': 'Varifocal Loss',\n",
       "   'url': 'https://arxiv.org/abs/2008.13367v2',\n",
       "   'title': 'VarifocalNet: An IoU-aware Dense Object Detector'},\n",
       "  'V-trace': {'full_name': 'V-trace',\n",
       "   'url': 'http://arxiv.org/abs/1802.01561v3',\n",
       "   'title': 'IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures'},\n",
       "  'RevSilo': {'full_name': 'RevSilo',\n",
       "   'url': 'https://arxiv.org/abs/2206.14098v1',\n",
       "   'title': 'RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network'},\n",
       "  'GIC': {'full_name': 'Graph InfoClust',\n",
       "   'url': 'https://arxiv.org/abs/2009.06946v1',\n",
       "   'title': 'Graph InfoClust: Leveraging cluster-level node information for unsupervised graph representation learning'},\n",
       "  'DeLighT': {'full_name': 'DeLighT',\n",
       "   'url': 'https://arxiv.org/abs/2008.00623v2',\n",
       "   'title': 'DeLighT: Deep and Light-weight Transformer'},\n",
       "  'PointNet': {'full_name': 'PointNet',\n",
       "   'url': 'http://arxiv.org/abs/1612.00593v2',\n",
       "   'title': 'PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation'},\n",
       "  'Scatter Connection': {'full_name': 'Scatter Connection',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Subformer': {'full_name': 'Subformer',\n",
       "   'url': 'https://arxiv.org/abs/2101.00234v3',\n",
       "   'title': 'Subformer: Exploring Weight Sharing for Parameter Efficiency in Generative Transformers'},\n",
       "  'GAM': {'full_name': 'Generalized additive models',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'SDNE': {'full_name': 'Structural Deep Network Embedding',\n",
       "   'url': 'https://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf',\n",
       "   'title': 'Structural Deep Network Embedding'},\n",
       "  '3D SA': {'full_name': '3 Dimensional Soft Attention',\n",
       "   'url': 'https://arxiv.org/abs/2009.04532v3',\n",
       "   'title': 'Attention based Writer Independent Handwriting Verification'},\n",
       "  'Informative Sample Mining Network': {'full_name': 'Informative Sample Mining Network',\n",
       "   'url': 'https://arxiv.org/abs/2001.01173v4',\n",
       "   'title': 'Informative Sample Mining Network for Multi-Domain Image-to-Image Translation'},\n",
       "  'Average Pooling': {'full_name': 'Average Pooling',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Non Maximum Suppression': {'full_name': 'Non Maximum Suppression',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Highway networks': {'full_name': 'Highway networks',\n",
       "   'url': 'http://arxiv.org/abs/1505.00387v2',\n",
       "   'title': 'Highway Networks'},\n",
       "  'StyleALAE': {'full_name': 'StyleALAE',\n",
       "   'url': 'https://arxiv.org/abs/2004.04467v1',\n",
       "   'title': 'Adversarial Latent Autoencoders'},\n",
       "  'SCCL': {'full_name': 'Supporting Clustering with Contrastive Learning',\n",
       "   'url': 'https://arxiv.org/abs/2103.12953v2',\n",
       "   'title': 'Supporting Clustering with Contrastive Learning'},\n",
       "  'Matrix NMS': {'full_name': 'Matrix Non-Maximum Suppression',\n",
       "   'url': 'https://arxiv.org/abs/2003.10152v3',\n",
       "   'title': 'SOLOv2: Dynamic and Fast Instance Segmentation'},\n",
       "  'Attention-augmented Convolution': {'full_name': 'Attention-augmented Convolution',\n",
       "   'url': 'https://arxiv.org/abs/1904.09925v5',\n",
       "   'title': 'Attention Augmented Convolutional Networks'},\n",
       "  'GEOMANCER': {'full_name': 'Geometric Manifold Component Estimator',\n",
       "   'url': 'https://arxiv.org/abs/2006.12982v2',\n",
       "   'title': 'Disentangling by Subspace Diffusion'},\n",
       "  'SCNN_UNet_ConvLSTM': {'full_name': 'Spatial CNN with UNet based Encoder-decoder and ConvLSTM',\n",
       "   'url': 'https://arxiv.org/abs/2110.04079v5',\n",
       "   'title': 'A Hybrid Spatial-temporal Deep Learning Architecture for Lane Detection'},\n",
       "  'Neighborhood Attention': {'full_name': 'Neighborhood Attention',\n",
       "   'url': 'https://arxiv.org/abs/2204.07143v2',\n",
       "   'title': 'Neighborhood Attention Transformer'},\n",
       "  'Squared ReLU': {'full_name': 'Squared ReLU',\n",
       "   'url': 'https://arxiv.org/abs/2109.08668v2',\n",
       "   'title': 'Primer: Searching for Efficient Transformers for Language Modeling'},\n",
       "  'CenterMask': {'full_name': 'CenterMask',\n",
       "   'url': 'https://arxiv.org/abs/1911.06667v6',\n",
       "   'title': 'CenterMask : Real-Time Anchor-Free Instance Segmentation'},\n",
       "  'bilayer decoupling': {'full_name': 'bilayer convolutional neural network',\n",
       "   'url': 'https://arxiv.org/abs/2103.12340v1',\n",
       "   'title': 'Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers'},\n",
       "  'VocGAN': {'full_name': 'VocGAN',\n",
       "   'url': 'https://arxiv.org/abs/2007.15256v1',\n",
       "   'title': 'VocGAN: A High-Fidelity Real-time Vocoder with a Hierarchically-nested Adversarial Network'},\n",
       "  'Serf': {'full_name': 'Serf',\n",
       "   'url': 'https://arxiv.org/abs/2108.09598v3',\n",
       "   'title': 'SERF: Towards better training of deep neural networks using log-Softplus ERror activation Function'},\n",
       "  'CrossTransformers': {'full_name': 'CrossTransformers',\n",
       "   'url': 'https://arxiv.org/abs/2007.11498v5',\n",
       "   'title': 'CrossTransformers: spatially-aware few-shot transfer'},\n",
       "  'Laplacian Pyramid': {'full_name': 'Laplacian Pyramid',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'DualCL': {'full_name': 'Dual Contrastive Learning',\n",
       "   'url': 'https://arxiv.org/abs/2201.08702v1',\n",
       "   'title': 'Dual Contrastive Learning: Text Classification via Label-Aware Data Augmentation'},\n",
       "  'Libra R-CNN': {'full_name': 'Libra R-CNN',\n",
       "   'url': 'http://arxiv.org/abs/1904.02701v1',\n",
       "   'title': 'Libra R-CNN: Towards Balanced Learning for Object Detection'},\n",
       "  'ReGLU': {'full_name': 'ReGLU',\n",
       "   'url': 'https://arxiv.org/abs/2002.05202v1',\n",
       "   'title': 'GLU Variants Improve Transformer'},\n",
       "  'CMCL': {'full_name': 'Crossmodal Contrastive Learning',\n",
       "   'url': 'https://arxiv.org/abs/2012.15409v4',\n",
       "   'title': 'UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning'},\n",
       "  'WaveRNN': {'full_name': 'WaveRNN',\n",
       "   'url': 'http://arxiv.org/abs/1802.08435v2',\n",
       "   'title': 'Efficient Neural Audio Synthesis'},\n",
       "  'U-Net GAN': {'full_name': 'U-Net Generative Adversarial Network',\n",
       "   'url': 'http://openaccess.thecvf.com/content_CVPR_2020/html/Schonfeld_A_U-Net_Based_Discriminator_for_Generative_Adversarial_Networks_CVPR_2020_paper.html',\n",
       "   'title': 'A U-Net Based Discriminator for Generative Adversarial Networks'},\n",
       "  'ResMLP': {'full_name': 'Residual Multi-Layer Perceptrons',\n",
       "   'url': 'https://arxiv.org/abs/2105.03404v2',\n",
       "   'title': 'ResMLP: Feedforward networks for image classification with data-efficient training'},\n",
       "  'CenterNet': {'full_name': 'CenterNet',\n",
       "   'url': 'http://arxiv.org/abs/1904.08189v3',\n",
       "   'title': 'CenterNet: Keypoint Triplets for Object Detection'},\n",
       "  'ESP': {'full_name': 'Efficient Spatial Pyramid',\n",
       "   'url': 'http://arxiv.org/abs/1803.06815v3',\n",
       "   'title': 'ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation'},\n",
       "  'NoisyNet-Dueling': {'full_name': 'NoisyNet-Dueling',\n",
       "   'url': 'https://arxiv.org/abs/1706.10295v3',\n",
       "   'title': 'Noisy Networks for Exploration'},\n",
       "  'Talking-Heads Attention': {'full_name': 'Talking-Heads Attention',\n",
       "   'url': 'https://arxiv.org/abs/2003.02436v1',\n",
       "   'title': 'Talking-Heads Attention'},\n",
       "  'DECA': {'full_name': 'Detailed Expression Capture and Animation',\n",
       "   'url': 'https://arxiv.org/abs/2012.04012v2',\n",
       "   'title': 'Learning an Animatable Detailed 3D Face Model from In-The-Wild Images'},\n",
       "  'ERU': {'full_name': 'Efficient Recurrent Unit',\n",
       "   'url': 'http://arxiv.org/abs/1811.11431v3',\n",
       "   'title': 'ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network'},\n",
       "  'AutoGAN': {'full_name': 'AutoGAN',\n",
       "   'url': 'https://arxiv.org/abs/1908.03835v1',\n",
       "   'title': 'AutoGAN: Neural Architecture Search for Generative Adversarial Networks'},\n",
       "  'PipeDream-2BW': {'full_name': 'PipeDream-2BW',\n",
       "   'url': 'https://arxiv.org/abs/2006.09503v3',\n",
       "   'title': 'Memory-Efficient Pipeline-Parallel DNN Training'},\n",
       "  'SGD with Momentum': {'full_name': 'SGD with Momentum',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'VideoBERT': {'full_name': 'VideoBERT',\n",
       "   'url': 'https://arxiv.org/abs/1904.01766v2',\n",
       "   'title': 'VideoBERT: A Joint Model for Video and Language Representation Learning'},\n",
       "  'MFR': {'full_name': 'Meta Face Recognition',\n",
       "   'url': 'https://arxiv.org/abs/2003.07733v2',\n",
       "   'title': 'Learning Meta Face Recognition in Unseen Domains'},\n",
       "  'Parrot': {'full_name': 'Parrot',\n",
       "   'url': 'https://arxiv.org/abs/2006.16239v2',\n",
       "   'title': 'An Imitation Learning Approach for Cache Replacement'},\n",
       "  'CTRL': {'full_name': 'CTRL',\n",
       "   'url': 'https://arxiv.org/abs/1909.05858v2',\n",
       "   'title': 'CTRL: A Conditional Transformer Language Model for Controllable Generation'},\n",
       "  'Manifold Mixup': {'full_name': 'Manifold Mixup',\n",
       "   'url': 'https://arxiv.org/abs/1806.05236v7',\n",
       "   'title': 'Manifold Mixup: Better Representations by Interpolating Hidden States'},\n",
       "  'PREDATOR': {'full_name': 'PREDATOR',\n",
       "   'url': 'https://arxiv.org/abs/2011.13005v3',\n",
       "   'title': 'PREDATOR: Registration of 3D Point Clouds with Low Overlap'},\n",
       "  'PWIL': {'full_name': 'Primal Wasserstein Imitation Learning',\n",
       "   'url': 'https://arxiv.org/abs/2006.04678v2',\n",
       "   'title': 'Primal Wasserstein Imitation Learning'},\n",
       "  'ShuffleNet Block': {'full_name': 'ShuffleNet Block',\n",
       "   'url': 'http://arxiv.org/abs/1707.01083v2',\n",
       "   'title': 'ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices'},\n",
       "  'Random Search': {'full_name': 'Random Search', 'url': None, 'title': None},\n",
       "  'NAS-FPN': {'full_name': 'NAS-FPN',\n",
       "   'url': 'http://arxiv.org/abs/1904.07392v1',\n",
       "   'title': 'NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection'},\n",
       "  'PPMC': {'full_name': 'Path Planning and Motion Control',\n",
       "   'url': 'https://arxiv.org/abs/2003.02655v2',\n",
       "   'title': 'PPMC RL Training Algorithm: Rough Terrain Intelligent Robots through Reinforcement Learning'},\n",
       "  'Channel-wise Cross Attention': {'full_name': 'Channel-wise Cross Attention',\n",
       "   'url': 'https://arxiv.org/abs/2109.04335v3',\n",
       "   'title': 'UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer'},\n",
       "  'Harm-Net': {'full_name': 'Harm-Net',\n",
       "   'url': 'https://arxiv.org/abs/2001.06570v3',\n",
       "   'title': 'Harmonic Convolutional Networks based on Discrete Cosine Transform'},\n",
       "  'CPVT': {'full_name': 'Conditional Position Encoding Vision Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2102.10882v2',\n",
       "   'title': 'Conditional Positional Encodings for Vision Transformers'},\n",
       "  'BiFPN': {'full_name': 'BiFPN',\n",
       "   'url': 'https://arxiv.org/abs/1911.09070v7',\n",
       "   'title': 'EfficientDet: Scalable and Efficient Object Detection'},\n",
       "  'SRN': {'full_name': 'Stable Rank Normalization',\n",
       "   'url': 'https://arxiv.org/abs/1906.04659v3',\n",
       "   'title': 'Stable Rank Normalization for Improved Generalization in Neural Networks and GANs'},\n",
       "  'Weight Decay': {'full_name': 'Weight Decay', 'url': None, 'title': None},\n",
       "  'Denoising Score Matching': {'full_name': 'Denoising Score Matching',\n",
       "   'url': 'https://arxiv.org/abs/1907.05600v3',\n",
       "   'title': 'Generative Modeling by Estimating Gradients of the Data Distribution'},\n",
       "  'CoVe': {'full_name': 'Contextual Word Vectors',\n",
       "   'url': 'http://arxiv.org/abs/1708.00107v2',\n",
       "   'title': 'Learned in Translation: Contextualized Word Vectors'},\n",
       "  'DenseNAS-B': {'full_name': 'DenseNAS-B',\n",
       "   'url': 'https://arxiv.org/abs/1906.09607v3',\n",
       "   'title': 'Densely Connected Search Space for More Flexible Neural Architecture Search'},\n",
       "  'MSGAN': {'full_name': 'Multi-source Sentiment Generative Adversarial Network',\n",
       "   'url': 'https://arxiv.org/abs/2001.03886v1',\n",
       "   'title': 'Multi-source Domain Adaptation for Visual Sentiment Classification'},\n",
       "  'NEAT': {'full_name': 'Neural Attention Fields',\n",
       "   'url': 'https://arxiv.org/abs/2109.04456v1',\n",
       "   'title': 'NEAT: Neural Attention Fields for End-to-End Autonomous Driving'},\n",
       "  'YOLOv2': {'full_name': 'YOLOv2',\n",
       "   'url': 'http://arxiv.org/abs/1612.08242v1',\n",
       "   'title': 'YOLO9000: Better, Faster, Stronger'},\n",
       "  'ProxylessNet-CPU': {'full_name': 'ProxylessNet-CPU',\n",
       "   'url': 'http://arxiv.org/abs/1812.00332v2',\n",
       "   'title': 'ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware'},\n",
       "  'ISPL': {'full_name': 'Implicit Subspace Prior Learning',\n",
       "   'url': 'https://arxiv.org/abs/2010.05508v1',\n",
       "   'title': 'Implicit Subspace Prior Learning for Dual-Blind Face Restoration'},\n",
       "  'OSCAR': {'full_name': 'OSCAR',\n",
       "   'url': 'https://arxiv.org/abs/2004.06165v5',\n",
       "   'title': 'Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks'},\n",
       "  'SuperpixelGridMasks': {'full_name': 'SuperpixelGridCut, SuperpixelGridMean, SuperpixelGridMix',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Graph Contrastive Coding': {'full_name': 'Graph Contrastive Coding',\n",
       "   'url': 'https://arxiv.org/abs/2006.09963v3',\n",
       "   'title': 'GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training'},\n",
       "  'Cycle Consistency Loss': {'full_name': 'Cycle Consistency Loss',\n",
       "   'url': 'https://arxiv.org/abs/1703.10593v7',\n",
       "   'title': 'Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks'},\n",
       "  'GraphESN': {'full_name': 'Graph Echo State Network',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'CRISS': {'full_name': 'CRISS',\n",
       "   'url': 'https://arxiv.org/abs/2006.09526v2',\n",
       "   'title': 'Cross-lingual Retrieval for Iterative Self-Supervised Training'},\n",
       "  'NeuralRecon': {'full_name': 'NeuralRecon',\n",
       "   'url': 'https://arxiv.org/abs/2104.00681v1',\n",
       "   'title': 'NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video'},\n",
       "  'PixelShuffle': {'full_name': 'PixelShuffle',\n",
       "   'url': 'http://arxiv.org/abs/1609.05158v2',\n",
       "   'title': 'Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network'},\n",
       "  'WYS': {'full_name': 'Watch Your Step',\n",
       "   'url': 'http://arxiv.org/abs/1710.09599v2',\n",
       "   'title': 'Watch Your Step: Learning Node Embeddings via Graph Attention'},\n",
       "  'Adaptive Input Representations': {'full_name': 'Adaptive Input Representations',\n",
       "   'url': 'http://arxiv.org/abs/1809.10853v3',\n",
       "   'title': 'Adaptive Input Representations for Neural Language Modeling'},\n",
       "  'SCAN-clustering': {'full_name': 'Semantic Clustering by Adopting Nearest Neighbours',\n",
       "   'url': 'https://arxiv.org/abs/2005.12320v2',\n",
       "   'title': 'SCAN: Learning to Classify Images without Labels'},\n",
       "  'POTO': {'full_name': 'Prediction-aware One-To-One',\n",
       "   'url': 'https://arxiv.org/abs/2012.03544v3',\n",
       "   'title': 'End-to-End Object Detection with Fully Convolutional Network'},\n",
       "  'A2C': {'full_name': 'A2C',\n",
       "   'url': 'http://arxiv.org/abs/1602.01783v2',\n",
       "   'title': 'Asynchronous Methods for Deep Reinforcement Learning'},\n",
       "  'Demon ADAM': {'full_name': 'Demon ADAM',\n",
       "   'url': 'https://arxiv.org/abs/1910.04952v4',\n",
       "   'title': 'Demon: Improved Neural Network Training with Momentum Decay'},\n",
       "  'Cross-Attention Module': {'full_name': 'Cross-Attention Module',\n",
       "   'url': 'https://arxiv.org/abs/2103.14899v2',\n",
       "   'title': 'CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification'},\n",
       "  'Virtual Batch Normalization': {'full_name': 'Virtual Batch Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1606.03498v1',\n",
       "   'title': 'Improved Techniques for Training GANs'},\n",
       "  'N-step Returns': {'full_name': 'N-step Returns',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'ShakeDrop': {'full_name': 'ShakeDrop',\n",
       "   'url': 'https://arxiv.org/abs/1802.02375v3',\n",
       "   'title': 'ShakeDrop Regularization for Deep Residual Learning'},\n",
       "  'LeVIT': {'full_name': 'LeVIT',\n",
       "   'url': 'https://arxiv.org/abs/2104.01136v2',\n",
       "   'title': \"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference\"},\n",
       "  'Triplet Attention': {'full_name': 'Triplet Attention',\n",
       "   'url': 'https://arxiv.org/abs/2010.03045v2',\n",
       "   'title': 'Rotate to Attend: Convolutional Triplet Attention Module'},\n",
       "  'Patch Merger': {'full_name': 'Patch Merger Module',\n",
       "   'url': 'https://arxiv.org/abs/2202.12015v1',\n",
       "   'title': 'Learning to Merge Tokens in Vision Transformers'},\n",
       "  'm-arcsinh': {'full_name': 'modified arcsinh',\n",
       "   'url': 'https://arxiv.org/abs/2009.07530v1',\n",
       "   'title': 'm-arcsinh: An Efficient and Reliable Function for SVM and MLP in scikit-learn'},\n",
       "  'SERLU': {'full_name': 'SERLU',\n",
       "   'url': 'http://arxiv.org/abs/1807.10117v2',\n",
       "   'title': 'Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)'},\n",
       "  'MDL': {'full_name': 'Minimum Description Length',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'MPNet': {'full_name': 'MPNet',\n",
       "   'url': 'https://arxiv.org/abs/2004.09297v2',\n",
       "   'title': 'MPNet: Masked and Permuted Pre-training for Language Understanding'},\n",
       "  'SELU': {'full_name': 'Scaled Exponential Linear Unit',\n",
       "   'url': 'http://arxiv.org/abs/1706.02515v5',\n",
       "   'title': 'Self-Normalizing Neural Networks'},\n",
       "  'ThunderNet': {'full_name': 'ThunderNet',\n",
       "   'url': 'https://arxiv.org/abs/1903.11752v3',\n",
       "   'title': 'ThunderNet: Towards Real-time Generic Object Detection'},\n",
       "  'TPN': {'full_name': 'Temporal Pyramid Network',\n",
       "   'url': 'https://arxiv.org/abs/2004.03548v2',\n",
       "   'title': 'Temporal Pyramid Network for Action Recognition'},\n",
       "  'ALDA': {'full_name': 'ALDA',\n",
       "   'url': 'https://arxiv.org/abs/2001.01046v1',\n",
       "   'title': 'Adversarial-Learned Loss for Domain Adaptation'},\n",
       "  'IPA-GNN': {'full_name': 'Instruction Pointer Attention Graph Neural Network',\n",
       "   'url': 'https://arxiv.org/abs/2010.12621v1',\n",
       "   'title': 'Learning to Execute Programs with Instruction Pointer Attention Graph Neural Networks'},\n",
       "  'SimAug': {'full_name': 'Simulation as Augmentation',\n",
       "   'url': 'https://arxiv.org/abs/2004.02022v2',\n",
       "   'title': 'SimAug: Learning Robust Representations from 3D Simulation for Pedestrian Trajectory Prediction in Unseen Cameras'},\n",
       "  'Layer Normalization': {'full_name': 'Layer Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1607.06450v1',\n",
       "   'title': 'Layer Normalization'},\n",
       "  'ZCA Whitening': {'full_name': 'ZCA Whitening', 'url': None, 'title': None},\n",
       "  'Efficient Channel Attention': {'full_name': 'Efficient Channel Attention',\n",
       "   'url': 'https://arxiv.org/abs/1910.03151v4',\n",
       "   'title': 'ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks'},\n",
       "  'PixelCNN': {'full_name': 'PixelCNN',\n",
       "   'url': 'http://arxiv.org/abs/1601.06759v3',\n",
       "   'title': 'Pixel Recurrent Neural Networks'},\n",
       "  'Vokenization': {'full_name': 'Vokenization',\n",
       "   'url': 'https://arxiv.org/abs/2010.06775v1',\n",
       "   'title': 'Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision'},\n",
       "  'SSFG regularization': {'full_name': 'Stochastically Scaling Features and Gradients Regularization',\n",
       "   'url': 'https://arxiv.org/abs/2102.10338v2',\n",
       "   'title': 'SSFG: Stochastically Scaling Features and Gradients for Regularizing Graph Convolutional Networks'},\n",
       "  'DropAttack': {'full_name': 'DropAttack',\n",
       "   'url': 'https://arxiv.org/abs/2108.12805v1',\n",
       "   'title': 'DropAttack: A Masked Weight Adversarial Training Method to Improve Generalization of Neural Networks'},\n",
       "  'VQSVD': {'full_name': 'VQSVD',\n",
       "   'url': 'https://arxiv.org/abs/2006.02336v3',\n",
       "   'title': 'Variational Quantum Singular Value Decomposition'},\n",
       "  'Locally-Grouped Self-Attention': {'full_name': 'Locally-Grouped Self-Attention',\n",
       "   'url': 'https://arxiv.org/abs/2104.13840v4',\n",
       "   'title': 'Twins: Revisiting the Design of Spatial Attention in Vision Transformers'},\n",
       "  'Pipelined Backpropagation': {'full_name': 'Pipelined Backpropagation',\n",
       "   'url': 'https://arxiv.org/abs/2003.11666v3',\n",
       "   'title': 'Pipelined Backpropagation at Scale: Training Large Models without Batches'},\n",
       "  'RegNetX': {'full_name': 'RegNetX',\n",
       "   'url': 'https://arxiv.org/abs/2003.13678v1',\n",
       "   'title': 'Designing Network Design Spaces'},\n",
       "  'Hierarchical Network Dissection': {'full_name': 'Hierarchical Network Dissection',\n",
       "   'url': 'https://arxiv.org/abs/2108.10360v2',\n",
       "   'title': 'Interpreting Face Inference Models using Hierarchical Network Dissection'},\n",
       "  'Syntax Heat Parse Tree': {'full_name': 'Syntax Heat Parse Tree',\n",
       "   'url': 'https://aclanthology.org/2020.emnlp-main.18',\n",
       "   'title': 'KERMIT: Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations'},\n",
       "  'Auto-Classifier': {'full_name': 'Auto-Classifier',\n",
       "   'url': 'https://arxiv.org/abs/2009.01573v1',\n",
       "   'title': 'Auto-Classifier: A Robust Defect Detector Based on an AutoML Head'},\n",
       "  'Scale Aggregation Block': {'full_name': 'Scale Aggregation Block',\n",
       "   'url': 'http://arxiv.org/abs/1904.09460v1',\n",
       "   'title': 'Data-Driven Neuron Allocation for Scale Aggregation Networks'},\n",
       "  'EESP': {'full_name': 'Extremely Efficient Spatial Pyramid of Depth-wise Dilated Separable Convolutions',\n",
       "   'url': 'http://arxiv.org/abs/1811.11431v3',\n",
       "   'title': 'ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network'},\n",
       "  'MoGA-B': {'full_name': 'MoGA-B',\n",
       "   'url': 'https://arxiv.org/abs/1908.01314v4',\n",
       "   'title': 'MoGA: Searching Beyond MobileNetV3'},\n",
       "  'GroupDNet': {'full_name': 'Group Decreasing Network',\n",
       "   'url': 'https://arxiv.org/abs/2003.12697v3',\n",
       "   'title': 'Semantically Multi-modal Image Synthesis'},\n",
       "  'ALI': {'full_name': 'Adversarially Learned Inference',\n",
       "   'url': 'http://arxiv.org/abs/1606.00704v3',\n",
       "   'title': 'Adversarially Learned Inference'},\n",
       "  'DeepCluster': {'full_name': 'DeepCluster',\n",
       "   'url': 'http://arxiv.org/abs/1807.05520v2',\n",
       "   'title': 'Deep Clustering for Unsupervised Learning of Visual Features'},\n",
       "  'Gated Convolution': {'full_name': 'Gated Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1612.08083v3',\n",
       "   'title': 'Language Modeling with Gated Convolutional Networks'},\n",
       "  'StreaMRAK': {'full_name': 'StreaMRAK',\n",
       "   'url': 'https://arxiv.org/abs/2108.10411v2',\n",
       "   'title': 'StreaMRAK a Streaming Multi-Resolution Adaptive Kernel Algorithm'},\n",
       "  'WaveGlow': {'full_name': 'WaveGlow',\n",
       "   'url': 'http://arxiv.org/abs/1811.00002v1',\n",
       "   'title': 'WaveGlow: A Flow-based Generative Network for Speech Synthesis'},\n",
       "  'Multi-Head Linear Attention': {'full_name': 'Multi-Head Linear Attention',\n",
       "   'url': 'https://arxiv.org/abs/2006.04768v3',\n",
       "   'title': 'Linformer: Self-Attention with Linear Complexity'},\n",
       "  'ProxyOptimization': {'full_name': 'Proxy Optimization for initial Proxies in Proxy Anchor Loss',\n",
       "   'url': 'https://arxiv.org/abs/2104.11231v1',\n",
       "   'title': 'VeriMedi: Pill Identification using Proxy-based Deep Metric Learning and Exact Solution'},\n",
       "  'TinaFace': {'full_name': 'TinaFace',\n",
       "   'url': 'https://arxiv.org/abs/2011.13183v3',\n",
       "   'title': 'TinaFace: Strong but Simple Baseline for Face Detection'},\n",
       "  'Set Transformer': {'full_name': 'Set Transformer',\n",
       "   'url': 'https://arxiv.org/abs/1810.00825v3',\n",
       "   'title': 'Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks'},\n",
       "  '3D Convolution': {'full_name': '3D Convolution',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'IC-SBP': {'full_name': 'Instance Colouring Stick-Breaking Process',\n",
       "   'url': 'https://arxiv.org/abs/2104.09958v3',\n",
       "   'title': 'GENESIS-V2: Inferring Unordered Object Representations without Iterative Refinement'},\n",
       "  'Fisher-BRC': {'full_name': 'Fisher-BRC',\n",
       "   'url': 'https://arxiv.org/abs/2103.08050v1',\n",
       "   'title': 'Offline Reinforcement Learning with Fisher Divergence Critic Regularization'},\n",
       "  'Dense Block': {'full_name': 'Dense Block',\n",
       "   'url': 'http://arxiv.org/abs/1608.06993v5',\n",
       "   'title': 'Densely Connected Convolutional Networks'},\n",
       "  'AutoSmart': {'full_name': 'AutoSmart',\n",
       "   'url': 'https://arxiv.org/abs/2109.04115v1',\n",
       "   'title': 'AutoSmart: An Efficient and Automatic Machine Learning framework for Temporal Relational Data'},\n",
       "  'wav2vec-U': {'full_name': 'wav2vec Unsupervised',\n",
       "   'url': 'https://arxiv.org/abs/2105.11084v3',\n",
       "   'title': 'Unsupervised Speech Recognition'},\n",
       "  'StoGCN': {'full_name': 'StoGCN',\n",
       "   'url': 'http://arxiv.org/abs/1710.10568v3',\n",
       "   'title': 'Stochastic Training of Graph Convolutional Networks with Variance Reduction'},\n",
       "  'EfficientDet': {'full_name': 'EfficientDet',\n",
       "   'url': 'https://arxiv.org/abs/1911.09070v7',\n",
       "   'title': 'EfficientDet: Scalable and Efficient Object Detection'},\n",
       "  'OMGD': {'full_name': 'Online Multi-granularity Distillation',\n",
       "   'url': 'https://arxiv.org/abs/2108.06908v2',\n",
       "   'title': 'Online Multi-Granularity Distillation for GAN Compression'},\n",
       "  'DAC': {'full_name': 'Dynamic Algorithm Configuration',\n",
       "   'url': 'http://ecai2020.eu/papers/1237_paper.pdf',\n",
       "   'title': 'Dynamic Algorithm Configuration: Foundation of a New Meta-Algorithmic Framework'},\n",
       "  'Policy Similarity Metric': {'full_name': 'Policy Similarity Metric',\n",
       "   'url': 'https://arxiv.org/abs/2101.05265v2',\n",
       "   'title': 'Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning'},\n",
       "  'Fast-YOLOv4-SmallObj': {'full_name': 'Fast-YOLOv4-SmallObj',\n",
       "   'url': 'https://arxiv.org/abs/2009.10181v5',\n",
       "   'title': 'Towards Image-based Automatic Meter Reading in Unconstrained Scenarios: A Robust and Efficient Approach'},\n",
       "  'PipeDream': {'full_name': 'PipeDream', 'url': None, 'title': None},\n",
       "  'RepVGG': {'full_name': 'RepVGG',\n",
       "   'url': 'https://arxiv.org/abs/2101.03697v3',\n",
       "   'title': 'RepVGG: Making VGG-style ConvNets Great Again'},\n",
       "  'IRN': {'full_name': 'Invertible Rescaling Network',\n",
       "   'url': 'https://arxiv.org/abs/2005.05650v1',\n",
       "   'title': 'Invertible Image Rescaling'},\n",
       "  'Max Pooling': {'full_name': 'Max Pooling', 'url': None, 'title': None},\n",
       "  'Lower Bound on Transmission using Non-Linear Bounding Function in Single Image Dehazing': {'full_name': 'Lower Bound on Transmission using Non-Linear Bounding Function in Single Image Dehazing',\n",
       "   'url': 'https://ieeexplore.ieee.org/document/9018379',\n",
       "   'title': 'Lower Bound on Transmission Using Non-Linear Bounding Function in Single Image Dehazing'},\n",
       "  'Accordion': {'full_name': 'Accordion',\n",
       "   'url': 'https://arxiv.org/abs/2010.16248v1',\n",
       "   'title': 'Accordion: Adaptive Gradient Communication via Critical Learning Regime Identification'},\n",
       "  'DVD-GAN GBlock': {'full_name': 'DVD-GAN GBlock',\n",
       "   'url': 'https://arxiv.org/abs/1907.06571v2',\n",
       "   'title': 'Adversarial Video Generation on Complex Datasets'},\n",
       "  'CSL': {'full_name': 'Circular Smooth Label',\n",
       "   'url': 'https://arxiv.org/abs/2003.05597v4',\n",
       "   'title': 'On the Arbitrary-Oriented Object Detection: Classification based Approaches Revisited'},\n",
       "  'OTM': {'full_name': 'Optimal Transport Modeling',\n",
       "   'url': 'https://arxiv.org/abs/2110.02999v2',\n",
       "   'title': 'Generative Modeling with Optimal Transport Maps'},\n",
       "  'Charformer': {'full_name': 'Charformer',\n",
       "   'url': 'https://arxiv.org/abs/2106.12672v3',\n",
       "   'title': 'Charformer: Fast Character Transformers via Gradient-based Subword Tokenization'},\n",
       "  'STraTA': {'full_name': 'Self-Training with Task Augmentation',\n",
       "   'url': 'https://arxiv.org/abs/2109.06270v2',\n",
       "   'title': 'STraTA: Self-Training with Task Augmentation for Better Few-shot Learning'},\n",
       "  'RReLU': {'full_name': 'Randomized Leaky Rectified Linear Units',\n",
       "   'url': 'http://arxiv.org/abs/1505.00853v2',\n",
       "   'title': 'Empirical Evaluation of Rectified Activations in Convolutional Network'},\n",
       "  'MaskFlownet': {'full_name': 'MaskFlownet',\n",
       "   'url': 'https://arxiv.org/abs/2003.10955v2',\n",
       "   'title': 'MaskFlownet: Asymmetric Feature Matching with Learnable Occlusion Mask'},\n",
       "  'CornerNet-Squeeze': {'full_name': 'CornerNet-Squeeze',\n",
       "   'url': 'https://arxiv.org/abs/1904.08900v2',\n",
       "   'title': 'CornerNet-Lite: Efficient Keypoint Based Object Detection'},\n",
       "  'TURL': {'full_name': 'TURL: Table Understanding through Representation Learning',\n",
       "   'url': 'https://arxiv.org/abs/2006.14806v2',\n",
       "   'title': 'TURL: Table Understanding through Representation Learning'},\n",
       "  'Stochastic Dueling Network': {'full_name': 'Stochastic Dueling Network',\n",
       "   'url': 'http://arxiv.org/abs/1611.01224v2',\n",
       "   'title': 'Sample Efficient Actor-Critic with Experience Replay'},\n",
       "  'Inception-C': {'full_name': 'Inception-C',\n",
       "   'url': 'http://arxiv.org/abs/1602.07261v2',\n",
       "   'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
       "  'Beta-VAE': {'full_name': 'Beta-VAE',\n",
       "   'url': 'https://openreview.net/forum?id=Sy2fzU9gl',\n",
       "   'title': 'beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework'},\n",
       "  'Dual Softmax Loss': {'full_name': 'Dual Softmax Loss',\n",
       "   'url': 'https://arxiv.org/abs/2109.04290v3',\n",
       "   'title': 'Improving Video-Text Retrieval by Multi-Stream Corpus Alignment and Dual Softmax Loss'},\n",
       "  'Trans-Encoder': {'full_name': 'Trans-Encoder',\n",
       "   'url': 'https://arxiv.org/abs/2109.13059v4',\n",
       "   'title': 'Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations'},\n",
       "  'DetNet': {'full_name': 'DetNet',\n",
       "   'url': 'http://arxiv.org/abs/1804.06215v2',\n",
       "   'title': 'DetNet: A Backbone network for Object Detection'},\n",
       "  'LAMA': {'full_name': 'Low-Rank Factorization-based Multi-Head Attention',\n",
       "   'url': 'https://arxiv.org/abs/1912.00835v2',\n",
       "   'title': 'Low Rank Factorization for Compact Multi-Head Self-Attention'},\n",
       "  'Sparse R-CNN': {'full_name': 'Sparse R-CNN',\n",
       "   'url': 'https://arxiv.org/abs/2011.12450v2',\n",
       "   'title': 'Sparse R-CNN: End-to-End Object Detection with Learnable Proposals'},\n",
       "  'DyGED': {'full_name': 'Dynamic Graph Event Detection',\n",
       "   'url': 'https://arxiv.org/abs/2110.12148v1',\n",
       "   'title': 'Event Detection on Dynamic Graphs'},\n",
       "  'Selective Kernel': {'full_name': 'Selective Kernel',\n",
       "   'url': 'http://arxiv.org/abs/1903.06586v2',\n",
       "   'title': 'Selective Kernel Networks'},\n",
       "  'Dynamic SmoothL1 Loss': {'full_name': 'Dynamic SmoothL1 Loss',\n",
       "   'url': 'https://arxiv.org/abs/2004.06002v2',\n",
       "   'title': 'Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training'},\n",
       "  'TABBIE': {'full_name': 'TABBIE',\n",
       "   'url': 'https://arxiv.org/abs/2105.02584v1',\n",
       "   'title': 'TABBIE: Pretrained Representations of Tabular Data'},\n",
       "  'SMITH': {'full_name': 'Siamese Multi-depth Transformer-based Hierarchical Encoder',\n",
       "   'url': 'https://arxiv.org/abs/2004.12297v2',\n",
       "   'title': 'Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching'},\n",
       "  'Jukebox': {'full_name': 'Jukebox',\n",
       "   'url': 'https://arxiv.org/abs/2005.00341v1',\n",
       "   'title': 'Jukebox: A Generative Model for Music'},\n",
       "  'InfoNCE': {'full_name': 'InfoNCE',\n",
       "   'url': 'http://arxiv.org/abs/1807.03748v2',\n",
       "   'title': 'Representation Learning with Contrastive Predictive Coding'},\n",
       "  'Rank-based Loss': {'full_name': 'Rank-based loss',\n",
       "   'url': 'https://arxiv.org/abs/2110.05941v2',\n",
       "   'title': 'Rank-based loss for learning hierarchical representations'},\n",
       "  'FFMv2': {'full_name': 'Feature Fusion Module v2',\n",
       "   'url': 'http://arxiv.org/abs/1811.04533v3',\n",
       "   'title': 'M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network'},\n",
       "  'IoU-Balanced Sampling': {'full_name': 'IoU-Balanced Sampling',\n",
       "   'url': 'http://arxiv.org/abs/1904.02701v1',\n",
       "   'title': 'Libra R-CNN: Towards Balanced Learning for Object Detection'},\n",
       "  'CP-N3-RP': {'full_name': 'CP with N3 Regularizer and Relation Prediction',\n",
       "   'url': 'https://arxiv.org/abs/2110.02834v1',\n",
       "   'title': 'Relation Prediction as an Auxiliary Training Objective for Improving Multi-Relational Graph Representations'},\n",
       "  'PCIDA': {'full_name': 'Probabilistic Continuously Indexed Domain Adaptation',\n",
       "   'url': 'https://arxiv.org/abs/2007.01807v2',\n",
       "   'title': 'Continuously Indexed Domain Adaptation'},\n",
       "  'Dynamic Memory Network': {'full_name': 'Dynamic Memory Network',\n",
       "   'url': 'http://arxiv.org/abs/1506.07285v5',\n",
       "   'title': 'Ask Me Anything: Dynamic Memory Networks for Natural Language Processing'},\n",
       "  'CTAL': {'full_name': 'CTAL',\n",
       "   'url': 'https://arxiv.org/abs/2109.00181v1',\n",
       "   'title': 'CTAL: Pre-training Cross-modal Transformer for Audio-and-Language Representations'},\n",
       "  'TWEC': {'full_name': 'Temporal Word Embeddings with a Compass',\n",
       "   'url': 'https://arxiv.org/abs/1906.02376v1',\n",
       "   'title': 'Training Temporal Word Embeddings with a Compass'},\n",
       "  'Florence': {'full_name': 'Florence',\n",
       "   'url': 'https://arxiv.org/abs/2111.11432v1',\n",
       "   'title': 'Florence: A New Foundation Model for Computer Vision'},\n",
       "  'GECO': {'full_name': 'Generalized ELBO with Constrained Optimization',\n",
       "   'url': 'http://arxiv.org/abs/1810.00597v1',\n",
       "   'title': 'Taming VAEs'},\n",
       "  'NAFNet': {'full_name': 'Nonlinear Activation Free Network',\n",
       "   'url': 'https://arxiv.org/abs/2204.04676v4',\n",
       "   'title': 'Simple Baselines for Image Restoration'},\n",
       "  'Stacked Hourglass Network': {'full_name': 'Stacked Hourglass Network',\n",
       "   'url': 'http://arxiv.org/abs/1603.06937v2',\n",
       "   'title': 'Stacked Hourglass Networks for Human Pose Estimation'},\n",
       "  'DSAM loss': {'full_name': 'Distance Shrinking with Angular Marginalizing Loss',\n",
       "   'url': 'https://arxiv.org/abs/2011.06228v3',\n",
       "   'title': 'DSAM: A Distance Shrinking with Angular Marginalizing Loss for High Performance Vehicle Re-identificatio'},\n",
       "  'DSelect-k': {'full_name': 'DSelect-k',\n",
       "   'url': 'https://arxiv.org/abs/2106.03760v3',\n",
       "   'title': 'DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning'},\n",
       "  'AVSlowFast': {'full_name': 'Audiovisual SlowFast Network',\n",
       "   'url': 'https://arxiv.org/abs/2001.08740v2',\n",
       "   'title': 'Audiovisual SlowFast Networks for Video Recognition'},\n",
       "  'K3M': {'full_name': 'K3M',\n",
       "   'url': 'https://arxiv.org/abs/2109.00895v1',\n",
       "   'title': 'Knowledge Perceived Multi-modal Pretraining in E-commerce'},\n",
       "  'Teacher-Tutor-Student Knowledge Distillation': {'full_name': 'Teacher-Tutor-Student Knowledge Distillation',\n",
       "   'url': 'https://arxiv.org/abs/2103.04559v2',\n",
       "   'title': 'Parser-Free Virtual Try-on via Distilling Appearance Flows'},\n",
       "  'Label Smoothing': {'full_name': 'Label Smoothing',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'All-Attention Layer': {'full_name': 'All-Attention Layer',\n",
       "   'url': 'https://arxiv.org/abs/1907.01470v1',\n",
       "   'title': 'Augmenting Self-attention with Persistent Memory'},\n",
       "  'CBHG': {'full_name': 'CBHG',\n",
       "   'url': 'http://arxiv.org/abs/1703.10135v2',\n",
       "   'title': 'Tacotron: Towards End-to-End Speech Synthesis'},\n",
       "  'StyleMapGAN': {'full_name': 'StyleMapGAN',\n",
       "   'url': 'https://arxiv.org/abs/2104.14754v2',\n",
       "   'title': 'Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing'},\n",
       "  'Transductive Inference': {'full_name': 'Transductive Inference',\n",
       "   'url': 'https://ieeexplore.ieee.org/abstract/document/6280886',\n",
       "   'title': 'Transductive Inference and Semi-Supervised Learning'},\n",
       "  'PresGAN': {'full_name': 'Prescribed Generative Adversarial Network',\n",
       "   'url': 'https://arxiv.org/abs/1910.04302v1',\n",
       "   'title': 'Prescribed Generative Adversarial Networks'},\n",
       "  'Location-based Attention': {'full_name': 'Location-based Attention',\n",
       "   'url': 'http://arxiv.org/abs/1508.04025v5',\n",
       "   'title': 'Effective Approaches to Attention-based Neural Machine Translation'},\n",
       "  'IB-BERT': {'full_name': 'Inverted Bottleneck BERT',\n",
       "   'url': 'https://arxiv.org/abs/2004.02984v2',\n",
       "   'title': 'MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices'},\n",
       "  'Activation Regularization': {'full_name': 'Activation Regularization',\n",
       "   'url': 'http://arxiv.org/abs/1708.01009v1',\n",
       "   'title': 'Revisiting Activation Regularization for Language RNNs'},\n",
       "  'AutoSync': {'full_name': 'AutoSync',\n",
       "   'url': 'http://proceedings.neurips.cc/paper/2020/hash/0a2298a72858d90d5c4b4fee954b6896-Abstract.html',\n",
       "   'title': 'AutoSync: Learning to Synchronize for Data-Parallel Distributed Deep Learning'},\n",
       "  'Neural Architecture Search': {'full_name': 'Neural Architecture Search',\n",
       "   'url': 'http://arxiv.org/abs/1707.07012v4',\n",
       "   'title': 'Learning Transferable Architectures for Scalable Image Recognition'},\n",
       "  'MobileNetV2': {'full_name': 'MobileNetV2',\n",
       "   'url': 'http://arxiv.org/abs/1801.04381v4',\n",
       "   'title': 'MobileNetV2: Inverted Residuals and Linear Bottlenecks'},\n",
       "  'STATEGAME MAINTAIN PICTURE BALANCED PLAY STABLE': {'full_name': 'ATTEMPT THIS FATHINETUTE TO REPOPULATE ALREADY POPULATED  SYSTEM',\n",
       "   'url': 'http://arxiv.org/abs/1801.09110v1',\n",
       "   'title': '0+ and 1+ heavy-light exotic mesons at N2LO in the chiral limit'},\n",
       "  'FBNet Block': {'full_name': 'FBNet Block',\n",
       "   'url': 'https://arxiv.org/abs/1812.03443v3',\n",
       "   'title': 'FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search'},\n",
       "  'ILVR': {'full_name': 'Iterative Latent Variable Refinement',\n",
       "   'url': 'https://arxiv.org/abs/2108.02938v2',\n",
       "   'title': 'ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models'},\n",
       "  'NFR': {'full_name': 'Negative Face Recognition',\n",
       "   'url': 'https://arxiv.org/abs/2002.09181v1',\n",
       "   'title': 'Unsupervised Enhancement of Soft-biometric Privacy with Negative Face Recognition'},\n",
       "  'Adabelief': {'full_name': 'Adabelief',\n",
       "   'url': 'https://arxiv.org/abs/2010.07468v5',\n",
       "   'title': 'AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients'},\n",
       "  'DCLS': {'full_name': 'Dilated convolution with learnable spacings',\n",
       "   'url': 'https://arxiv.org/abs/2112.03740v1',\n",
       "   'title': 'Dilated convolution with learnable spacings'},\n",
       "  'YOLOP': {'full_name': 'YOLOP',\n",
       "   'url': 'https://arxiv.org/abs/2108.11250v7',\n",
       "   'title': 'YOLOP: You Only Look Once for Panoptic Driving Perception'},\n",
       "  'ICA': {'full_name': 'Independent Component Analysis',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Contrastive Predictive Coding': {'full_name': 'Contrastive Predictive Coding',\n",
       "   'url': 'http://arxiv.org/abs/1807.03748v2',\n",
       "   'title': 'Representation Learning with Contrastive Predictive Coding'},\n",
       "  'TNT': {'full_name': 'Transformer in Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2103.00112v3',\n",
       "   'title': 'Transformer in Transformer'},\n",
       "  'DenseNAS-A': {'full_name': 'DenseNAS-A',\n",
       "   'url': 'https://arxiv.org/abs/1906.09607v3',\n",
       "   'title': 'Densely Connected Search Space for More Flexible Neural Architecture Search'},\n",
       "  'Logistic Regression': {'full_name': 'Logistic Regression',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'TanhExp': {'full_name': 'Tanh Exponential Activation Function',\n",
       "   'url': 'https://arxiv.org/abs/2003.09855v2',\n",
       "   'title': 'TanhExp: A Smooth Activation Function with High Convergence Speed for Lightweight Neural Networks'},\n",
       "  'BASE': {'full_name': 'Balanced Selection',\n",
       "   'url': 'https://arxiv.org/abs/2111.12880v1',\n",
       "   'title': 'Active Learning at the ImageNet Scale'},\n",
       "  'HyperTree MetaModel': {'full_name': 'HyperTree MetaModel',\n",
       "   'url': 'http://arxiv.org/abs/1810.11714v2',\n",
       "   'title': 'The CoSTAR Block Stacking Dataset: Learning with Workspace Constraints'},\n",
       "  'Streaming Module': {'full_name': 'Streaming Module',\n",
       "   'url': 'http://arxiv.org/abs/1904.09290v1',\n",
       "   'title': 'FeatherNets: Convolutional Neural Networks as Light as Feather for Face Anti-spoofing'},\n",
       "  'TSRUs': {'full_name': 'TSRUs',\n",
       "   'url': 'https://arxiv.org/abs/2003.04035v3',\n",
       "   'title': 'Transformation-based Adversarial Video Prediction on Large-Scale Data'},\n",
       "  'Switch FFN': {'full_name': 'Switch FFN',\n",
       "   'url': 'https://arxiv.org/abs/2101.03961v3',\n",
       "   'title': 'Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity'},\n",
       "  'PointASNL': {'full_name': 'PointASNL',\n",
       "   'url': 'https://arxiv.org/abs/2003.00492v3',\n",
       "   'title': 'PointASNL: Robust Point Clouds Processing using Nonlocal Neural Networks with Adaptive Sampling'},\n",
       "  'AMSBound': {'full_name': 'AMSBound',\n",
       "   'url': 'http://arxiv.org/abs/1902.09843v1',\n",
       "   'title': 'Adaptive Gradient Methods with Dynamic Bound of Learning Rate'},\n",
       "  'Conditional DBlock': {'full_name': 'Conditional DBlock',\n",
       "   'url': 'https://arxiv.org/abs/1909.11646v2',\n",
       "   'title': 'High Fidelity Speech Synthesis with Adversarial Networks'},\n",
       "  'DGI': {'full_name': 'Deep Graph Infomax',\n",
       "   'url': 'http://arxiv.org/abs/1809.10341v2',\n",
       "   'title': 'Deep Graph Infomax'},\n",
       "  'Dilated Sliding Window Attention': {'full_name': 'Dilated Sliding Window Attention',\n",
       "   'url': 'https://arxiv.org/abs/2004.05150v2',\n",
       "   'title': 'Longformer: The Long-Document Transformer'},\n",
       "  'ComiRec': {'full_name': 'ComiRec',\n",
       "   'url': 'https://arxiv.org/abs/2005.09347v2',\n",
       "   'title': 'Controllable Multi-Interest Framework for Recommendation'},\n",
       "  'Spatial Feature Transform': {'full_name': 'Spatial Feature Transform',\n",
       "   'url': 'http://arxiv.org/abs/1804.02815v1',\n",
       "   'title': 'Recovering Realistic Texture in Image Super-resolution by Deep Spatial Feature Transform'},\n",
       "  'mBART': {'full_name': 'mBART',\n",
       "   'url': 'https://arxiv.org/abs/2001.08210v2',\n",
       "   'title': 'Multilingual Denoising Pre-training for Neural Machine Translation'},\n",
       "  'DiffPool': {'full_name': 'DiffPool',\n",
       "   'url': 'http://arxiv.org/abs/1806.08804v4',\n",
       "   'title': 'Hierarchical Graph Representation Learning with Differentiable Pooling'},\n",
       "  'VATT': {'full_name': 'VATT',\n",
       "   'url': 'https://arxiv.org/abs/2104.11178v3',\n",
       "   'title': 'VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text'},\n",
       "  'Inception-ResNet-v2 Reduction-B': {'full_name': 'Inception-ResNet-v2 Reduction-B',\n",
       "   'url': 'http://arxiv.org/abs/1602.07261v2',\n",
       "   'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
       "  'Variational Inference': {'full_name': 'Variational Inference',\n",
       "   'url': 'https://arxiv.org/abs/2012.03715v1',\n",
       "   'title': 'Autoencoding Variational Autoencoder'},\n",
       "  'MnasNet': {'full_name': 'MnasNet',\n",
       "   'url': 'https://arxiv.org/abs/1807.11626v3',\n",
       "   'title': 'MnasNet: Platform-Aware Neural Architecture Search for Mobile'},\n",
       "  'StruBERT': {'full_name': 'StruBERT: Structure-aware BERT for Table Search and Matching',\n",
       "   'url': 'https://arxiv.org/abs/2203.14278v1',\n",
       "   'title': 'StruBERT: Structure-aware BERT for Table Search and Matching'},\n",
       "  'Deformable Kernel': {'full_name': 'Deformable Kernel',\n",
       "   'url': 'https://arxiv.org/abs/1910.02940v2',\n",
       "   'title': 'Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation'},\n",
       "  'ALP-GMM': {'full_name': 'Absolute Learning Progress and Gaussian Mixture Models for Automatic Curriculum Learning',\n",
       "   'url': 'https://arxiv.org/abs/1910.07224v1',\n",
       "   'title': 'Teacher algorithms for curriculum learning of Deep RL in continuously parameterized environments'},\n",
       "  'STDC': {'full_name': 'Short-Term Dense Concatenate',\n",
       "   'url': 'https://arxiv.org/abs/2104.13188v1',\n",
       "   'title': 'Rethinking BiSeNet For Real-time Semantic Segmentation'},\n",
       "  'Euclidean Norm Regularization': {'full_name': 'Euclidean Norm Regularization',\n",
       "   'url': 'https://arxiv.org/abs/1905.06723v2',\n",
       "   'title': 'Deep Compressed Sensing'},\n",
       "  'KE-MLM': {'full_name': 'Knowledge Enhanced Masked Language Model',\n",
       "   'url': 'https://aclanthology.org/2021.naacl-main.376',\n",
       "   'title': 'Knowledge Enhanced Masked Language Model for Stance Detection'},\n",
       "  'ED-GNN': {'full_name': 'Medical Entity Disambiguation using Graph Neural Networks',\n",
       "   'url': 'https://arxiv.org/abs/2104.01488v1',\n",
       "   'title': 'Medical Entity Disambiguation Using Graph Neural Networks'},\n",
       "  'Lookahead': {'full_name': 'Lookahead',\n",
       "   'url': 'https://arxiv.org/abs/1907.08610v2',\n",
       "   'title': 'Lookahead Optimizer: k steps forward, 1 step back'},\n",
       "  'PASE+': {'full_name': 'Problem Agnostic Speech Encoder +',\n",
       "   'url': 'https://arxiv.org/abs/2001.09239v2',\n",
       "   'title': 'Multi-task self-supervised learning for Robust Speech Recognition'},\n",
       "  'HS-ResNet': {'full_name': 'HS-ResNet',\n",
       "   'url': 'https://arxiv.org/abs/2010.07621v1',\n",
       "   'title': 'HS-ResNet: Hierarchical-Split Block on Convolutional Neural Network'},\n",
       "  'PonderNet': {'full_name': 'PonderNet',\n",
       "   'url': 'https://arxiv.org/abs/2107.05407v2',\n",
       "   'title': 'PonderNet: Learning to Ponder'},\n",
       "  'HRank': {'full_name': 'HRank',\n",
       "   'url': 'https://arxiv.org/abs/2002.10179v2',\n",
       "   'title': 'HRank: Filter Pruning using High-Rank Feature Map'},\n",
       "  'Sarsa Lambda': {'full_name': 'Sarsa Lambda', 'url': None, 'title': None},\n",
       "  'MLP-Mixer': {'full_name': 'MLP-Mixer',\n",
       "   'url': 'https://arxiv.org/abs/2105.01601v4',\n",
       "   'title': 'MLP-Mixer: An all-MLP Architecture for Vision'},\n",
       "  'Bottleneck Residual Block': {'full_name': 'Bottleneck Residual Block',\n",
       "   'url': 'http://arxiv.org/abs/1512.03385v1',\n",
       "   'title': 'Deep Residual Learning for Image Recognition'},\n",
       "  'SCN': {'full_name': 'Self-Cure Network',\n",
       "   'url': 'https://arxiv.org/abs/2002.10392v2',\n",
       "   'title': 'Suppressing Uncertainties for Large-Scale Facial Expression Recognition'},\n",
       "  'Parallax': {'full_name': 'Parallax', 'url': None, 'title': None},\n",
       "  'AutoGL': {'full_name': 'Automated Graph Learning',\n",
       "   'url': 'https://www.nature.com/articles/s42256-022-00501-8',\n",
       "   'title': 'An adaptive graph learning method for automated molecular interactions and properties predictions'},\n",
       "  'Dilated Convolution': {'full_name': 'Dilated Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1511.07122v3',\n",
       "   'title': 'Multi-Scale Context Aggregation by Dilated Convolutions'},\n",
       "  'Grammatical evolution + Q-learning': {'full_name': 'Grammatical evolution and Q-learning',\n",
       "   'url': 'https://arxiv.org/abs/2012.07723v3',\n",
       "   'title': 'Evolutionary learning of interpretable decision trees'},\n",
       "  'Revision Network': {'full_name': 'Revision Network',\n",
       "   'url': 'https://arxiv.org/abs/2104.05376v2',\n",
       "   'title': 'Drafting and Revision: Laplacian Pyramid Network for Fast High-Quality Artistic Style Transfer'},\n",
       "  'ARShoe': {'full_name': 'ARShoe',\n",
       "   'url': 'https://arxiv.org/abs/2108.10515v1',\n",
       "   'title': 'ARShoe: Real-Time Augmented Reality Shoe Try-on System on Smartphones'},\n",
       "  'NN4G': {'full_name': 'Neural network for graphs',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'StereoLayers': {'full_name': 'StereoLayers',\n",
       "   'url': 'https://arxiv.org/abs/2201.05023v2',\n",
       "   'title': 'Stereo Magnification with Multi-Layer Images'},\n",
       "  'Deep Ensembles': {'full_name': 'Deep Ensembles',\n",
       "   'url': 'http://arxiv.org/abs/1612.01474v3',\n",
       "   'title': 'Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles'},\n",
       "  'Grid R-CNN': {'full_name': 'Grid R-CNN',\n",
       "   'url': 'http://arxiv.org/abs/1811.12030v1',\n",
       "   'title': 'Grid R-CNN'},\n",
       "  'Cross-View Training': {'full_name': 'Cross-View Training',\n",
       "   'url': 'http://arxiv.org/abs/1809.08370v1',\n",
       "   'title': 'Semi-Supervised Sequence Modeling with Cross-View Training'},\n",
       "  'PinvGCN': {'full_name': 'Pseudoinverse Graph Convolutional Network',\n",
       "   'url': 'https://arxiv.org/abs/2008.00720v2',\n",
       "   'title': 'Pseudoinverse Graph Convolutional Networks: Fast Filters Tailored for Large Eigengaps of Dense Graphs and Hypergraphs'},\n",
       "  'BLIP': {'full_name': 'BLIP: Bootstrapping Language-Image Pre-training',\n",
       "   'url': 'https://arxiv.org/abs/2201.12086v2',\n",
       "   'title': 'BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation'},\n",
       "  'DistilBERT': {'full_name': 'DistilBERT',\n",
       "   'url': 'https://arxiv.org/abs/1910.01108v4',\n",
       "   'title': 'DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter'},\n",
       "  'DGCNN': {'full_name': 'Deep Graph Convolutional Neural Network',\n",
       "   'url': 'https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17146',\n",
       "   'title': 'An End-to-End Deep Learning Architecture for Graph Classification'},\n",
       "  'SAC': {'full_name': 'Switchable Atrous Convolution',\n",
       "   'url': 'https://arxiv.org/abs/2006.02334v2',\n",
       "   'title': 'DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution'},\n",
       "  'DOLG': {'full_name': 'Deep Orthogonal Fusion of Local and Global Features',\n",
       "   'url': 'https://arxiv.org/abs/2108.02927v2',\n",
       "   'title': 'DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features'},\n",
       "  'HFPSO': {'full_name': 'Hybrid Firefly and Particle Swarm Optimization',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Adaptive Softmax': {'full_name': 'Adaptive Softmax',\n",
       "   'url': 'http://arxiv.org/abs/1609.04309v3',\n",
       "   'title': 'Efficient softmax approximation for GPUs'},\n",
       "  'Conditional Positional Encoding': {'full_name': 'Conditional Positional Encoding',\n",
       "   'url': 'https://arxiv.org/abs/2102.10882v2',\n",
       "   'title': 'Conditional Positional Encodings for Vision Transformers'},\n",
       "  'Probabilistic Anchor Assignment': {'full_name': 'Probabilistic Anchor Assignment',\n",
       "   'url': 'https://arxiv.org/abs/2007.08103v2',\n",
       "   'title': 'Probabilistic Anchor Assignment with IoU Prediction for Object Detection'},\n",
       "  'TridentNet': {'full_name': 'TridentNet',\n",
       "   'url': 'https://arxiv.org/abs/1901.01892v2',\n",
       "   'title': 'Scale-Aware Trident Networks for Object Detection'},\n",
       "  'TopK Copy': {'full_name': 'TopK Copy',\n",
       "   'url': 'https://arxiv.org/abs/2109.04901v1',\n",
       "   'title': 'Document-level Entity-based Extraction as Template Generation'},\n",
       "  'AdaMod': {'full_name': 'AdaMod',\n",
       "   'url': 'https://arxiv.org/abs/1910.12249v1',\n",
       "   'title': 'An Adaptive and Momental Bound Method for Stochastic Learning'},\n",
       "  'MEI': {'full_name': 'Multi-partition Embedding Interaction',\n",
       "   'url': 'https://arxiv.org/abs/2006.16365v1',\n",
       "   'title': 'Multi-Partition Embedding Interaction with Block Term Format for Knowledge Graph Completion'},\n",
       "  'Unified VLP': {'full_name': 'Unified VLP',\n",
       "   'url': 'https://arxiv.org/abs/1909.11059v3',\n",
       "   'title': 'Unified Vision-Language Pre-Training for Image Captioning and VQA'},\n",
       "  'GAIL': {'full_name': 'Generative Adversarial Imitation Learning',\n",
       "   'url': 'http://arxiv.org/abs/1606.03476v1',\n",
       "   'title': 'Generative Adversarial Imitation Learning'},\n",
       "  'Powerpropagation': {'full_name': 'Powerpropagation',\n",
       "   'url': 'https://arxiv.org/abs/2110.00296v2',\n",
       "   'title': 'Powerpropagation: A sparsity inducing weight reparameterisation'},\n",
       "  'Lambda Layer': {'full_name': 'Lambda Layer',\n",
       "   'url': 'https://arxiv.org/abs/2102.08602v1',\n",
       "   'title': 'LambdaNetworks: Modeling Long-Range Interactions Without Attention'},\n",
       "  'SANet': {'full_name': 'Self-Attention Network',\n",
       "   'url': 'https://arxiv.org/abs/2004.13621v1',\n",
       "   'title': 'Exploring Self-attention for Image Recognition'},\n",
       "  'Style Transfer Module': {'full_name': 'Style Transfer Module',\n",
       "   'url': 'http://arxiv.org/abs/1703.06868v2',\n",
       "   'title': 'Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization'},\n",
       "  'ProxyAnchorLoss': {'full_name': 'Proxy Anchor Loss for Deep Metric Learning',\n",
       "   'url': 'https://arxiv.org/abs/2003.13911v1',\n",
       "   'title': 'Proxy Anchor Loss for Deep Metric Learning'},\n",
       "  'HyperHyperNetwork': {'full_name': 'Hyper HyperNetwork',\n",
       "   'url': 'https://arxiv.org/abs/2105.03838v1',\n",
       "   'title': 'HyperHyperNetworks for the Design of Antenna Arrays'},\n",
       "  'RGA': {'full_name': 'Relation-aware Global Attention',\n",
       "   'url': 'https://arxiv.org/abs/1904.02998v2',\n",
       "   'title': 'Relation-Aware Global Attention for Person Re-identification'},\n",
       "  'SRM': {'full_name': 'style-based recalibration module',\n",
       "   'url': 'http://openaccess.thecvf.com/content_ICCV_2019/html/Lee_SRM_A_Style-Based_Recalibration_Module_for_Convolutional_Neural_Networks_ICCV_2019_paper.html',\n",
       "   'title': 'SRM: A Style-Based Recalibration Module for Convolutional Neural Networks'},\n",
       "  'FPN': {'full_name': 'Feature Pyramid Network',\n",
       "   'url': 'http://arxiv.org/abs/1612.03144v2',\n",
       "   'title': 'Feature Pyramid Networks for Object Detection'},\n",
       "  'Class Attention': {'full_name': 'Class Attention',\n",
       "   'url': 'https://arxiv.org/abs/2103.17239v2',\n",
       "   'title': 'Going deeper with Image Transformers'},\n",
       "  'GPT-Neo': {'full_name': 'GPT-Neo', 'url': None, 'title': None},\n",
       "  'Feedforward Network': {'full_name': 'Feedforward Network',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'ASPP': {'full_name': 'Atrous Spatial Pyramid Pooling',\n",
       "   'url': 'http://arxiv.org/abs/1606.00915v2',\n",
       "   'title': 'DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs'},\n",
       "  'WEGL': {'full_name': 'Wasserstein Embedding for Graph Learning',\n",
       "   'url': 'https://arxiv.org/abs/2006.09430v2',\n",
       "   'title': 'Wasserstein Embedding for Graph Learning'},\n",
       "  'Invertible 1x1 Convolution': {'full_name': 'Invertible 1x1 Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1807.03039v2',\n",
       "   'title': 'Glow: Generative Flow with Invertible 1x1 Convolutions'},\n",
       "  'Temporal attention': {'full_name': 'Temporal attention',\n",
       "   'url': 'http://arxiv.org/abs/1708.02286v2',\n",
       "   'title': 'Jointly Attentive Spatial-Temporal Pooling Networks for Video-based Person Re-Identification'},\n",
       "  'Transformer': {'full_name': 'Transformer',\n",
       "   'url': 'http://arxiv.org/abs/1706.03762v5',\n",
       "   'title': 'Attention Is All You Need'},\n",
       "  'Expected Sarsa': {'full_name': 'Expected Sarsa',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'SEER': {'full_name': 'SEER',\n",
       "   'url': 'https://arxiv.org/abs/2103.01988v2',\n",
       "   'title': 'Self-supervised Pretraining of Visual Features in the Wild'},\n",
       "  'SM3': {'full_name': 'SM3',\n",
       "   'url': 'http://papers.nips.cc/paper/9168-memory-efficient-adaptive-optimization',\n",
       "   'title': 'Memory Efficient Adaptive Optimization'},\n",
       "  'Feedback Transformer': {'full_name': 'Feedback Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2002.09402v3',\n",
       "   'title': 'Addressing Some Limitations of Transformers with Feedback Memory'},\n",
       "  'cVAE': {'full_name': 'Conditional Variational Auto Encoder',\n",
       "   'url': 'http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models',\n",
       "   'title': 'Learning Structured Output Representation using Deep Conditional Generative Models'},\n",
       "  'Spatial Transformer': {'full_name': 'Spatial Transformer',\n",
       "   'url': 'http://arxiv.org/abs/1506.02025v3',\n",
       "   'title': 'Spatial Transformer Networks'},\n",
       "  '3D ResNet-RS': {'full_name': '3D ResNet-RS',\n",
       "   'url': 'https://arxiv.org/abs/2109.01696v1',\n",
       "   'title': 'Revisiting 3D ResNets for Video Recognition'},\n",
       "  'CAMoE': {'full_name': 'CAMoE',\n",
       "   'url': 'https://arxiv.org/abs/2109.04290v3',\n",
       "   'title': 'Improving Video-Text Retrieval by Multi-Stream Corpus Alignment and Dual Softmax Loss'},\n",
       "  'Topographic VAE': {'full_name': 'Topographic VAE',\n",
       "   'url': 'https://arxiv.org/abs/2109.01394v2',\n",
       "   'title': 'Topographic VAEs learn Equivariant Capsules'},\n",
       "  'Neural Turing Machine': {'full_name': 'Neural Turing Machine',\n",
       "   'url': 'http://arxiv.org/abs/1410.5401v2',\n",
       "   'title': 'Neural Turing Machines'},\n",
       "  'Gradient Checkpointing': {'full_name': 'Gradient Checkpointing',\n",
       "   'url': 'http://arxiv.org/abs/1604.06174v2',\n",
       "   'title': 'Training Deep Nets with Sublinear Memory Cost'},\n",
       "  'PSFR-GAN': {'full_name': 'PSFR-GAN',\n",
       "   'url': 'https://arxiv.org/abs/2009.08709v2',\n",
       "   'title': 'Progressive Semantic-Aware Style Transformation for Blind Face Restoration'},\n",
       "  'ACGPN': {'full_name': 'Adaptive Content Generating and Preserving Network',\n",
       "   'url': 'http://openaccess.thecvf.com/content_CVPR_2020/html/Yang_Towards_Photo-Realistic_Virtual_Try-On_by_Adaptively_Generating-Preserving_Image_Content_CVPR_2020_paper.html',\n",
       "   'title': 'Towards Photo-Realistic Virtual Try-On by Adaptively Generating-Preserving Image Content'},\n",
       "  'GCNII': {'full_name': 'GCNII',\n",
       "   'url': 'https://arxiv.org/abs/2007.02133v1',\n",
       "   'title': 'Simple and Deep Graph Convolutional Networks'},\n",
       "  'MoBY': {'full_name': 'MoBY',\n",
       "   'url': 'https://arxiv.org/abs/2105.04553v2',\n",
       "   'title': 'Self-Supervised Learning with Swin Transformers'},\n",
       "  'DMA': {'full_name': 'Dual Multimodal Attention',\n",
       "   'url': 'https://arxiv.org/abs/2004.03212v4',\n",
       "   'title': 'Text-Guided Neural Image Inpainting'},\n",
       "  'ZoomNet': {'full_name': 'ZoomNet',\n",
       "   'url': 'https://arxiv.org/abs/2007.11858v1',\n",
       "   'title': 'Whole-Body Human Pose Estimation in the Wild'},\n",
       "  'Collaborative Distillation': {'full_name': 'Collaborative Distillation',\n",
       "   'url': 'https://arxiv.org/abs/2003.08436v2',\n",
       "   'title': 'Collaborative Distillation for Ultra-Resolution Universal Style Transfer'},\n",
       "  'SPL': {'full_name': 'Semi-Pseudo-Label',\n",
       "   'url': 'https://arxiv.org/abs/2207.09869v1',\n",
       "   'title': 'A Novel Neural Network Training Method for Autonomous Driving Using Semi-Pseudo-Labels and 3D Data Augmentations'},\n",
       "  'Longformer': {'full_name': 'Longformer',\n",
       "   'url': 'https://arxiv.org/abs/2004.05150v2',\n",
       "   'title': 'Longformer: The Long-Document Transformer'},\n",
       "  'Peer-attention': {'full_name': 'Peer-attention',\n",
       "   'url': 'https://arxiv.org/abs/2008.08072v1',\n",
       "   'title': 'AssembleNet++: Assembling Modality Representations via Attention Connections'},\n",
       "  'SepFormer': {'full_name': 'SepFormer',\n",
       "   'url': 'https://arxiv.org/abs/2010.13154v2',\n",
       "   'title': 'Attention is All You Need in Speech Separation'},\n",
       "  'DAPO': {'full_name': 'Dialogue-Adaptive Pre-training Objective',\n",
       "   'url': 'https://arxiv.org/abs/2009.04984v1',\n",
       "   'title': 'Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation'},\n",
       "  'Single-path NAS': {'full_name': 'Single-path NAS',\n",
       "   'url': 'http://arxiv.org/abs/1904.02877v1',\n",
       "   'title': 'Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours'},\n",
       "  'GridMask': {'full_name': 'GridMask',\n",
       "   'url': 'https://arxiv.org/abs/2001.04086v2',\n",
       "   'title': 'GridMask Data Augmentation'},\n",
       "  'TS': {'full_name': 'Spatio-temporal stability analysis',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'High-resolution input': {'full_name': 'High-resolution input',\n",
       "   'url': 'https://arxiv.org/abs/2004.12186v2',\n",
       "   'title': 'EfficientPose: Scalable single-person pose estimation'},\n",
       "  'Make-A-Scene': {'full_name': 'Make-A-Scene',\n",
       "   'url': 'https://arxiv.org/abs/2203.13131v1',\n",
       "   'title': 'Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors'},\n",
       "  'TuckER': {'full_name': 'TuckER',\n",
       "   'url': 'https://arxiv.org/abs/1901.09590v2',\n",
       "   'title': 'TuckER: Tensor Factorization for Knowledge Graph Completion'},\n",
       "  'SVD Parameterization': {'full_name': 'Singular Value Decomposition Parameterization',\n",
       "   'url': 'http://arxiv.org/abs/1803.09327v1',\n",
       "   'title': 'Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization'},\n",
       "  'DetNAS': {'full_name': 'DetNAS',\n",
       "   'url': 'https://arxiv.org/abs/1903.10979v4',\n",
       "   'title': 'DetNAS: Backbone Search for Object Detection'},\n",
       "  'Seesaw Loss': {'full_name': 'Seesaw Loss',\n",
       "   'url': 'https://arxiv.org/abs/2008.10032v4',\n",
       "   'title': 'Seesaw Loss for Long-Tailed Instance Segmentation'},\n",
       "  'GCNFN': {'full_name': 'Graph Convolutional Networks for Fake News Detection',\n",
       "   'url': 'http://arxiv.org/abs/1902.06673v1',\n",
       "   'title': 'Fake News Detection on Social Media using Geometric Deep Learning'},\n",
       "  'DDParser': {'full_name': 'Baidu Dependency Parser',\n",
       "   'url': 'https://arxiv.org/abs/2009.00901v2',\n",
       "   'title': 'A Practical Chinese Dependency Parser Based on A Large-scale Dataset'},\n",
       "  'CuBERT': {'full_name': 'CuBERT',\n",
       "   'url': 'https://arxiv.org/abs/2001.00059v3',\n",
       "   'title': 'Learning and Evaluating Contextual Embedding of Source Code'},\n",
       "  'DG-Net': {'full_name': 'Discriminative and Generative Network',\n",
       "   'url': 'https://arxiv.org/abs/1904.07223v3',\n",
       "   'title': 'Joint Discriminative and Generative Learning for Person Re-identification'},\n",
       "  'ECANet': {'full_name': 'efficient channel attention',\n",
       "   'url': 'https://arxiv.org/abs/1910.03151v4',\n",
       "   'title': 'ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks'},\n",
       "  'Hierarchical Softmax': {'full_name': 'Hierarchical Softmax',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Clipped Double Q-learning': {'full_name': 'Clipped Double Q-learning',\n",
       "   'url': 'http://arxiv.org/abs/1802.09477v3',\n",
       "   'title': 'Addressing Function Approximation Error in Actor-Critic Methods'},\n",
       "  'Axial Attention': {'full_name': 'Axial Attention',\n",
       "   'url': 'https://arxiv.org/abs/1912.12180v1',\n",
       "   'title': 'Axial Attention in Multidimensional Transformers'},\n",
       "  'ResNeXt Block': {'full_name': 'ResNeXt Block',\n",
       "   'url': 'http://arxiv.org/abs/1611.05431v2',\n",
       "   'title': 'Aggregated Residual Transformations for Deep Neural Networks'},\n",
       "  'LDA': {'full_name': 'Linear Discriminant Analysis',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Viewmaker Network': {'full_name': 'Viewmaker Network',\n",
       "   'url': 'https://arxiv.org/abs/2010.07432v2',\n",
       "   'title': 'Viewmaker Networks: Learning Views for Unsupervised Representation Learning'},\n",
       "  'AutoInt': {'full_name': 'AutoInt',\n",
       "   'url': 'https://arxiv.org/abs/1810.11921v2',\n",
       "   'title': 'AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks'},\n",
       "  'CoOp': {'full_name': 'Context Optimization',\n",
       "   'url': 'https://arxiv.org/abs/2109.01134v5',\n",
       "   'title': 'Learning to Prompt for Vision-Language Models'},\n",
       "  'PointRend': {'full_name': 'PointRend',\n",
       "   'url': 'https://arxiv.org/abs/1912.08193v2',\n",
       "   'title': 'PointRend: Image Segmentation as Rendering'},\n",
       "  'LightConv': {'full_name': 'Lightweight Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1901.10430v2',\n",
       "   'title': 'Pay Less Attention with Lightweight and Dynamic Convolutions'},\n",
       "  'ENIGMA': {'full_name': 'ENIGMA',\n",
       "   'url': 'https://arxiv.org/abs/2102.10242v3',\n",
       "   'title': 'Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach'},\n",
       "  'Tree-structured Parzen Estimator Approach (TPE)': {'full_name': 'Tree-structured Parzen Estimator Approach (TPE)',\n",
       "   'url': 'https://www.researchgate.net/publication/285464863_Hyperopt_A_Python_library_for_optimizing_the_hyperparameters_of_machine_learning_algorithms',\n",
       "   'title': 'Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms'},\n",
       "  'Filter Response Normalization': {'full_name': 'Filter Response Normalization',\n",
       "   'url': 'https://arxiv.org/abs/1911.09737v2',\n",
       "   'title': 'Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks'},\n",
       "  'CSPResNeXt': {'full_name': 'CSPResNeXt',\n",
       "   'url': 'https://arxiv.org/abs/1911.11929v1',\n",
       "   'title': 'CSPNet: A New Backbone that can Enhance Learning Capability of CNN'},\n",
       "  'Multiple Random Window Discriminator': {'full_name': 'Multiple Random Window Discriminator',\n",
       "   'url': 'https://arxiv.org/abs/1909.11646v2',\n",
       "   'title': 'High Fidelity Speech Synthesis with Adversarial Networks'},\n",
       "  'Low-resolution input': {'full_name': 'Low-resolution input',\n",
       "   'url': 'https://arxiv.org/abs/2004.12186v2',\n",
       "   'title': 'EfficientPose: Scalable single-person pose estimation'},\n",
       "  'RepPoints': {'full_name': 'RepPoints',\n",
       "   'url': 'https://arxiv.org/abs/1904.11490v2',\n",
       "   'title': 'RepPoints: Point Set Representation for Object Detection'},\n",
       "  'Res2Net Block': {'full_name': 'Res2Net Block',\n",
       "   'url': 'https://arxiv.org/abs/1904.01169v3',\n",
       "   'title': 'Res2Net: A New Multi-scale Backbone Architecture'},\n",
       "  'rnnDrop': {'full_name': 'rnnDrop', 'url': None, 'title': None},\n",
       "  'LOGAN': {'full_name': 'LOGAN',\n",
       "   'url': 'https://arxiv.org/abs/1912.00953v2',\n",
       "   'title': 'LOGAN: Latent Optimisation for Generative Adversarial Networks'},\n",
       "  'L-GCN': {'full_name': 'Learnable adjacency matrix GCN',\n",
       "   'url': 'https://arxiv.org/abs/2104.05089v2',\n",
       "   'title': 'The World as a Graph: Improving El Niño Forecasts with Graph Neural Networks'},\n",
       "  'GIN': {'full_name': 'Graph Isomorphism Network',\n",
       "   'url': 'http://arxiv.org/abs/1810.00826v3',\n",
       "   'title': 'How Powerful are Graph Neural Networks?'},\n",
       "  'ShuffleNet V2 Block': {'full_name': 'ShuffleNet V2 Block',\n",
       "   'url': 'http://arxiv.org/abs/1807.11164v1',\n",
       "   'title': 'ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design'},\n",
       "  'Chimera': {'full_name': 'Chimera',\n",
       "   'url': 'https://arxiv.org/abs/2107.06925v3',\n",
       "   'title': 'Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines'},\n",
       "  'Fast-OCR': {'full_name': 'Fast-OCR',\n",
       "   'url': 'https://arxiv.org/abs/2009.10181v5',\n",
       "   'title': 'Towards Image-based Automatic Meter Reading in Unconstrained Scenarios: A Robust and Efficient Approach'},\n",
       "  'Object Dropout': {'full_name': 'Object Dropout',\n",
       "   'url': 'https://www.ijcai.org/proceedings/2021/105',\n",
       "   'title': 'Perturb, Predict & Paraphrase: Semi-Supervised Learning using Noisy Student for Image Captioning'},\n",
       "  'Spectral Clustering': {'full_name': 'Spectral Clustering',\n",
       "   'url': 'http://arxiv.org/abs/0711.0189v1',\n",
       "   'title': 'A Tutorial on Spectral Clustering'},\n",
       "  'IICNet': {'full_name': 'IICNet',\n",
       "   'url': 'https://arxiv.org/abs/2109.04242v1',\n",
       "   'title': 'IICNet: A Generic Framework for Reversible Image Conversion'},\n",
       "  'Kaleido-BERT': {'full_name': 'Kaleido-BERT', 'url': None, 'title': None},\n",
       "  'ARMA': {'full_name': 'ARMA GNN',\n",
       "   'url': 'https://arxiv.org/abs/1901.01343v7',\n",
       "   'title': 'Graph Neural Networks with convolutional ARMA filters'},\n",
       "  'ConvBERT': {'full_name': 'ConvBERT',\n",
       "   'url': 'https://arxiv.org/abs/2008.02496v3',\n",
       "   'title': 'ConvBERT: Improving BERT with Span-based Dynamic Convolution'},\n",
       "  'MacBERT': {'full_name': 'MacBERT',\n",
       "   'url': 'https://arxiv.org/abs/2004.13922v2',\n",
       "   'title': 'Revisiting Pre-Trained Models for Chinese Natural Language Processing'},\n",
       "  'Latent Optimisation': {'full_name': 'Latent Optimisation',\n",
       "   'url': 'https://arxiv.org/abs/1905.06723v2',\n",
       "   'title': 'Deep Compressed Sensing'},\n",
       "  'RBPN': {'full_name': 'Recurrent Back Projection Network',\n",
       "   'url': 'http://arxiv.org/abs/1903.10128v1',\n",
       "   'title': 'Recurrent Back-Projection Network for Video Super-Resolution'},\n",
       "  'Smish': {'full_name': 'Smish', 'url': None, 'title': None},\n",
       "  'Graph2Tree': {'full_name': 'Graph-to-Tree MWP Solver',\n",
       "   'url': 'https://aclanthology.org/2020.acl-main.362',\n",
       "   'title': 'Graph-to-Tree Learning for Solving Math Word Problems'},\n",
       "  'Residual GRU': {'full_name': 'Residual GRU',\n",
       "   'url': 'http://arxiv.org/abs/1608.05148v2',\n",
       "   'title': 'Full Resolution Image Compression with Recurrent Neural Networks'},\n",
       "  'Wide Residual Block': {'full_name': 'Wide Residual Block',\n",
       "   'url': 'http://arxiv.org/abs/1605.07146v4',\n",
       "   'title': 'Wide Residual Networks'},\n",
       "  'BERT': {'full_name': 'BERT',\n",
       "   'url': 'https://arxiv.org/abs/1810.04805v2',\n",
       "   'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'},\n",
       "  'ResNeXt-Elastic': {'full_name': 'ResNeXt-Elastic',\n",
       "   'url': 'http://arxiv.org/abs/1812.05262v2',\n",
       "   'title': 'ELASTIC: Improving CNNs with Dynamic Scaling Policies'},\n",
       "  'BP-Transformer': {'full_name': 'BP-Transformer',\n",
       "   'url': 'https://arxiv.org/abs/1911.04070v1',\n",
       "   'title': 'BP-Transformer: Modelling Long-Range Context via Binary Partitioning'},\n",
       "  'Snapshot Ensembles': {'full_name': 'Snapshot Ensembles: Train 1, get M for free',\n",
       "   'url': 'http://arxiv.org/abs/1704.00109v1',\n",
       "   'title': 'Snapshot Ensembles: Train 1, get M for free'},\n",
       "  'FastMoE': {'full_name': 'FastMoE',\n",
       "   'url': 'https://arxiv.org/abs/2103.13262v1',\n",
       "   'title': 'FastMoE: A Fast Mixture-of-Expert Training System'},\n",
       "  'RPDet': {'full_name': 'RPDet',\n",
       "   'url': 'https://arxiv.org/abs/1904.11490v2',\n",
       "   'title': 'RepPoints: Point Set Representation for Object Detection'},\n",
       "  'Composite Fields': {'full_name': 'Composite Fields',\n",
       "   'url': 'http://arxiv.org/abs/1903.06593v2',\n",
       "   'title': 'PifPaf: Composite Fields for Human Pose Estimation'},\n",
       "  'Population Based Augmentation': {'full_name': 'Population Based Augmentation',\n",
       "   'url': 'https://arxiv.org/abs/1905.05393v1',\n",
       "   'title': 'Population Based Augmentation: Efficient Learning of Augmentation Policy Schedules'},\n",
       "  'DropConnect': {'full_name': 'DropConnect',\n",
       "   'url': 'http://cds.nyu.edu/projects/regularization-neural-networks-using-dropconnect/',\n",
       "   'title': 'Regularization of Neural Networks using DropConnect'},\n",
       "  'Compact Global Descriptor': {'full_name': 'Compact Global Descriptor',\n",
       "   'url': 'https://arxiv.org/abs/1907.09665v10',\n",
       "   'title': 'Compact Global Descriptor for Neural Networks'},\n",
       "  'ClariNet': {'full_name': 'ClariNet',\n",
       "   'url': 'http://arxiv.org/abs/1807.07281v3',\n",
       "   'title': 'ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech'},\n",
       "  'CentripetalNet': {'full_name': 'CentripetalNet',\n",
       "   'url': 'https://arxiv.org/abs/2003.09119v1',\n",
       "   'title': 'CentripetalNet: Pursuing High-quality Keypoint Pairs for Object Detection'},\n",
       "  'VTDE': {'full_name': 'Variational Trace Distance Estimation',\n",
       "   'url': 'https://arxiv.org/abs/2012.05768v3',\n",
       "   'title': 'Variational Quantum Algorithms for Trace Distance and Fidelity Estimation'},\n",
       "  'DenseNet-Elastic': {'full_name': 'DenseNet-Elastic',\n",
       "   'url': 'http://arxiv.org/abs/1812.05262v2',\n",
       "   'title': 'ELASTIC: Improving CNNs with Dynamic Scaling Policies'},\n",
       "  'PICARD': {'full_name': 'Parsing Incrementally for Constrained Auto-Regressive Decoding',\n",
       "   'url': 'https://arxiv.org/abs/2109.05093v1',\n",
       "   'title': 'PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models'},\n",
       "  'Local Contrast Normalization': {'full_name': 'Local Contrast Normalization',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'FT-Transformer': {'full_name': 'FT-Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2106.11959v2',\n",
       "   'title': 'Revisiting Deep Learning Models for Tabular Data'},\n",
       "  'Graph Transformer': {'full_name': 'Graph Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2012.09699v2',\n",
       "   'title': 'A Generalization of Transformer Networks to Graphs'},\n",
       "  'AdaGrad': {'full_name': 'AdaGrad', 'url': None, 'title': None},\n",
       "  'SRGAN': {'full_name': 'SRGAN',\n",
       "   'url': 'http://arxiv.org/abs/1609.04802v5',\n",
       "   'title': 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'},\n",
       "  'SlowMo': {'full_name': 'SlowMo',\n",
       "   'url': 'https://arxiv.org/abs/1910.00643v2',\n",
       "   'title': 'SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum'},\n",
       "  'ALS': {'full_name': 'Adaptive Label Smoothing',\n",
       "   'url': 'http://proceedings.mlr.press/v123/kim20a.html',\n",
       "   'title': 'Efficient Model for Image Classification With Regularization Tricks'},\n",
       "  'SqueezeNet': {'full_name': 'SqueezeNet',\n",
       "   'url': 'http://arxiv.org/abs/1602.07360v4',\n",
       "   'title': 'SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size'},\n",
       "  'DEXTR': {'full_name': 'Deep Extreme Cut',\n",
       "   'url': 'http://arxiv.org/abs/1711.09081v2',\n",
       "   'title': 'Deep Extreme Cut: From Extreme Points to Object Segmentation'},\n",
       "  'Demon': {'full_name': 'Demon',\n",
       "   'url': 'https://arxiv.org/abs/1910.04952v4',\n",
       "   'title': 'Demon: Improved Neural Network Training with Momentum Decay'},\n",
       "  'Channel & Spatial attention': {'full_name': 'Channel & Spatial attention',\n",
       "   'url': 'http://arxiv.org/abs/1704.06904v1',\n",
       "   'title': 'Residual Attention Network for Image Classification'},\n",
       "  'PP-YOLO': {'full_name': 'PP-YOLO',\n",
       "   'url': 'https://arxiv.org/abs/2007.12099v3',\n",
       "   'title': 'PP-YOLO: An Effective and Efficient Implementation of Object Detector'},\n",
       "  'Implicit PointRend': {'full_name': 'Implicit PointRend',\n",
       "   'url': 'https://arxiv.org/abs/2104.06404v2',\n",
       "   'title': 'Pointly-Supervised Instance Segmentation'},\n",
       "  'Point-GNN': {'full_name': 'Point-GNN',\n",
       "   'url': 'https://arxiv.org/abs/2003.01251v1',\n",
       "   'title': 'Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud'},\n",
       "  'reSGLD': {'full_name': 'Replica exchange stochastic gradient Langevin Dynamics',\n",
       "   'url': 'https://arxiv.org/abs/2008.05367v3',\n",
       "   'title': 'Non-convex Learning via Replica Exchange Stochastic Gradient MCMC'},\n",
       "  'CutBlur': {'full_name': 'CutBlur',\n",
       "   'url': 'https://arxiv.org/abs/2004.00448v2',\n",
       "   'title': 'Rethinking Data Augmentation for Image Super-resolution: A Comprehensive Analysis and a New Strategy'},\n",
       "  'Large-scale spectral clustering': {'full_name': 'Large-scale spectral clustering',\n",
       "   'url': 'https://www.researchgate.net/publication/351270623_Divide-and-conquer_based_Large-Scale_Spectral_Clustering',\n",
       "   'title': 'Divide-and-conquer based Large-Scale Spectral Clustering'},\n",
       "  'Gradient Normalization': {'full_name': 'Gradient Normalization',\n",
       "   'url': 'https://arxiv.org/abs/2109.02235v2',\n",
       "   'title': 'Gradient Normalization for Generative Adversarial Networks'},\n",
       "  'Smooth Step': {'full_name': 'Smooth Step',\n",
       "   'url': 'https://arxiv.org/abs/2002.07772v2',\n",
       "   'title': 'The Tree Ensemble Layer: Differentiability meets Conditional Computation'},\n",
       "  'CARLA': {'full_name': 'CARLA: An Open Urban Driving Simulator',\n",
       "   'url': 'http://arxiv.org/abs/1711.03938v1',\n",
       "   'title': 'CARLA: An Open Urban Driving Simulator'},\n",
       "  'VirTex': {'full_name': 'VirTex',\n",
       "   'url': 'https://arxiv.org/abs/2006.06666v3',\n",
       "   'title': 'VirTex: Learning Visual Representations from Textual Annotations'},\n",
       "  'CKConv': {'full_name': 'Continuous Kernel Convolution',\n",
       "   'url': 'https://arxiv.org/abs/2102.02611v3',\n",
       "   'title': 'CKConv: Continuous Kernel Convolution For Sequential Data'},\n",
       "  'Decorrelated Batch Normalization': {'full_name': 'Decorrelated Batch Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1804.08450v1',\n",
       "   'title': 'Decorrelated Batch Normalization'},\n",
       "  'Additive Attention': {'full_name': 'Additive Attention',\n",
       "   'url': 'http://arxiv.org/abs/1409.0473v7',\n",
       "   'title': 'Neural Machine Translation by Jointly Learning to Align and Translate'},\n",
       "  'SqueezeNeXt': {'full_name': 'SqueezeNeXt',\n",
       "   'url': 'http://arxiv.org/abs/1803.10615v2',\n",
       "   'title': 'SqueezeNext: Hardware-Aware Neural Network Design'},\n",
       "  'HANet': {'full_name': 'Height-driven Attention Network',\n",
       "   'url': 'https://arxiv.org/abs/2003.05128v3',\n",
       "   'title': \"Cars Can't Fly up in the Sky: Improving Urban-Scene Segmentation via Height-driven Attention Networks\"},\n",
       "  'FiLM Module': {'full_name': 'FiLM Module',\n",
       "   'url': 'https://arxiv.org/abs/2009.00713v2',\n",
       "   'title': 'WaveGrad: Estimating Gradients for Waveform Generation'},\n",
       "  'YellowFin': {'full_name': 'YellowFin',\n",
       "   'url': 'http://arxiv.org/abs/1706.03471v2',\n",
       "   'title': 'YellowFin and the Art of Momentum Tuning'},\n",
       "  'LFPNet (TTA)': {'full_name': 'LFPNet with test time augmentation',\n",
       "   'url': 'https://arxiv.org/abs/2003.07711v1',\n",
       "   'title': '$F$, $B$, Alpha Matting'},\n",
       "  'GradientDICE': {'full_name': 'GradientDICE',\n",
       "   'url': 'https://arxiv.org/abs/2001.11113v7',\n",
       "   'title': 'GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values'},\n",
       "  'DRPNN': {'full_name': 'Deep Residual Pansharpening Neural Network',\n",
       "   'url': 'http://arxiv.org/abs/1705.07556v2',\n",
       "   'title': 'Boosting the accuracy of multi-spectral image pan-sharpening by learning a deep residual network'},\n",
       "  'Triplet Entropy Loss': {'full_name': 'Triplet Entropy Loss',\n",
       "   'url': 'https://arxiv.org/abs/2012.03775v1',\n",
       "   'title': 'Triplet Entropy Loss: Improving The Generalisation of Short Speech Language Identification Systems'},\n",
       "  'RESCAL': {'full_name': 'RESCAL',\n",
       "   'url': 'https://icml.cc/2011/papers/438_icmlpaper.pdf',\n",
       "   'title': 'A Three-Way Model for Collective Learning on Multi-Relational Data'},\n",
       "  'FastSpeech 2': {'full_name': 'FastSpeech 2',\n",
       "   'url': 'https://arxiv.org/abs/2006.04558v8',\n",
       "   'title': 'FastSpeech 2: Fast and High-Quality End-to-End Text to Speech'},\n",
       "  'Perceiver IO': {'full_name': 'Perceiver IO',\n",
       "   'url': 'https://arxiv.org/abs/2107.14795v3',\n",
       "   'title': 'Perceiver IO: A General Architecture for Structured Inputs & Outputs'},\n",
       "  'GMI': {'full_name': 'Graphic Mutual Information',\n",
       "   'url': 'https://arxiv.org/abs/2002.01169v1',\n",
       "   'title': 'Graph Representation Learning via Graphical Mutual Information Maximization'},\n",
       "  'AccoMontage': {'full_name': 'AccoMontage',\n",
       "   'url': 'https://arxiv.org/abs/2108.11213v1',\n",
       "   'title': 'AccoMontage: Accompaniment Arrangement via Phrase Selection and Style Transfer'},\n",
       "  'Masked Convolution': {'full_name': 'Masked Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1601.06759v3',\n",
       "   'title': 'Pixel Recurrent Neural Networks'},\n",
       "  'R-CNN': {'full_name': 'R-CNN',\n",
       "   'url': 'http://arxiv.org/abs/1311.2524v5',\n",
       "   'title': 'Rich feature hierarchies for accurate object detection and semantic segmentation'},\n",
       "  'TGAN': {'full_name': 'TGAN',\n",
       "   'url': 'http://arxiv.org/abs/1611.06624v3',\n",
       "   'title': 'Temporal Generative Adversarial Nets with Singular Value Clipping'},\n",
       "  'ESPNetv2': {'full_name': 'ESPNetv2',\n",
       "   'url': 'http://arxiv.org/abs/1811.11431v3',\n",
       "   'title': 'ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network'},\n",
       "  'StyleGAN': {'full_name': 'StyleGAN',\n",
       "   'url': 'http://arxiv.org/abs/1812.04948v3',\n",
       "   'title': 'A Style-Based Generator Architecture for Generative Adversarial Networks'},\n",
       "  'Grab': {'full_name': 'Grab',\n",
       "   'url': 'https://arxiv.org/abs/2001.01033v1',\n",
       "   'title': 'Grab: Fast and Accurate Sensor Processing for Cashier-Free Shopping'},\n",
       "  'myGym': {'full_name': 'MyGym: Modular Toolkit for Visuomotor Robotic Tasks',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Position-Wise Feed-Forward Layer': {'full_name': 'Position-Wise Feed-Forward Layer',\n",
       "   'url': 'http://arxiv.org/abs/1706.03762v5',\n",
       "   'title': 'Attention Is All You Need'},\n",
       "  'CoaT': {'full_name': 'Co-Scale Conv-attentional Image Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2104.06399v2',\n",
       "   'title': 'Co-Scale Conv-Attentional Image Transformers'},\n",
       "  'VGG Loss': {'full_name': 'VGG Loss',\n",
       "   'url': 'http://arxiv.org/abs/1609.04802v5',\n",
       "   'title': 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'},\n",
       "  'AutoML-Zero': {'full_name': 'AutoML-Zero',\n",
       "   'url': 'https://arxiv.org/abs/2003.03384v2',\n",
       "   'title': 'AutoML-Zero: Evolving Machine Learning Algorithms From Scratch'},\n",
       "  'Distributed Shampoo': {'full_name': 'Distributed Shampoo',\n",
       "   'url': 'https://openreview.net/forum?id=Sc8cY4Jpi3s',\n",
       "   'title': 'Towards Practical Second Order Optimization for Deep Learning'},\n",
       "  'PCB': {'full_name': 'Part-based Convolutional Baseline',\n",
       "   'url': 'http://arxiv.org/abs/1711.09349v3',\n",
       "   'title': 'Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)'},\n",
       "  'Adaptive Dropout': {'full_name': 'Adaptive Dropout',\n",
       "   'url': 'http://papers.nips.cc/paper/5032-adaptive-dropout-for-training-deep-neural-networks',\n",
       "   'title': 'Adaptive dropout for training deep neural networks'},\n",
       "  'Random Grayscale': {'full_name': 'Random Grayscale',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'WenLan': {'full_name': 'WenLan',\n",
       "   'url': 'https://arxiv.org/abs/2103.06561v6',\n",
       "   'title': 'WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training'},\n",
       "  'Aging Evolution': {'full_name': 'Aging Evolution',\n",
       "   'url': 'http://arxiv.org/abs/1802.01548v7',\n",
       "   'title': 'Regularized Evolution for Image Classifier Architecture Search'},\n",
       "  'Fastformer': {'full_name': 'Fastformer',\n",
       "   'url': 'https://arxiv.org/abs/2108.09084v6',\n",
       "   'title': 'Fastformer: Additive Attention Can Be All You Need'},\n",
       "  'CodeBERT': {'full_name': 'CodeBERT',\n",
       "   'url': 'https://arxiv.org/abs/2002.08155v4',\n",
       "   'title': 'CodeBERT: A Pre-Trained Model for Programming and Natural Languages'},\n",
       "  'PCA Whitening': {'full_name': 'PCA Whitening', 'url': None, 'title': None},\n",
       "  'FCN': {'full_name': 'Fully Convolutional Network',\n",
       "   'url': 'http://arxiv.org/abs/1605.06211v1',\n",
       "   'title': 'Fully Convolutional Networks for Semantic Segmentation'},\n",
       "  'SHAP': {'full_name': 'Shapley Additive Explanations',\n",
       "   'url': 'http://arxiv.org/abs/1705.07874v2',\n",
       "   'title': 'A Unified Approach to Interpreting Model Predictions'},\n",
       "  'DetNASNet': {'full_name': 'DetNASNet',\n",
       "   'url': 'https://arxiv.org/abs/1903.10979v4',\n",
       "   'title': 'DetNAS: Backbone Search for Object Detection'},\n",
       "  'Adam': {'full_name': 'Adam',\n",
       "   'url': 'http://arxiv.org/abs/1412.6980v9',\n",
       "   'title': 'Adam: A Method for Stochastic Optimization'},\n",
       "  'RoI Tanh-polar Transform': {'full_name': 'RoI Tanh-polar Transform',\n",
       "   'url': 'https://arxiv.org/abs/2102.02717v3',\n",
       "   'title': 'RoI Tanh-polar Transformer Network for Face Parsing in the Wild'},\n",
       "  'FMix': {'full_name': 'FMix',\n",
       "   'url': 'https://arxiv.org/abs/2002.12047v3',\n",
       "   'title': 'FMix: Enhancing Mixed Sample Data Augmentation'},\n",
       "  'Spectral Normalization': {'full_name': 'Spectral Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1802.05957v1',\n",
       "   'title': 'Spectral Normalization for Generative Adversarial Networks'},\n",
       "  'ZeRO-Infinity': {'full_name': 'ZeRO-Infinity',\n",
       "   'url': 'https://arxiv.org/abs/2104.07857v1',\n",
       "   'title': 'ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning'},\n",
       "  'Unitary RNN': {'full_name': 'Unitary RNN',\n",
       "   'url': 'http://arxiv.org/abs/1511.06464v4',\n",
       "   'title': 'Unitary Evolution Recurrent Neural Networks'},\n",
       "  'WaveGrad DBlock': {'full_name': 'WaveGrad DBlock',\n",
       "   'url': 'https://arxiv.org/abs/2009.00713v2',\n",
       "   'title': 'WaveGrad: Estimating Gradients for Waveform Generation'},\n",
       "  'Fast-YOLOv2': {'full_name': 'Fast-YOLOv2',\n",
       "   'url': 'http://arxiv.org/abs/1612.08242v1',\n",
       "   'title': 'YOLO9000: Better, Faster, Stronger'},\n",
       "  'NCL': {'full_name': 'Neighborhood Contrastive Learning',\n",
       "   'url': 'https://arxiv.org/abs/2106.05142v1',\n",
       "   'title': 'Neighborhood Contrastive Learning Applied to Online Patient Monitoring'},\n",
       "  'End-To-End Memory Network': {'full_name': 'End-To-End Memory Network',\n",
       "   'url': 'http://arxiv.org/abs/1503.08895v5',\n",
       "   'title': 'End-To-End Memory Networks'},\n",
       "  'HITNet': {'full_name': 'HITNet',\n",
       "   'url': 'https://arxiv.org/abs/2007.12140v3',\n",
       "   'title': 'HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching'},\n",
       "  'FixRes': {'full_name': 'FixRes',\n",
       "   'url': 'https://arxiv.org/abs/1906.06423v4',\n",
       "   'title': 'Fixing the train-test resolution discrepancy'},\n",
       "  'DenseNet': {'full_name': 'DenseNet',\n",
       "   'url': 'http://arxiv.org/abs/1608.06993v5',\n",
       "   'title': 'Densely Connected Convolutional Networks'},\n",
       "  'Blended Diffusion': {'full_name': 'Blended Diffusion',\n",
       "   'url': 'https://arxiv.org/abs/2111.14818v2',\n",
       "   'title': 'Blended Diffusion for Text-driven Editing of Natural Images'},\n",
       "  'PVT': {'full_name': 'Pyramid Vision Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2102.12122v2',\n",
       "   'title': 'Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions'},\n",
       "  'Tacotron': {'full_name': 'Tacotron',\n",
       "   'url': 'http://arxiv.org/abs/1703.10135v2',\n",
       "   'title': 'Tacotron: Towards End-to-End Speech Synthesis'},\n",
       "  'BYOL': {'full_name': 'Bootstrap Your Own Latent',\n",
       "   'url': 'http://proceedings.neurips.cc/paper/2020/hash/f3ada80d5c4ee70142b17b8192b2958e-Abstract.html',\n",
       "   'title': 'Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning'},\n",
       "  'TD Lambda': {'full_name': 'TD Lambda', 'url': None, 'title': None},\n",
       "  'Projection Discriminator': {'full_name': 'Projection Discriminator',\n",
       "   'url': 'http://arxiv.org/abs/1802.05637v2',\n",
       "   'title': 'cGANs with Projection Discriminator'},\n",
       "  'Supervised Contrastive Loss': {'full_name': 'Supervised Contrastive Loss',\n",
       "   'url': 'https://arxiv.org/abs/2004.11362v5',\n",
       "   'title': 'Supervised Contrastive Learning'},\n",
       "  'CAG': {'full_name': 'Class activation guide',\n",
       "   'url': 'https://arxiv.org/abs/2007.05405v1',\n",
       "   'title': 'Recognition of Instrument-Tissue Interactions in Endoscopic Videos via Action Triplets'},\n",
       "  'SRDC': {'full_name': 'Structurally Regularized Deep Clustering',\n",
       "   'url': 'https://arxiv.org/abs/2003.08607v1',\n",
       "   'title': 'Unsupervised Domain Adaptation via Structurally Regularized Deep Clustering'},\n",
       "  'SRU++': {'full_name': 'SRU++',\n",
       "   'url': 'https://arxiv.org/abs/2102.12459v3',\n",
       "   'title': 'When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute'},\n",
       "  'QHM': {'full_name': 'QHM',\n",
       "   'url': 'http://arxiv.org/abs/1810.06801v4',\n",
       "   'title': 'Quasi-hyperbolic momentum and Adam for deep learning'},\n",
       "  'FFMv1': {'full_name': 'Feature Fusion Module v1',\n",
       "   'url': 'http://arxiv.org/abs/1811.04533v3',\n",
       "   'title': 'M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network'},\n",
       "  'Nesterov Accelerated Gradient': {'full_name': 'Nesterov Accelerated Gradient',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Contextual Residual Aggregation': {'full_name': 'Contextual Residual Aggregation',\n",
       "   'url': 'https://arxiv.org/abs/2005.09704v1',\n",
       "   'title': 'Contextual Residual Aggregation for Ultra High-Resolution Image Inpainting'},\n",
       "  'MUSIQ': {'full_name': 'MUSIQ',\n",
       "   'url': 'https://arxiv.org/abs/2108.05997v1',\n",
       "   'title': 'MUSIQ: Multi-scale Image Quality Transformer'},\n",
       "  'TabNet': {'full_name': 'TabNet',\n",
       "   'url': 'https://arxiv.org/abs/1908.07442v5',\n",
       "   'title': 'TabNet: Attentive Interpretable Tabular Learning'},\n",
       "  'MFF': {'full_name': 'Multimodal Fuzzy Fusion Framework',\n",
       "   'url': 'http://arxiv.org/abs/1611.09926v1',\n",
       "   'title': 'Choquet integral in decision analysis - lessons from the axiomatization'},\n",
       "  'Focal Transformers': {'full_name': 'Focal Transformers',\n",
       "   'url': 'https://arxiv.org/abs/2107.00641v1',\n",
       "   'title': 'Focal Self-attention for Local-Global Interactions in Vision Transformers'},\n",
       "  'Routing Transformer': {'full_name': 'Routing Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2003.05997v5',\n",
       "   'title': 'Efficient Content-Based Sparse Attention with Routing Transformers'},\n",
       "  'Chinchilla': {'full_name': 'Chinchilla',\n",
       "   'url': 'https://arxiv.org/abs/2203.15556v1',\n",
       "   'title': 'Training Compute-Optimal Large Language Models'},\n",
       "  'MixConv': {'full_name': 'Mixed Depthwise Convolution',\n",
       "   'url': 'https://arxiv.org/abs/1907.09595v3',\n",
       "   'title': 'MixConv: Mixed Depthwise Convolutional Kernels'},\n",
       "  'DeeBERT': {'full_name': 'DeeBERT',\n",
       "   'url': 'https://arxiv.org/abs/2004.12993v1',\n",
       "   'title': 'DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference'},\n",
       "  'FIERCE': {'full_name': 'Feature Information Entropy Regularized Cross Entropy',\n",
       "   'url': 'https://arxiv.org/abs/2208.03684v1',\n",
       "   'title': 'Preserving Fine-Grain Feature Information in Classification via Entropic Regularization'},\n",
       "  'Dilated Bottleneck with Projection Block': {'full_name': 'Dilated Bottleneck with Projection Block',\n",
       "   'url': 'http://arxiv.org/abs/1804.06215v2',\n",
       "   'title': 'DetNet: A Backbone network for Object Detection'},\n",
       "  'EdgeFlow': {'full_name': 'EdgeFlow',\n",
       "   'url': 'https://arxiv.org/abs/2109.09406v2',\n",
       "   'title': 'EdgeFlow: Achieving Practical Interactive Segmentation with Edge-Guided Flow'},\n",
       "  'BRepNet': {'full_name': 'BRepNet',\n",
       "   'url': 'https://arxiv.org/abs/2104.00706v2',\n",
       "   'title': 'BRepNet: A topological message passing system for solid models'},\n",
       "  'Hierarchical Feature Fusion': {'full_name': 'Hierarchical Feature Fusion',\n",
       "   'url': 'http://arxiv.org/abs/1803.06815v3',\n",
       "   'title': 'ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation'},\n",
       "  'mRNN': {'full_name': 'Multiplicative RNN', 'url': None, 'title': None},\n",
       "  'SCARLET-NAS': {'full_name': 'SCARLET-NAS',\n",
       "   'url': 'https://arxiv.org/abs/1908.06022v6',\n",
       "   'title': 'SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search'},\n",
       "  'Residual Block': {'full_name': 'Residual Block',\n",
       "   'url': 'http://arxiv.org/abs/1512.03385v1',\n",
       "   'title': 'Deep Residual Learning for Image Recognition'},\n",
       "  'Visformer': {'full_name': 'Visformer',\n",
       "   'url': 'https://arxiv.org/abs/2104.12533v4',\n",
       "   'title': 'Visformer: The Vision-friendly Transformer'},\n",
       "  'S-GCN': {'full_name': 'Spherical Graph Convolutional Network',\n",
       "   'url': 'https://arxiv.org/abs/2011.07980v2',\n",
       "   'title': 'Spherical convolutions on molecular graphs for protein model quality assessment'},\n",
       "  'LSTM': {'full_name': 'Long Short-Term Memory', 'url': None, 'title': None},\n",
       "  'MAVL': {'full_name': 'Multiscale Attention ViT with Late fusion',\n",
       "   'url': 'https://arxiv.org/abs/2111.11430v6',\n",
       "   'title': 'Class-agnostic Object Detection with Multi-modal Transformer'},\n",
       "  'WGAN-GP Loss': {'full_name': 'WGAN-GP Loss',\n",
       "   'url': 'http://arxiv.org/abs/1704.00028v3',\n",
       "   'title': 'Improved Training of Wasserstein GANs'},\n",
       "  'H-BEMD': {'full_name': 'Hue — Bi-Dimensional Empirical Mode Decomposition',\n",
       "   'url': 'https://ieeexplore.ieee.org/document/9159123',\n",
       "   'title': 'Deep Learning for Landslide Recognition in Satellite Architecture'},\n",
       "  'Cosine Normalization': {'full_name': 'Cosine Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1702.05870v5',\n",
       "   'title': 'Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks'},\n",
       "  'Zoneout': {'full_name': 'Zoneout',\n",
       "   'url': 'http://arxiv.org/abs/1606.01305v4',\n",
       "   'title': 'Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations'},\n",
       "  'GaAN': {'full_name': 'Gated Attention Networks',\n",
       "   'url': 'http://arxiv.org/abs/1803.07294v1',\n",
       "   'title': 'GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs'},\n",
       "  'Exact Fusion Model': {'full_name': 'Exact Fusion Model',\n",
       "   'url': 'https://arxiv.org/abs/1911.11929v1',\n",
       "   'title': 'CSPNet: A New Backbone that can Enhance Learning Capability of CNN'},\n",
       "  'Fixed Factorized Attention': {'full_name': 'Fixed Factorized Attention',\n",
       "   'url': 'http://arxiv.org/abs/1904.10509v1',\n",
       "   'title': 'Generating Long Sequences with Sparse Transformers'},\n",
       "  'CPC v2': {'full_name': 'CPC v2',\n",
       "   'url': 'https://arxiv.org/abs/1905.09272v3',\n",
       "   'title': 'Data-Efficient Image Recognition with Contrastive Predictive Coding'},\n",
       "  'DSGN': {'full_name': 'Deep Stereo Geometry Network',\n",
       "   'url': 'https://arxiv.org/abs/2001.03398v3',\n",
       "   'title': 'DSGN: Deep Stereo Geometry Network for 3D Object Detection'},\n",
       "  'Multi-DConv-Head Attention': {'full_name': 'Multi-DConv-Head Attention',\n",
       "   'url': 'https://arxiv.org/abs/2109.08668v2',\n",
       "   'title': 'Primer: Searching for Efficient Transformers for Language Modeling'},\n",
       "  'Style-based Recalibration Module': {'full_name': 'Style-based Recalibration Module',\n",
       "   'url': 'http://arxiv.org/abs/1903.10829v1',\n",
       "   'title': 'SRM : A Style-based Recalibration Module for Convolutional Neural Networks'},\n",
       "  'Hamburger': {'full_name': 'Hamburger',\n",
       "   'url': 'https://arxiv.org/abs/2109.04553v2',\n",
       "   'title': 'Is Attention Better Than Matrix Decomposition?'},\n",
       "  'LapStyle': {'full_name': 'Laplacian Pyramid Network',\n",
       "   'url': 'https://arxiv.org/abs/2104.05376v2',\n",
       "   'title': 'Drafting and Revision: Laplacian Pyramid Network for Fast High-Quality Artistic Style Transfer'},\n",
       "  'MoGA-C': {'full_name': 'MoGA-C',\n",
       "   'url': 'https://arxiv.org/abs/1908.01314v4',\n",
       "   'title': 'MoGA: Searching Beyond MobileNetV3'},\n",
       "  'MViT': {'full_name': 'Multiscale Vision Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2104.11227v1',\n",
       "   'title': 'Multiscale Vision Transformers'},\n",
       "  'Weight Normalization': {'full_name': 'Weight Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1602.07868v3',\n",
       "   'title': 'Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks'},\n",
       "  'Skip-gram Word2Vec': {'full_name': 'Skip-gram Word2Vec',\n",
       "   'url': 'http://arxiv.org/abs/1301.3781v3',\n",
       "   'title': 'Efficient Estimation of Word Representations in Vector Space'},\n",
       "  'GPS': {'full_name': 'Greedy Policy Search',\n",
       "   'url': 'https://arxiv.org/abs/2002.09103v2',\n",
       "   'title': 'Greedy Policy Search: A Simple Baseline for Learnable Test-Time Augmentation'},\n",
       "  'COLA': {'full_name': 'COLA',\n",
       "   'url': 'https://arxiv.org/abs/2010.10915v1',\n",
       "   'title': 'Contrastive Learning of General-Purpose Audio Representations'},\n",
       "  'Conditional Instance Normalization': {'full_name': 'Conditional Instance Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1610.07629v5',\n",
       "   'title': 'A Learned Representation For Artistic Style'},\n",
       "  'Zero-padded Shortcut Connection': {'full_name': 'Zero-padded Shortcut Connection',\n",
       "   'url': 'http://arxiv.org/abs/1610.02915v4',\n",
       "   'title': 'Deep Pyramidal Residual Networks'},\n",
       "  'Good Feature Matching': {'full_name': 'Good Feature Matching',\n",
       "   'url': 'https://arxiv.org/abs/2001.00714v1',\n",
       "   'title': 'Good Feature Matching: Towards Accurate, Robust VO/VSLAM with Low Latency'},\n",
       "  'FoveaBox': {'full_name': 'FoveaBox',\n",
       "   'url': 'https://arxiv.org/abs/1904.03797v2',\n",
       "   'title': 'FoveaBox: Beyond Anchor-based Object Detector'},\n",
       "  'Slot Attention': {'full_name': 'Slot Attention',\n",
       "   'url': 'https://arxiv.org/abs/2006.15055v2',\n",
       "   'title': 'Object-Centric Learning with Slot Attention'},\n",
       "  'Associative LSTM': {'full_name': 'Associative LSTM',\n",
       "   'url': 'http://arxiv.org/abs/1602.03032v2',\n",
       "   'title': 'Associative Long Short-Term Memory'},\n",
       "  'Poincaré Embeddings': {'full_name': 'Poincaré Embeddings',\n",
       "   'url': 'http://arxiv.org/abs/1705.08039v2',\n",
       "   'title': 'Poincaré Embeddings for Learning Hierarchical Representations'},\n",
       "  'VoiceFilter-Lite': {'full_name': 'VoiceFilter-Lite',\n",
       "   'url': 'https://arxiv.org/abs/2009.04323v1',\n",
       "   'title': 'VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition'},\n",
       "  'MLFPN': {'full_name': 'MLFPN',\n",
       "   'url': 'http://arxiv.org/abs/1811.04533v3',\n",
       "   'title': 'M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network'},\n",
       "  'LiteSeg': {'full_name': 'LiteSeg',\n",
       "   'url': 'https://arxiv.org/abs/1912.06683v1',\n",
       "   'title': 'LiteSeg: A Novel Lightweight ConvNet for Semantic Segmentation'},\n",
       "  'Grouped Convolution': {'full_name': 'Grouped Convolution',\n",
       "   'url': 'http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks',\n",
       "   'title': 'ImageNet Classification with Deep Convolutional Neural Networks'},\n",
       "  'MagFace': {'full_name': 'MagFace',\n",
       "   'url': 'https://arxiv.org/abs/2103.06627v4',\n",
       "   'title': 'MagFace: A Universal Representation for Face Recognition and Quality Assessment'},\n",
       "  'Laplacian PE': {'full_name': 'Laplacian Positional Encodings',\n",
       "   'url': 'https://arxiv.org/abs/2003.00982v4',\n",
       "   'title': 'Benchmarking Graph Neural Networks'},\n",
       "  'LGCL': {'full_name': 'Learnable graph convolutional layer',\n",
       "   'url': 'http://arxiv.org/abs/1808.03965v1',\n",
       "   'title': 'Large-Scale Learnable Graph Convolutional Networks'},\n",
       "  'Sample Redistribution': {'full_name': 'Sample Redistribution',\n",
       "   'url': 'https://arxiv.org/abs/2105.04714v1',\n",
       "   'title': 'Sample and Computation Redistribution for Efficient Face Detection'},\n",
       "  'PNAS': {'full_name': 'Progressive Neural Architecture Search',\n",
       "   'url': 'http://arxiv.org/abs/1712.00559v3',\n",
       "   'title': 'Progressive Neural Architecture Search'},\n",
       "  'BiGAN': {'full_name': 'Bidirectional GAN',\n",
       "   'url': 'http://arxiv.org/abs/1605.09782v7',\n",
       "   'title': 'Adversarial Feature Learning'},\n",
       "  'PGC-DGCNN': {'full_name': 'PGC-DGCNN',\n",
       "   'url': 'http://arxiv.org/abs/1811.10435v1',\n",
       "   'title': 'On Filter Size in Graph Convolutional Networks'},\n",
       "  '(2+1)D Convolution': {'full_name': '(2+1)D Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1711.11248v3',\n",
       "   'title': 'A Closer Look at Spatiotemporal Convolutions for Action Recognition'},\n",
       "  'DTW': {'full_name': 'Dynamic Time Warping', 'url': None, 'title': None},\n",
       "  'SC-GPT': {'full_name': 'SC-GPT',\n",
       "   'url': 'https://arxiv.org/abs/2002.12328v1',\n",
       "   'title': 'Few-shot Natural Language Generation for Task-Oriented Dialog'},\n",
       "  'TridentNet Block': {'full_name': 'TridentNet Block',\n",
       "   'url': 'https://arxiv.org/abs/1901.01892v2',\n",
       "   'title': 'Scale-Aware Trident Networks for Object Detection'},\n",
       "  'KNN and IOU based verification': {'full_name': 'KNN and IOU based verification',\n",
       "   'url': 'https://ieeexplore.ieee.org/abstract/document/8822896',\n",
       "   'title': 'Machine learning approach of automatic identification and counting of blood cells'},\n",
       "  'MiVOS': {'full_name': 'Modular Interactive VOS',\n",
       "   'url': 'https://arxiv.org/abs/2103.07941v3',\n",
       "   'title': 'Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion'},\n",
       "  'Hardtanh Activation': {'full_name': 'Hardtanh Activation',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Global-Local Attention': {'full_name': 'Global-Local Attention',\n",
       "   'url': 'https://arxiv.org/abs/2004.08483v5',\n",
       "   'title': 'ETC: Encoding Long and Structured Inputs in Transformers'},\n",
       "  'WaveGAN': {'full_name': 'WaveGAN',\n",
       "   'url': 'http://arxiv.org/abs/1802.04208v3',\n",
       "   'title': 'Adversarial Audio Synthesis'},\n",
       "  '3DSSD': {'full_name': '3DSSD',\n",
       "   'url': 'https://arxiv.org/abs/2002.10187v1',\n",
       "   'title': '3DSSD: Point-based 3D Single Stage Object Detector'},\n",
       "  'InfoGAN': {'full_name': 'InfoGAN',\n",
       "   'url': 'http://arxiv.org/abs/1606.03657v1',\n",
       "   'title': 'InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets'},\n",
       "  'Deactivable Skip Connection': {'full_name': 'Deactivable Skip Connection',\n",
       "   'url': 'https://arxiv.org/abs/2003.09691v2',\n",
       "   'title': 'Cross-modal Deep Face Normals with Deactivable Skip Connections'},\n",
       "  'GNNCL': {'full_name': 'Graph Neural Networks with Continual Learning',\n",
       "   'url': 'https://arxiv.org/abs/2007.03316v2',\n",
       "   'title': 'Graph Neural Networks with Continual Learning for Fake News Detection from Social Media'},\n",
       "  'EvoNorms': {'full_name': 'EvoNorms',\n",
       "   'url': 'https://arxiv.org/abs/2004.02967v5',\n",
       "   'title': 'Evolving Normalization-Activation Layers'},\n",
       "  'DIME': {'full_name': 'Distance to Modelled Embedding',\n",
       "   'url': 'https://arxiv.org/abs/2108.10673v1',\n",
       "   'title': 'Out-of-Distribution Example Detection in Deep Neural Networks using Distance to Modelled Embedding'},\n",
       "  'LapEigen': {'full_name': 'Laplacian EigenMap',\n",
       "   'url': 'https://ieeexplore.ieee.org/abstract/document/6789755',\n",
       "   'title': 'Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering'},\n",
       "  'Shake-Shake Regularization': {'full_name': 'Shake-Shake Regularization',\n",
       "   'url': 'http://arxiv.org/abs/1705.07485v2',\n",
       "   'title': 'Shake-Shake regularization'},\n",
       "  'ABCNet': {'full_name': 'Adaptive Bezier-Curve Network',\n",
       "   'url': 'https://arxiv.org/abs/2002.10200v2',\n",
       "   'title': 'ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network'},\n",
       "  'Mish': {'full_name': 'Mish',\n",
       "   'url': 'https://arxiv.org/abs/1908.08681v3',\n",
       "   'title': 'Mish: A Self Regularized Non-Monotonic Activation Function'},\n",
       "  'TimeSformer': {'full_name': 'TimeSformer',\n",
       "   'url': 'https://arxiv.org/abs/2102.05095v4',\n",
       "   'title': 'Is Space-Time Attention All You Need for Video Understanding?'},\n",
       "  'Instance Normalization': {'full_name': 'Instance Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1607.08022v3',\n",
       "   'title': 'Instance Normalization: The Missing Ingredient for Fast Stylization'},\n",
       "  'FLICA': {'full_name': 'A Framework for Leader Identification in Coordinated Activity',\n",
       "   'url': 'https://arxiv.org/abs/1603.01570v2',\n",
       "   'title': 'Coordination Event Detection and Initiator Identification in Time Series Data'},\n",
       "  'Adaptive NMS': {'full_name': 'Adaptive NMS',\n",
       "   'url': 'http://arxiv.org/abs/1904.03629v1',\n",
       "   'title': 'Adaptive NMS: Refining Pedestrian Detection in a Crowd'},\n",
       "  'ENet Bottleneck': {'full_name': 'ENet Bottleneck',\n",
       "   'url': 'http://arxiv.org/abs/1606.02147v1',\n",
       "   'title': 'ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation'},\n",
       "  'AdaSqrt': {'full_name': 'AdaSqrt',\n",
       "   'url': 'https://arxiv.org/abs/1912.09926v1',\n",
       "   'title': 'Second-order Information in First-order Optimization Methods'},\n",
       "  'Spatially Separable Self-Attention': {'full_name': 'Spatially Separable Self-Attention',\n",
       "   'url': 'https://arxiv.org/abs/2104.13840v4',\n",
       "   'title': 'Twins: Revisiting the Design of Spatial Attention in Vision Transformers'},\n",
       "  'LocalViT': {'full_name': 'LocalViT',\n",
       "   'url': 'https://arxiv.org/abs/2104.05707v1',\n",
       "   'title': 'LocalViT: Bringing Locality to Vision Transformers'},\n",
       "  'FLAVR': {'full_name': 'FLAVR',\n",
       "   'url': 'https://arxiv.org/abs/2012.08512v3',\n",
       "   'title': 'FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation'},\n",
       "  'Leaky ReLU': {'full_name': 'Leaky ReLU', 'url': None, 'title': None},\n",
       "  'BinaryBERT': {'full_name': 'BinaryBERT',\n",
       "   'url': 'https://arxiv.org/abs/2012.15701v2',\n",
       "   'title': 'BinaryBERT: Pushing the Limit of BERT Quantization'},\n",
       "  'PCA': {'full_name': 'Principal Components Analysis',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'ArcFace': {'full_name': 'Additive Angular Margin Loss',\n",
       "   'url': 'http://arxiv.org/abs/1801.07698v3',\n",
       "   'title': 'ArcFace: Additive Angular Margin Loss for Deep Face Recognition'},\n",
       "  'Strided EESP': {'full_name': 'Strided EESP',\n",
       "   'url': 'http://arxiv.org/abs/1811.11431v3',\n",
       "   'title': 'ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network'},\n",
       "  'VERSE': {'full_name': 'VERtex Similarity Embeddings',\n",
       "   'url': 'http://arxiv.org/abs/1803.04742v1',\n",
       "   'title': 'VERSE: Versatile Graph Embeddings from Similarity Measures'},\n",
       "  'Primer': {'full_name': 'Primer',\n",
       "   'url': 'https://arxiv.org/abs/2109.08668v2',\n",
       "   'title': 'Primer: Searching for Efficient Transformers for Language Modeling'},\n",
       "  'SpecGAN': {'full_name': 'SpecGAN',\n",
       "   'url': 'http://arxiv.org/abs/1802.04208v3',\n",
       "   'title': 'Adversarial Audio Synthesis'},\n",
       "  'UNIMO': {'full_name': 'UNIMO',\n",
       "   'url': 'https://arxiv.org/abs/2012.15409v4',\n",
       "   'title': 'UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning'},\n",
       "  'VQ-VAE-2': {'full_name': 'VQ-VAE-2',\n",
       "   'url': 'https://arxiv.org/abs/1906.00446v1',\n",
       "   'title': 'Generating Diverse High-Fidelity Images with VQ-VAE-2'},\n",
       "  'Anycost GAN': {'full_name': 'Anycost GAN',\n",
       "   'url': 'https://arxiv.org/abs/2103.03243v1',\n",
       "   'title': 'Anycost GANs for Interactive Image Synthesis and Editing'},\n",
       "  'True Online TD Lambda': {'full_name': 'True Online TD Lambda',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Performer': {'full_name': 'Performer',\n",
       "   'url': 'https://arxiv.org/abs/2009.14794v3',\n",
       "   'title': 'Rethinking Attention with Performers'},\n",
       "  'Res2Net': {'full_name': 'Res2Net',\n",
       "   'url': 'https://arxiv.org/abs/1904.01169v3',\n",
       "   'title': 'Res2Net: A New Multi-scale Backbone Architecture'},\n",
       "  'Dynamic Convolution': {'full_name': 'Dynamic Convolution',\n",
       "   'url': 'https://arxiv.org/abs/1912.03458v2',\n",
       "   'title': 'Dynamic Convolution: Attention over Convolution Kernels'},\n",
       "  'Mixture of Softmaxes': {'full_name': 'Mixture of Softmaxes',\n",
       "   'url': 'http://arxiv.org/abs/1711.03953v4',\n",
       "   'title': 'Breaking the Softmax Bottleneck: A High-Rank RNN Language Model'},\n",
       "  'Gradient Clipping': {'full_name': 'Gradient Clipping',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'CP conv': {'full_name': 'Center-pivot convolution',\n",
       "   'url': 'https://arxiv.org/abs/2104.01538v3',\n",
       "   'title': 'Hypercorrelation Squeeze for Few-Shot Segmentation'},\n",
       "  'CaiT': {'full_name': 'Class-Attention in Image Transformers',\n",
       "   'url': 'https://arxiv.org/abs/2103.17239v2',\n",
       "   'title': 'Going deeper with Image Transformers'},\n",
       "  'GBlock': {'full_name': 'GBlock',\n",
       "   'url': 'https://arxiv.org/abs/1909.11646v2',\n",
       "   'title': 'High Fidelity Speech Synthesis with Adversarial Networks'},\n",
       "  'EDLPS': {'full_name': 'Encoder-Decoder model with local and pairwise loss along with shared encoder and discriminator network (EDLPS)',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'DenseNAS-C': {'full_name': 'DenseNAS-C',\n",
       "   'url': 'https://arxiv.org/abs/1906.09607v3',\n",
       "   'title': 'Densely Connected Search Space for More Flexible Neural Architecture Search'},\n",
       "  'Hermite Activation': {'full_name': 'Hermite Polynomial Activation',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'ZFNet': {'full_name': 'ZFNet',\n",
       "   'url': 'http://arxiv.org/abs/1311.2901v3',\n",
       "   'title': 'Visualizing and Understanding Convolutional Networks'},\n",
       "  'CPN': {'full_name': 'Contour Proposal Network',\n",
       "   'url': 'https://arxiv.org/abs/2104.03393v1',\n",
       "   'title': 'Contour Proposal Networks for Biomedical Instance Segmentation'},\n",
       "  'GRoIE': {'full_name': 'Generic RoI Extractor',\n",
       "   'url': 'https://arxiv.org/abs/2004.13665v2',\n",
       "   'title': 'A novel Region of Interest Extraction Layer for Instance Segmentation'},\n",
       "  'imGHUM': {'full_name': 'imGHUM',\n",
       "   'url': 'https://arxiv.org/abs/2108.10842v1',\n",
       "   'title': 'imGHUM: Implicit Generative Models of 3D Human Shape and Articulated Pose'},\n",
       "  'MDETR': {'full_name': 'MDETR',\n",
       "   'url': 'https://arxiv.org/abs/2104.12763v2',\n",
       "   'title': 'MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding'},\n",
       "  'AMP': {'full_name': 'Adversarial Model Perturbation',\n",
       "   'url': 'https://arxiv.org/abs/2010.04925v4',\n",
       "   'title': 'Regularizing Neural Networks via Adversarial Model Perturbation'},\n",
       "  'Recurrent Dropout': {'full_name': 'Recurrent Dropout',\n",
       "   'url': 'http://arxiv.org/abs/1603.05118v2',\n",
       "   'title': 'Recurrent Dropout without Memory Loss'},\n",
       "  'Softmax': {'full_name': 'Softmax', 'url': None, 'title': None},\n",
       "  'DeepWalk': {'full_name': 'DeepWalk',\n",
       "   'url': 'http://arxiv.org/abs/1403.6652v2',\n",
       "   'title': 'DeepWalk: Online Learning of Social Representations'},\n",
       "  'Flow Alignment Module': {'full_name': 'Flow Alignment Module',\n",
       "   'url': 'https://arxiv.org/abs/2002.10120v3',\n",
       "   'title': 'Semantic Flow for Fast and Accurate Scene Parsing'},\n",
       "  'BS-Net': {'full_name': 'BS-Net',\n",
       "   'url': 'https://arxiv.org/abs/2006.04603v3',\n",
       "   'title': 'BS-Net: learning COVID-19 pneumonia severity on a large Chest X-Ray dataset'},\n",
       "  'Fast R-CNN': {'full_name': 'Fast R-CNN',\n",
       "   'url': 'http://arxiv.org/abs/1504.08083v2',\n",
       "   'title': 'Fast R-CNN'},\n",
       "  'Ghost Bottleneck': {'full_name': 'Ghost Bottleneck',\n",
       "   'url': 'https://arxiv.org/abs/1911.11907v2',\n",
       "   'title': 'GhostNet: More Features from Cheap Operations'},\n",
       "  'Inception-ResNet-v2': {'full_name': 'Inception-ResNet-v2',\n",
       "   'url': 'http://arxiv.org/abs/1602.07261v2',\n",
       "   'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
       "  'Non-Local Block': {'full_name': 'Non-Local Block',\n",
       "   'url': 'http://arxiv.org/abs/1711.07971v3',\n",
       "   'title': 'Non-local Neural Networks'},\n",
       "  'Inception-B': {'full_name': 'Inception-B',\n",
       "   'url': 'http://arxiv.org/abs/1602.07261v2',\n",
       "   'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
       "  'XGrad-CAM': {'full_name': 'XGrad-CAM',\n",
       "   'url': 'https://arxiv.org/abs/2008.02312v4',\n",
       "   'title': 'Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of CNNs'},\n",
       "  'DistDGL': {'full_name': 'DistDGL',\n",
       "   'url': 'https://arxiv.org/abs/2010.05337v3',\n",
       "   'title': 'DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs'},\n",
       "  'Highway Network': {'full_name': 'Highway Network',\n",
       "   'url': 'http://arxiv.org/abs/1505.00387v2',\n",
       "   'title': 'Highway Networks'},\n",
       "  'CORAD': {'full_name': 'CORAD: Correlation-Aware Compression of Massive Time Series using Sparse Dictionary Coding',\n",
       "   'url': 'https://ieeexplore.ieee.org/abstract/document/9005580',\n",
       "   'title': 'CORAD: Correlation-Aware Compression of Massive Time Series using Sparse Dictionary Coding'},\n",
       "  'Deformable Attention Module': {'full_name': 'Deformable Attention Module',\n",
       "   'url': 'https://arxiv.org/abs/2010.04159v4',\n",
       "   'title': 'Deformable DETR: Deformable Transformers for End-to-End Object Detection'},\n",
       "  '1-bit LAMB': {'full_name': '1-bit LAMB',\n",
       "   'url': 'https://arxiv.org/abs/2104.06069v2',\n",
       "   'title': \"1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training with LAMB's Convergence Speed\"},\n",
       "  'TAPAS': {'full_name': 'TAPAS',\n",
       "   'url': 'https://arxiv.org/abs/2004.02349v2',\n",
       "   'title': 'TAPAS: Weakly Supervised Table Parsing via Pre-training'},\n",
       "  'Depthwise Convolution': {'full_name': 'Depthwise Convolution',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'PANet': {'full_name': 'PANet',\n",
       "   'url': 'http://arxiv.org/abs/1803.01534v4',\n",
       "   'title': 'Path Aggregation Network for Instance Segmentation'},\n",
       "  'PAFPN': {'full_name': 'PAFPN',\n",
       "   'url': 'http://arxiv.org/abs/1803.01534v4',\n",
       "   'title': 'Path Aggregation Network for Instance Segmentation'},\n",
       "  'GFSA': {'full_name': 'Graph Finite-State Automaton',\n",
       "   'url': 'https://arxiv.org/abs/2007.04929v2',\n",
       "   'title': 'Learning Graph Structure With A Finite-State Automaton Layer'},\n",
       "  'RIFE': {'full_name': 'RIFE',\n",
       "   'url': 'https://arxiv.org/abs/2011.06294v11',\n",
       "   'title': 'RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation'},\n",
       "  'Movement Pruning': {'full_name': 'Movement Pruning',\n",
       "   'url': 'https://arxiv.org/abs/2005.07683v2',\n",
       "   'title': 'Movement Pruning: Adaptive Sparsity by Fine-Tuning'},\n",
       "  'Random Resized Crop': {'full_name': 'Random Resized Crop',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'HBMP': {'full_name': 'Hierarchical BiLSTM Max Pooling',\n",
       "   'url': 'https://arxiv.org/abs/1808.08762v2',\n",
       "   'title': 'Sentence Embeddings in NLI with Iterative Refinement Encoders'},\n",
       "  'SIFA': {'full_name': 'Synergistic Image and Feature Alignment',\n",
       "   'url': 'https://arxiv.org/abs/2002.02255v1',\n",
       "   'title': 'Unsupervised Bidirectional Cross-Modality Adaptation via Deeply Synergistic Image and Feature Alignment for Medical Image Segmentation'},\n",
       "  'TransE': {'full_name': 'TransE',\n",
       "   'url': 'http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data',\n",
       "   'title': 'Translating Embeddings for Modeling Multi-relational Data'},\n",
       "  'ARiA': {'full_name': \"Adaptive Richard's Curve Weighted Activation\",\n",
       "   'url': 'http://arxiv.org/abs/1805.08878v1',\n",
       "   'title': \"ARiA: Utilizing Richard's Curve for Controlling the Non-monotonicity of the Activation Function in Deep Neural Nets\"},\n",
       "  'Detr': {'full_name': 'Detection Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2005.12872v3',\n",
       "   'title': 'End-to-End Object Detection with Transformers'},\n",
       "  'RGCN': {'full_name': 'Relational Graph Convolution Network',\n",
       "   'url': 'http://arxiv.org/abs/1703.06103v4',\n",
       "   'title': 'Modeling Relational Data with Graph Convolutional Networks'},\n",
       "  'HardELiSH': {'full_name': 'HardELiSH',\n",
       "   'url': 'http://arxiv.org/abs/1808.00783v1',\n",
       "   'title': 'The Quest for the Golden Activation Function'},\n",
       "  'CGRU': {'full_name': 'Convolutional GRU',\n",
       "   'url': 'http://arxiv.org/abs/1511.06432v4',\n",
       "   'title': 'Delving Deeper into Convolutional Networks for Learning Video Representations'},\n",
       "  'Cosine Annealing': {'full_name': 'Cosine Annealing',\n",
       "   'url': 'http://arxiv.org/abs/1608.03983v5',\n",
       "   'title': 'SGDR: Stochastic Gradient Descent with Warm Restarts'},\n",
       "  'SAINT': {'full_name': 'SAINT',\n",
       "   'url': 'https://arxiv.org/abs/2106.01342v1',\n",
       "   'title': 'SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training'},\n",
       "  'RoBERTa': {'full_name': 'RoBERTa',\n",
       "   'url': 'https://arxiv.org/abs/1907.11692v1',\n",
       "   'title': 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'},\n",
       "  'PReLU': {'full_name': 'Parameterized ReLU',\n",
       "   'url': 'http://arxiv.org/abs/1502.01852v1',\n",
       "   'title': 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification'},\n",
       "  'Local Patch Interaction': {'full_name': 'Local Patch Interaction',\n",
       "   'url': 'https://arxiv.org/abs/2106.09681v2',\n",
       "   'title': 'XCiT: Cross-Covariance Image Transformers'},\n",
       "  'Social-STGCNN': {'full_name': 'Social-STGCNN',\n",
       "   'url': 'https://arxiv.org/abs/2002.11927v3',\n",
       "   'title': 'Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction'},\n",
       "  'Convolution': {'full_name': 'Convolution', 'url': None, 'title': None},\n",
       "  'IAN': {'full_name': 'Introspective Adversarial Network',\n",
       "   'url': 'http://arxiv.org/abs/1609.07093v3',\n",
       "   'title': 'Neural Photo Editing with Introspective Adversarial Networks'},\n",
       "  'G-GLN': {'full_name': 'Gaussian Gated Linear Network',\n",
       "   'url': 'https://arxiv.org/abs/2006.05964v2',\n",
       "   'title': 'Gaussian Gated Linear Networks'},\n",
       "  'CCAC': {'full_name': 'Confidence Calibration with an Auxiliary Class)',\n",
       "   'url': 'https://arxiv.org/abs/2006.08914v1',\n",
       "   'title': 'Calibrating Deep Neural Network Classifiers on Out-of-Distribution Datasets'},\n",
       "  'Twins-PCPVT': {'full_name': 'Twins-PCPVT',\n",
       "   'url': 'https://arxiv.org/abs/2104.13840v4',\n",
       "   'title': 'Twins: Revisiting the Design of Spatial Attention in Vision Transformers'},\n",
       "  'Pointer Sentinel-LSTM': {'full_name': 'Pointer Sentinel-LSTM',\n",
       "   'url': 'http://arxiv.org/abs/1609.07843v1',\n",
       "   'title': 'Pointer Sentinel Mixture Models'},\n",
       "  'TabTransformer': {'full_name': 'TabTransformer',\n",
       "   'url': 'https://arxiv.org/abs/2012.06678v1',\n",
       "   'title': 'TabTransformer: Tabular Data Modeling Using Contextual Embeddings'},\n",
       "  'DASPP': {'full_name': 'Deeper Atrous Spatial Pyramid Pooling',\n",
       "   'url': 'https://arxiv.org/abs/1912.06683v1',\n",
       "   'title': 'LiteSeg: A Novel Lightweight ConvNet for Semantic Segmentation'},\n",
       "  'MNMF': {'full_name': 'Modularity preserving NMF',\n",
       "   'url': 'https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14589',\n",
       "   'title': 'Font Size: Community Preserving Network Embedding'},\n",
       "  'Location Sensitive Attention': {'full_name': 'Location Sensitive Attention',\n",
       "   'url': 'http://arxiv.org/abs/1506.07503v1',\n",
       "   'title': 'Attention-Based Models for Speech Recognition'},\n",
       "  'WaveVAE': {'full_name': 'WaveVAE',\n",
       "   'url': 'https://arxiv.org/abs/1905.08459v3',\n",
       "   'title': 'Non-Autoregressive Neural Text-to-Speech'},\n",
       "  'IoU-Net': {'full_name': 'IoU-Net',\n",
       "   'url': 'http://arxiv.org/abs/1807.11590v1',\n",
       "   'title': 'Acquisition of Localization Confidence for Accurate Object Detection'},\n",
       "  'LIME': {'full_name': 'Local Interpretable Model-Agnostic Explanations',\n",
       "   'url': 'http://arxiv.org/abs/1602.04938v3',\n",
       "   'title': '\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier'},\n",
       "  'Step Decay': {'full_name': 'Step Decay', 'url': None, 'title': None},\n",
       "  'VQ-VAE': {'full_name': 'VQ-VAE',\n",
       "   'url': 'http://arxiv.org/abs/1711.00937v2',\n",
       "   'title': 'Neural Discrete Representation Learning'},\n",
       "  'InPlace-ABN': {'full_name': 'In-Place Activated Batch Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1712.02616v3',\n",
       "   'title': 'In-Place Activated BatchNorm for Memory-Optimized Training of DNNs'},\n",
       "  'Aggregated Learning': {'full_name': 'Aggregated Learning',\n",
       "   'url': 'https://arxiv.org/abs/2001.03955v3',\n",
       "   'title': 'Aggregated Learning: A Vector-Quantization Approach to Learning Neural Network Classifiers'},\n",
       "  'Compressive Transformer': {'full_name': 'Compressive Transformer',\n",
       "   'url': 'https://arxiv.org/abs/1911.05507v1',\n",
       "   'title': 'Compressive Transformers for Long-Range Sequence Modelling'},\n",
       "  'SmeLU': {'full_name': 'Smooth ReLU', 'url': None, 'title': None},\n",
       "  'RPM-Net': {'full_name': 'RPM-Net',\n",
       "   'url': 'https://arxiv.org/abs/2003.13479v1',\n",
       "   'title': 'RPM-Net: Robust Point Matching using Learned Features'},\n",
       "  'Multi-band MelGAN': {'full_name': 'Multi-band MelGAN',\n",
       "   'url': 'https://arxiv.org/abs/2005.05106v1',\n",
       "   'title': 'Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech'},\n",
       "  'DAEL': {'full_name': 'Domain Adaptive Ensemble Learning',\n",
       "   'url': 'https://arxiv.org/abs/2003.07325v3',\n",
       "   'title': 'Domain Adaptive Ensemble Learning'},\n",
       "  'SCNet': {'full_name': 'SCNet',\n",
       "   'url': 'https://arxiv.org/abs/2012.10150v1',\n",
       "   'title': 'SCNet: Training Inference Sample Consistency for Instance Segmentation'},\n",
       "  'Pointer Network': {'full_name': 'Pointer Network',\n",
       "   'url': 'http://arxiv.org/abs/1506.03134v2',\n",
       "   'title': 'Pointer Networks'},\n",
       "  'gMLP': {'full_name': 'gMLP',\n",
       "   'url': 'https://arxiv.org/abs/2105.08050v2',\n",
       "   'title': 'Pay Attention to MLPs'},\n",
       "  'STA-LSTM': {'full_name': 'Spatio-Temporal Attention LSTM',\n",
       "   'url': 'http://arxiv.org/abs/1611.06067v1',\n",
       "   'title': 'An End-to-End Spatio-Temporal Attention Model for Human Action Recognition from Skeleton Data'},\n",
       "  'ALiBi': {'full_name': 'Attention with Linear Biases',\n",
       "   'url': 'https://arxiv.org/abs/2108.12409v2',\n",
       "   'title': 'Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation'},\n",
       "  'Temporally Consistent Spatial Augmentation': {'full_name': 'Temporally Consistent Spatial Augmentation',\n",
       "   'url': 'https://arxiv.org/abs/2008.03800v4',\n",
       "   'title': 'Spatiotemporal Contrastive Video Representation Learning'},\n",
       "  'Blink Communication': {'full_name': 'Blink Communication',\n",
       "   'url': 'https://arxiv.org/abs/1910.04940v1',\n",
       "   'title': 'Blink: Fast and Generic Collectives for Distributed ML'},\n",
       "  'LPM': {'full_name': 'Local Prior Matching',\n",
       "   'url': 'https://arxiv.org/abs/2002.10336v1',\n",
       "   'title': 'Semi-Supervised Speech Recognition via Local Prior Matching'},\n",
       "  'Ensemble Clustering': {'full_name': 'Ensemble Clustering',\n",
       "   'url': 'https://ieeexplore.ieee.org/document/9338349',\n",
       "   'title': 'Ensemble Learning for Spectral Clustering'},\n",
       "  'XLNet': {'full_name': 'XLNet',\n",
       "   'url': 'https://arxiv.org/abs/1906.08237v2',\n",
       "   'title': 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'},\n",
       "  'ComplEx-N3': {'full_name': 'ComplEx with N3 Regularizer',\n",
       "   'url': 'http://arxiv.org/abs/1806.07297v1',\n",
       "   'title': 'Canonical Tensor Decomposition for Knowledge Base Completion'},\n",
       "  'Non-Local Operation': {'full_name': 'Non-Local Operation',\n",
       "   'url': 'http://arxiv.org/abs/1711.07971v3',\n",
       "   'title': 'Non-local Neural Networks'},\n",
       "  'TransferQA': {'full_name': 'TransferQA',\n",
       "   'url': 'https://arxiv.org/abs/2109.04655v1',\n",
       "   'title': 'Zero-Shot Dialogue State Tracking via Cross-Task Transfer'},\n",
       "  'GAN Feature Matching': {'full_name': 'GAN Feature Matching',\n",
       "   'url': 'http://arxiv.org/abs/1606.03498v1',\n",
       "   'title': 'Improved Techniques for Training GANs'},\n",
       "  'QHAdam': {'full_name': 'QHAdam',\n",
       "   'url': 'http://arxiv.org/abs/1810.06801v4',\n",
       "   'title': 'Quasi-hyperbolic momentum and Adam for deep learning'},\n",
       "  'BiLSTM': {'full_name': 'Bidirectional LSTM', 'url': None, 'title': None},\n",
       "  'Random Gaussian Blur': {'full_name': 'Random Gaussian Blur',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Graph Self-Attention': {'full_name': 'Graph Self-Attention',\n",
       "   'url': 'https://arxiv.org/abs/1911.04070v1',\n",
       "   'title': 'BP-Transformer: Modelling Long-Range Context via Binary Partitioning'},\n",
       "  'Double DQN': {'full_name': 'Double DQN',\n",
       "   'url': 'http://arxiv.org/abs/1509.06461v3',\n",
       "   'title': 'Deep Reinforcement Learning with Double Q-learning'},\n",
       "  'CSPDarknet53': {'full_name': 'CSPDarknet53',\n",
       "   'url': 'https://arxiv.org/abs/2004.10934v1',\n",
       "   'title': 'YOLOv4: Optimal Speed and Accuracy of Object Detection'},\n",
       "  'PolarNet': {'full_name': 'PolarNet',\n",
       "   'url': 'https://arxiv.org/abs/2003.14032v2',\n",
       "   'title': 'PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation'},\n",
       "  'Mixture Normalization': {'full_name': 'Mixture Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1806.02892v2',\n",
       "   'title': 'Training Faster by Separating Modes of Variation in Batch-normalized Models'},\n",
       "  'MCKERNEL': {'full_name': 'MCKERNEL',\n",
       "   'url': 'http://arxiv.org/abs/1702.08159v9',\n",
       "   'title': 'McKernel: A Library for Approximate Kernel Expansions in Log-linear Time'},\n",
       "  'ESPNet': {'full_name': 'ESPNet',\n",
       "   'url': 'http://arxiv.org/abs/1803.06815v3',\n",
       "   'title': 'ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation'},\n",
       "  'BoundaryNet': {'full_name': 'BoundaryNet',\n",
       "   'url': 'https://arxiv.org/abs/2108.09433v1',\n",
       "   'title': 'BoundaryNet: An Attentive Deep Network with Fast Marching Distance Maps for Semi-automatic Layout Annotation'},\n",
       "  'Visual Parsing': {'full_name': 'Visual Parsing',\n",
       "   'url': 'https://openreview.net/forum?id=e0nZIFEpmYh',\n",
       "   'title': 'Probing Inter-modality: Visual Parsing with Self-Attention for Vision-and-Language Pre-training'},\n",
       "  'Cycle-CenterNet': {'full_name': 'Cycle-CenterNet',\n",
       "   'url': 'https://arxiv.org/abs/2109.02199v1',\n",
       "   'title': 'Parsing Table Structures in the Wild'},\n",
       "  'DMAGE': {'full_name': 'Unsupervised Deep Manifold Attributed Graph Embedding',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'MPNN': {'full_name': 'Message Passing Neural Network',\n",
       "   'url': 'http://arxiv.org/abs/1704.01212v2',\n",
       "   'title': 'Neural Message Passing for Quantum Chemistry'},\n",
       "  'VL-BERT': {'full_name': 'Visual-Linguistic BERT',\n",
       "   'url': 'https://arxiv.org/abs/1908.08530v4',\n",
       "   'title': 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'},\n",
       "  'PixelRNN': {'full_name': 'Pixel Recurrent Neural Network',\n",
       "   'url': 'http://arxiv.org/abs/1601.06759v3',\n",
       "   'title': 'Pixel Recurrent Neural Networks'},\n",
       "  'PPO': {'full_name': 'Proximal Policy Optimization',\n",
       "   'url': 'http://arxiv.org/abs/1707.06347v2',\n",
       "   'title': 'Proximal Policy Optimization Algorithms'},\n",
       "  'CT3D': {'full_name': 'CT3D',\n",
       "   'url': 'https://arxiv.org/abs/2108.10723v2',\n",
       "   'title': 'Improving 3D Object Detection with Channel-wise Transformer'},\n",
       "  'FRILL': {'full_name': 'FRILL',\n",
       "   'url': 'https://arxiv.org/abs/2011.04609v5',\n",
       "   'title': 'FRILL: A Non-Semantic Speech Embedding for Mobile Devices'},\n",
       "  'SVM': {'full_name': 'Support Vector Machine', 'url': None, 'title': None},\n",
       "  'DU-GAN': {'full_name': 'DU-GAN',\n",
       "   'url': 'https://arxiv.org/abs/2108.10772v2',\n",
       "   'title': 'DU-GAN: Generative Adversarial Networks with Dual-Domain U-Net Based Discriminators for Low-Dose CT Denoising'},\n",
       "  'Meta Pseudo Labels': {'full_name': 'Meta Pseudo Labels',\n",
       "   'url': 'https://arxiv.org/abs/2003.10580v4',\n",
       "   'title': 'Meta Pseudo Labels'},\n",
       "  'HTC': {'full_name': 'Hybrid Task Cascade',\n",
       "   'url': 'http://arxiv.org/abs/1901.07518v2',\n",
       "   'title': 'Hybrid Task Cascade for Instance Segmentation'},\n",
       "  'Inception-v3': {'full_name': 'Inception-v3',\n",
       "   'url': 'http://arxiv.org/abs/1512.00567v3',\n",
       "   'title': 'Rethinking the Inception Architecture for Computer Vision'},\n",
       "  'Darknet-19': {'full_name': 'Darknet-19',\n",
       "   'url': 'http://arxiv.org/abs/1612.08242v1',\n",
       "   'title': 'YOLO9000: Better, Faster, Stronger'},\n",
       "  'FLAVA': {'full_name': 'FLAVA',\n",
       "   'url': 'https://arxiv.org/abs/2112.04482v3',\n",
       "   'title': 'FLAVA: A Foundational Language And Vision Alignment Model'},\n",
       "  'KP': {'full_name': 'Kollen-Pollack Learning',\n",
       "   'url': 'https://arxiv.org/abs/1904.05391v5',\n",
       "   'title': 'Deep Learning without Weight Transport'},\n",
       "  'Normalizing Flows': {'full_name': 'Normalizing Flows',\n",
       "   'url': 'http://arxiv.org/abs/1505.05770v6',\n",
       "   'title': 'Variational Inference with Normalizing Flows'},\n",
       "  'DDPG': {'full_name': 'Deep Deterministic Policy Gradient',\n",
       "   'url': 'https://arxiv.org/abs/1509.02971v6',\n",
       "   'title': 'Continuous control with deep reinforcement learning'},\n",
       "  'CBoW Word2Vec': {'full_name': 'Continuous Bag-of-Words Word2Vec',\n",
       "   'url': 'http://arxiv.org/abs/1301.3781v3',\n",
       "   'title': 'Efficient Estimation of Word Representations in Vector Space'},\n",
       "  'Stochastic Depth': {'full_name': 'Stochastic Depth',\n",
       "   'url': 'http://arxiv.org/abs/1603.09382v3',\n",
       "   'title': 'Deep Networks with Stochastic Depth'},\n",
       "  'mBARTHez': {'full_name': 'mBARTHez',\n",
       "   'url': 'https://arxiv.org/abs/2010.12321v2',\n",
       "   'title': 'BARThez: a Skilled Pretrained French Sequence-to-Sequence Model'},\n",
       "  'One-Shot Aggregation': {'full_name': 'One-Shot Aggregation',\n",
       "   'url': 'http://arxiv.org/abs/1904.09730v1',\n",
       "   'title': 'An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection'},\n",
       "  'CrossViT': {'full_name': 'CrossViT',\n",
       "   'url': 'https://arxiv.org/abs/2103.14899v2',\n",
       "   'title': 'CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification'},\n",
       "  'Mixed Attention Block': {'full_name': 'Mixed Attention Block',\n",
       "   'url': 'https://arxiv.org/abs/2008.02496v3',\n",
       "   'title': 'ConvBERT: Improving BERT with Span-based Dynamic Convolution'},\n",
       "  'Deformable RoI Pooling': {'full_name': 'Deformable RoI Pooling',\n",
       "   'url': 'http://arxiv.org/abs/1703.06211v3',\n",
       "   'title': 'Deformable Convolutional Networks'},\n",
       "  'ViP-DeepLab': {'full_name': 'ViP-DeepLab',\n",
       "   'url': 'https://arxiv.org/abs/2012.05258v1',\n",
       "   'title': 'ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation'},\n",
       "  'Positional Encoding Generator': {'full_name': 'Positional Encoding Generator',\n",
       "   'url': 'https://arxiv.org/abs/2102.10882v2',\n",
       "   'title': 'Conditional Positional Encodings for Vision Transformers'},\n",
       "  'Pixel-BERT': {'full_name': 'Pixel-BERT',\n",
       "   'url': 'https://arxiv.org/abs/2004.00849v2',\n",
       "   'title': 'Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers'},\n",
       "  'Symbolic Deep Learning': {'full_name': 'Symbolic Deep Learning',\n",
       "   'url': 'https://arxiv.org/abs/2006.11287v2',\n",
       "   'title': 'Discovering Symbolic Models from Deep Learning with Inductive Biases'},\n",
       "  'TD3': {'full_name': 'Twin Delayed Deep Deterministic',\n",
       "   'url': 'http://arxiv.org/abs/1802.09477v3',\n",
       "   'title': 'Addressing Function Approximation Error in Actor-Critic Methods'},\n",
       "  'EfficientUNet++': {'full_name': 'EfficientUNet++',\n",
       "   'url': 'https://arxiv.org/abs/2106.11447v1',\n",
       "   'title': 'Encoder-Decoder Architectures for Clinically Relevant Coronary Artery Segmentation'},\n",
       "  'Shape Adaptor': {'full_name': 'Shape Adaptor',\n",
       "   'url': 'https://arxiv.org/abs/2008.00892v2',\n",
       "   'title': 'Shape Adaptor: A Learnable Resizing Module'},\n",
       "  'NVAE': {'full_name': 'Nouveau VAE',\n",
       "   'url': 'https://arxiv.org/abs/2007.03898v3',\n",
       "   'title': 'NVAE: A Deep Hierarchical Variational Autoencoder'},\n",
       "  'Adaptive Masking': {'full_name': 'Adaptive Masking',\n",
       "   'url': 'https://arxiv.org/abs/1905.07799v2',\n",
       "   'title': 'Adaptive Attention Span in Transformers'},\n",
       "  'MobileNetV1': {'full_name': 'MobileNetV1',\n",
       "   'url': 'http://arxiv.org/abs/1704.04861v1',\n",
       "   'title': 'MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications'},\n",
       "  'ProxylessNet-Mobile': {'full_name': 'ProxylessNet-Mobile',\n",
       "   'url': 'http://arxiv.org/abs/1812.00332v2',\n",
       "   'title': 'ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware'},\n",
       "  'BAGUA': {'full_name': 'BAGUA',\n",
       "   'url': 'https://arxiv.org/abs/2107.01499v4',\n",
       "   'title': 'BAGUA: Scaling up Distributed Learning with System Relaxations'},\n",
       "  'EVM': {'full_name': 'Extreme Value Machine',\n",
       "   'url': 'http://arxiv.org/abs/1506.06112v4',\n",
       "   'title': 'The Extreme Value Machine'},\n",
       "  'DeBERTa': {'full_name': 'DeBERTa',\n",
       "   'url': 'https://arxiv.org/abs/2006.03654v6',\n",
       "   'title': 'DeBERTa: Decoding-enhanced BERT with Disentangled Attention'},\n",
       "  'Cross-Scale Non-Local Attention': {'full_name': 'Cross-Scale Non-Local Attention',\n",
       "   'url': 'https://arxiv.org/abs/2006.01424v1',\n",
       "   'title': 'Image Super-Resolution with Cross-Scale Non-Local Attention and Exhaustive Self-Exemplars Mining'},\n",
       "  'AdaMax': {'full_name': 'AdaMax',\n",
       "   'url': 'http://arxiv.org/abs/1412.6980v9',\n",
       "   'title': 'Adam: A Method for Stochastic Optimization'},\n",
       "  'GraphSAGE': {'full_name': 'GraphSAGE',\n",
       "   'url': 'http://arxiv.org/abs/1706.02216v4',\n",
       "   'title': 'Inductive Representation Learning on Large Graphs'},\n",
       "  'SSE': {'full_name': 'Stochastic Steady-state Embedding',\n",
       "   'url': 'https://icml.cc/Conferences/2018/Schedule?showEvent=2424',\n",
       "   'title': 'Learning Steady-States of Iterative Algorithms over Graphs'},\n",
       "  'Local Mixup': {'full_name': 'Local Mixup',\n",
       "   'url': 'https://arxiv.org/abs/2201.04368v1',\n",
       "   'title': 'Preventing Manifold Intrusion with Locality: Local Mixup'},\n",
       "  'BART': {'full_name': 'BART',\n",
       "   'url': 'https://arxiv.org/abs/1910.13461v1',\n",
       "   'title': 'BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension'},\n",
       "  'Kaiming Initialization': {'full_name': 'Kaiming Initialization',\n",
       "   'url': 'http://arxiv.org/abs/1502.01852v1',\n",
       "   'title': 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification'},\n",
       "  'RetinaNet': {'full_name': 'RetinaNet',\n",
       "   'url': 'http://arxiv.org/abs/1708.02002v2',\n",
       "   'title': 'Focal Loss for Dense Object Detection'},\n",
       "  'AdvProp': {'full_name': 'AdvProp',\n",
       "   'url': 'https://arxiv.org/abs/1911.09665v2',\n",
       "   'title': 'Adversarial Examples Improve Image Recognition'},\n",
       "  'DExTra': {'full_name': 'DExTra',\n",
       "   'url': 'https://arxiv.org/abs/2008.00623v2',\n",
       "   'title': 'DeLighT: Deep and Light-weight Transformer'},\n",
       "  'CodeT5': {'full_name': 'CodeT5',\n",
       "   'url': 'https://arxiv.org/abs/2109.00859v1',\n",
       "   'title': 'CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation'},\n",
       "  'Temporal Distribution Characterization': {'full_name': 'Temporal Distribution Characterization',\n",
       "   'url': 'https://arxiv.org/abs/2108.04443v2',\n",
       "   'title': 'AdaRNN: Adaptive Learning and Forecasting of Time Series'},\n",
       "  'NesT': {'full_name': 'NesT',\n",
       "   'url': 'https://arxiv.org/abs/2105.12723v4',\n",
       "   'title': 'Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding'},\n",
       "  'VL-T5': {'full_name': 'VL-T5',\n",
       "   'url': 'https://arxiv.org/abs/2102.02779v2',\n",
       "   'title': 'Unifying Vision-and-Language Tasks via Text Generation'},\n",
       "  'DANet': {'full_name': 'Dual Attention Network',\n",
       "   'url': 'http://arxiv.org/abs/1809.02983v4',\n",
       "   'title': 'Dual Attention Network for Scene Segmentation'},\n",
       "  'Fire Module': {'full_name': 'Fire Module',\n",
       "   'url': 'http://arxiv.org/abs/1602.07360v4',\n",
       "   'title': 'SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size'},\n",
       "  'ERNIE-GEN': {'full_name': 'ERNIE-GEN',\n",
       "   'url': 'https://arxiv.org/abs/2001.11314v3',\n",
       "   'title': 'ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation'},\n",
       "  'Local Relation Layer': {'full_name': 'Local Relation Layer',\n",
       "   'url': 'http://arxiv.org/abs/1904.11491v1',\n",
       "   'title': 'Local Relation Networks for Image Recognition'},\n",
       "  'FCPose': {'full_name': 'FCPose',\n",
       "   'url': 'https://arxiv.org/abs/2105.14185v1',\n",
       "   'title': 'FCPose: Fully Convolutional Multi-Person Pose Estimation with Dynamic Instance-Aware Convolutions'},\n",
       "  'Singular Value Clipping': {'full_name': 'Singular Value Clipping',\n",
       "   'url': 'http://arxiv.org/abs/1611.06624v3',\n",
       "   'title': 'Temporal Generative Adversarial Nets with Singular Value Clipping'},\n",
       "  'Random Synthesized Attention': {'full_name': 'Random Synthesized Attention',\n",
       "   'url': 'https://arxiv.org/abs/2005.00743v3',\n",
       "   'title': 'Synthesizer: Rethinking Self-Attention in Transformer Models'},\n",
       "  'Monte Carlo Dropout': {'full_name': 'Monte Carlo Dropout',\n",
       "   'url': 'http://arxiv.org/abs/1506.02142v6',\n",
       "   'title': 'Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning'},\n",
       "  'Center Pooling': {'full_name': 'Center Pooling',\n",
       "   'url': 'http://arxiv.org/abs/1904.08189v3',\n",
       "   'title': 'CenterNet: Keypoint Triplets for Object Detection'},\n",
       "  'SHA-RNN': {'full_name': 'Single Headed Attention RNN',\n",
       "   'url': 'https://arxiv.org/abs/1911.11423v2',\n",
       "   'title': 'Single Headed Attention RNN: Stop Thinking With Your Head'},\n",
       "  'DimConv': {'full_name': 'Dimension-wise Convolution',\n",
       "   'url': 'https://arxiv.org/abs/1906.03516v3',\n",
       "   'title': 'DiCENet: Dimension-wise Convolutions for Efficient Networks'},\n",
       "  'GMVAE': {'full_name': 'Gaussian Mixture Variational Autoencoder',\n",
       "   'url': 'https://arxiv.org/abs/2108.10764v1',\n",
       "   'title': 'Regularizing Transformers With Deep Probabilistic Layers'},\n",
       "  'LR-Net': {'full_name': 'LR-Net', 'url': None, 'title': None},\n",
       "  'SkipInit': {'full_name': 'SkipInit',\n",
       "   'url': 'https://arxiv.org/abs/2002.10444v3',\n",
       "   'title': 'Batch Normalization Biases Residual Blocks Towards the Identity Function in Deep Networks'},\n",
       "  'TinyNet': {'full_name': \"Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets\",\n",
       "   'url': 'https://arxiv.org/abs/2010.14819v2',\n",
       "   'title': \"Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets\"},\n",
       "  'Gradual Self-Training': {'full_name': 'Gradual Self-Training',\n",
       "   'url': 'https://arxiv.org/abs/2002.11361v1',\n",
       "   'title': 'Understanding Self-Training for Gradual Domain Adaptation'},\n",
       "  'PGM': {'full_name': 'Probability Guided Maxout',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Fast-YOLOv3': {'full_name': 'Fast-YOLOv3',\n",
       "   'url': 'http://arxiv.org/abs/1804.02767v1',\n",
       "   'title': 'YOLOv3: An Incremental Improvement'},\n",
       "  'Self-adaptive Training': {'full_name': 'Self-adaptive Training',\n",
       "   'url': 'https://arxiv.org/abs/2002.10319v2',\n",
       "   'title': 'Self-Adaptive Training: beyond Empirical Risk Minimization'},\n",
       "  'UNETR': {'full_name': 'UNet Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2103.10504v3',\n",
       "   'title': 'UNETR: Transformers for 3D Medical Image Segmentation'},\n",
       "  'Base Boosting': {'full_name': 'Base Boosting',\n",
       "   'url': 'https://arxiv.org/abs/2005.06194v1',\n",
       "   'title': 'Boosting on the shoulders of giants in quantum device calibration'},\n",
       "  'GShard': {'full_name': 'GShard',\n",
       "   'url': 'https://arxiv.org/abs/2006.16668v1',\n",
       "   'title': 'GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding'},\n",
       "  'FastSGT': {'full_name': 'FastSGT',\n",
       "   'url': 'https://arxiv.org/abs/2008.12335v1',\n",
       "   'title': 'A Fast and Robust BERT-based Dialogue State Tracker for Schema-Guided Dialogue Dataset'},\n",
       "  'YOLOX': {'full_name': 'YOLOX',\n",
       "   'url': 'https://arxiv.org/abs/2107.08430v2',\n",
       "   'title': 'YOLOX: Exceeding YOLO Series in 2021'},\n",
       "  'DIoU-NMS': {'full_name': 'DIoU-NMS',\n",
       "   'url': 'https://arxiv.org/abs/1911.08287v1',\n",
       "   'title': 'Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression'},\n",
       "  'MoNet': {'full_name': 'Mixture model network',\n",
       "   'url': 'http://arxiv.org/abs/1611.08402v3',\n",
       "   'title': 'Geometric deep learning on graphs and manifolds using mixture model CNNs'},\n",
       "  'Inception-ResNet-v2-C': {'full_name': 'Inception-ResNet-v2-C',\n",
       "   'url': 'http://arxiv.org/abs/1602.07261v2',\n",
       "   'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
       "  'VGG': {'full_name': 'VGG',\n",
       "   'url': 'http://arxiv.org/abs/1409.1556v6',\n",
       "   'title': 'Very Deep Convolutional Networks for Large-Scale Image Recognition'},\n",
       "  'Label Quality Model': {'full_name': 'Label Quality Model',\n",
       "   'url': 'https://arxiv.org/abs/2107.11413v4',\n",
       "   'title': 'An Instance-Dependent Simulation Framework for Learning with Label Noise'},\n",
       "  'Anti-Alias Downsampling': {'full_name': 'Anti-Alias Downsampling',\n",
       "   'url': 'https://arxiv.org/abs/1904.11486v2',\n",
       "   'title': 'Making Convolutional Networks Shift-Invariant Again'},\n",
       "  'GALA': {'full_name': 'Global-and-Local attention',\n",
       "   'url': 'https://arxiv.org/abs/1805.08819v4',\n",
       "   'title': 'Learning what and where to attend'},\n",
       "  'Dilated Causal Convolution': {'full_name': 'Dilated Causal Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1609.03499v2',\n",
       "   'title': 'WaveNet: A Generative Model for Raw Audio'},\n",
       "  'pixel2style2pixel': {'full_name': 'pixel2style2pixel',\n",
       "   'url': 'https://arxiv.org/abs/2008.00951v2',\n",
       "   'title': 'Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation'},\n",
       "  'SAFRAN': {'full_name': 'SAFRAN - Scalable and fast non-redundant rule application',\n",
       "   'url': 'https://arxiv.org/abs/2012.05750v1',\n",
       "   'title': 'Scalable and interpretable rule-based link prediction for large heterogeneous knowledge graphs'},\n",
       "  'Ghost Module': {'full_name': 'Ghost Module',\n",
       "   'url': 'https://arxiv.org/abs/1911.11907v2',\n",
       "   'title': 'GhostNet: More Features from Cheap Operations'},\n",
       "  'Cascade Corner Pooling': {'full_name': 'Cascade Corner Pooling',\n",
       "   'url': 'http://arxiv.org/abs/1904.08189v3',\n",
       "   'title': 'CenterNet: Keypoint Triplets for Object Detection'},\n",
       "  'Funnel Transformer': {'full_name': 'Funnel Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2006.03236v1',\n",
       "   'title': 'Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing'},\n",
       "  'HRI pipeline': {'full_name': 'Human Robot Interaction Pipeline',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'FCOS': {'full_name': 'FCOS',\n",
       "   'url': 'https://arxiv.org/abs/1904.01355v5',\n",
       "   'title': 'FCOS: Fully Convolutional One-Stage Object Detection'},\n",
       "  'Blender': {'full_name': 'Blender',\n",
       "   'url': 'https://arxiv.org/abs/2001.00309v3',\n",
       "   'title': 'BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation'},\n",
       "  'AggMo': {'full_name': 'AggMo',\n",
       "   'url': 'http://arxiv.org/abs/1804.00325v3',\n",
       "   'title': 'Aggregated Momentum: Stability Through Passive Damping'},\n",
       "  'EBM': {'full_name': 'energy-based model',\n",
       "   'url': 'http://arxiv.org/abs/1602.03264v3',\n",
       "   'title': 'A Theory of Generative ConvNet'},\n",
       "  'Dueling Network': {'full_name': 'Dueling Network',\n",
       "   'url': 'http://arxiv.org/abs/1511.06581v3',\n",
       "   'title': 'Dueling Network Architectures for Deep Reinforcement Learning'},\n",
       "  'ESACL': {'full_name': 'Enhanced Seq2Seq Autoencoder via Contrastive Learning',\n",
       "   'url': 'https://arxiv.org/abs/2108.11992v1',\n",
       "   'title': 'Enhanced Seq2Seq Autoencoder via Contrastive Learning for Abstractive Text Summarization'},\n",
       "  'OASIS': {'full_name': 'OASIS',\n",
       "   'url': 'https://arxiv.org/abs/2012.04781v3',\n",
       "   'title': 'You Only Need Adversarial Supervision for Semantic Image Synthesis'},\n",
       "  'OODformer': {'full_name': 'OODformer',\n",
       "   'url': 'https://arxiv.org/abs/2107.08976v2',\n",
       "   'title': 'OODformer: Out-Of-Distribution Detection Transformer'},\n",
       "  'Deformable DETR': {'full_name': 'Deformable DETR',\n",
       "   'url': 'https://arxiv.org/abs/2010.04159v4',\n",
       "   'title': 'Deformable DETR: Deformable Transformers for End-to-End Object Detection'},\n",
       "  'FuseFormer': {'full_name': 'FuseFormer',\n",
       "   'url': 'https://arxiv.org/abs/2109.02974v1',\n",
       "   'title': 'FuseFormer: Fusing Fine-Grained Information in Transformers for Video Inpainting'},\n",
       "  'LightAutoML': {'full_name': 'LightAutoML',\n",
       "   'url': 'https://arxiv.org/abs/2109.01528v2',\n",
       "   'title': 'LightAutoML: AutoML Solution for a Large Financial Services Ecosystem'},\n",
       "  'HypE': {'full_name': 'Hyperboloid Embeddings',\n",
       "   'url': 'https://arxiv.org/abs/2012.13023v3',\n",
       "   'title': 'Self-Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs'},\n",
       "  'Coordinate attention': {'full_name': 'Coordinate attention',\n",
       "   'url': 'https://arxiv.org/abs/2103.02907v1',\n",
       "   'title': 'Coordinate Attention for Efficient Mobile Network Design'},\n",
       "  'CRF': {'full_name': 'Conditional Random Field', 'url': None, 'title': None},\n",
       "  'Dorylus': {'full_name': 'Dorylus',\n",
       "   'url': 'https://arxiv.org/abs/2105.11118v2',\n",
       "   'title': 'Dorylus: Affordable, Scalable, and Accurate GNN Training with Distributed CPU Servers and Serverless Threads'},\n",
       "  'Enhanced Fusion Framework': {'full_name': 'Enhanced Fusion Framework',\n",
       "   'url': 'https://arxiv.org/abs/2101.06968v2',\n",
       "   'title': 'Motor-Imagery-Based Brain Computer Interface using Signal Derivation and Aggregation Functions'},\n",
       "  'Parametric UMAP': {'full_name': 'Parametric UMAP',\n",
       "   'url': 'https://arxiv.org/abs/2009.12981v4',\n",
       "   'title': 'Parametric UMAP embeddings for representation and semi-supervised learning'},\n",
       "  'ConViT': {'full_name': 'ConViT',\n",
       "   'url': 'https://arxiv.org/abs/2103.10697v2',\n",
       "   'title': 'ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases'},\n",
       "  'MobileBERT': {'full_name': 'MobileBERT',\n",
       "   'url': 'https://arxiv.org/abs/2004.02984v2',\n",
       "   'title': 'MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices'},\n",
       "  'GAN Least Squares Loss': {'full_name': 'GAN Least Squares Loss',\n",
       "   'url': 'http://arxiv.org/abs/1611.04076v3',\n",
       "   'title': 'Least Squares Generative Adversarial Networks'},\n",
       "  'Sparsemax': {'full_name': 'Sparsemax',\n",
       "   'url': 'http://arxiv.org/abs/1602.02068v2',\n",
       "   'title': 'From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification'},\n",
       "  'Rendezvous': {'full_name': 'Multi-head of Mixed Attention',\n",
       "   'url': 'https://arxiv.org/abs/2109.03223v2',\n",
       "   'title': 'Rendezvous: Attention Mechanisms for the Recognition of Surgical Action Triplets in Endoscopic Videos'},\n",
       "  'Gaussian Process': {'full_name': 'Gaussian Process',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Augmented SBERT': {'full_name': 'Augmented SBERT',\n",
       "   'url': 'https://arxiv.org/abs/2010.08240v2',\n",
       "   'title': 'Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks'},\n",
       "  'FSAF': {'full_name': 'FSAF',\n",
       "   'url': 'http://arxiv.org/abs/1903.00621v1',\n",
       "   'title': 'Feature Selective Anchor-Free Module for Single-Shot Object Detection'},\n",
       "  'Noisy Student': {'full_name': 'Noisy Student',\n",
       "   'url': 'https://arxiv.org/abs/1911.04252v4',\n",
       "   'title': 'Self-training with Noisy Student improves ImageNet classification'},\n",
       "  'Co-Correcting': {'full_name': 'Co-Correcting',\n",
       "   'url': 'https://arxiv.org/abs/2109.05159v1',\n",
       "   'title': 'Co-Correcting: Noise-tolerant Medical Image Classification via mutual Label Correction'},\n",
       "  'Random Scaling': {'full_name': 'Random Scaling',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'OFA': {'full_name': 'OFA',\n",
       "   'url': 'https://arxiv.org/abs/2202.03052v2',\n",
       "   'title': 'OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework'},\n",
       "  'PELU': {'full_name': 'Parametric Exponential Linear Unit',\n",
       "   'url': 'http://arxiv.org/abs/1605.09332v4',\n",
       "   'title': 'Parametric Exponential Linear Unit for Deep Convolutional Neural Networks'},\n",
       "  'Phase Shuffle': {'full_name': 'Phase Shuffle',\n",
       "   'url': 'http://arxiv.org/abs/1802.04208v3',\n",
       "   'title': 'Adversarial Audio Synthesis'},\n",
       "  'Source Hypothesis Transfer': {'full_name': 'Source Hypothesis Transfer',\n",
       "   'url': 'https://arxiv.org/abs/2002.08546v6',\n",
       "   'title': 'Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation'},\n",
       "  '1D CNN': {'full_name': '1-Dimensional Convolutional Neural Networks',\n",
       "   'url': 'https://www.researchgate.net/publication/348288032_Convolutional_Neural_Network_and_Rule-Based_Algorithms_for_Classifying_12-lead_ECGs',\n",
       "   'title': 'Convolutional Neural Network and Rule-Based Algorithms for Classifying 12-lead ECGs'},\n",
       "  'Pix2Pix': {'full_name': 'Pix2Pix',\n",
       "   'url': 'http://arxiv.org/abs/1611.07004v3',\n",
       "   'title': 'Image-to-Image Translation with Conditional Adversarial Networks'},\n",
       "  'DynaBERT': {'full_name': 'DynaBERT',\n",
       "   'url': 'https://arxiv.org/abs/2004.04037v2',\n",
       "   'title': 'DynaBERT: Dynamic BERT with Adaptive Width and Depth'},\n",
       "  'Panoptic FPN': {'full_name': 'Panoptic FPN',\n",
       "   'url': 'http://arxiv.org/abs/1901.02446v2',\n",
       "   'title': 'Panoptic Feature Pyramid Networks'},\n",
       "  'LeViT Attention Block': {'full_name': 'LeViT Attention Block',\n",
       "   'url': 'https://arxiv.org/abs/2104.01136v2',\n",
       "   'title': \"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference\"},\n",
       "  'BigBiGAN': {'full_name': 'BigBiGAN',\n",
       "   'url': 'https://arxiv.org/abs/1907.02544v2',\n",
       "   'title': 'Large Scale Adversarial Representation Learning'},\n",
       "  'AlphaFold': {'full_name': 'AlphaFold',\n",
       "   'url': 'https://www.nature.com/articles/s41586-021-03819-2',\n",
       "   'title': 'Highly accurate protein structure prediction with AlphaFold'},\n",
       "  'VC R-CNN': {'full_name': 'Visual Commonsense Region-based Convolutional Neural Network',\n",
       "   'url': 'https://arxiv.org/abs/2002.12204v3',\n",
       "   'title': 'Visual Commonsense R-CNN'},\n",
       "  'Bilateral Grid': {'full_name': 'Bilateral Grid',\n",
       "   'url': 'http://arxiv.org/abs/1707.02880v2',\n",
       "   'title': 'Deep Bilateral Learning for Real-Time Image Enhancement'},\n",
       "  'U-Net': {'full_name': 'U-Net',\n",
       "   'url': 'http://arxiv.org/abs/1505.04597v1',\n",
       "   'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation'},\n",
       "  'Gradient Sparsification': {'full_name': 'Gradient Sparsification',\n",
       "   'url': 'http://arxiv.org/abs/1710.09854v1',\n",
       "   'title': 'Gradient Sparsification for Communication-Efficient Distributed Optimization'},\n",
       "  'PReLU-Net': {'full_name': 'PReLU-Net',\n",
       "   'url': 'http://arxiv.org/abs/1502.01852v1',\n",
       "   'title': 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification'},\n",
       "  'Bayesian REX': {'full_name': 'Bayesian Reward Extrapolation',\n",
       "   'url': 'https://arxiv.org/abs/2002.09089v4',\n",
       "   'title': 'Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences'},\n",
       "  'Robust Predictable Control': {'full_name': 'Robust Predictable Control',\n",
       "   'url': 'https://arxiv.org/abs/2109.03214v1',\n",
       "   'title': 'Robust Predictable Control'},\n",
       "  'MEUZZ': {'full_name': 'MEUZZ',\n",
       "   'url': 'https://arxiv.org/abs/2002.08568v2',\n",
       "   'title': 'MEUZZ: Smart Seed Scheduling for Hybrid Fuzzing'},\n",
       "  'Transposed convolution': {'full_name': 'Transposed convolution',\n",
       "   'url': 'http://arxiv.org/abs/1605.06211v1',\n",
       "   'title': 'Fully Convolutional Networks for Semantic Segmentation'},\n",
       "  'L2M': {'full_name': 'Learning to Match',\n",
       "   'url': 'https://arxiv.org/abs/2007.10791v3',\n",
       "   'title': 'Learning to Match Distributions for Domain Adaptation'},\n",
       "  'AutoDropout': {'full_name': 'AutoDropout',\n",
       "   'url': 'https://arxiv.org/abs/2101.01761v1',\n",
       "   'title': 'AutoDropout: Learning Dropout Patterns to Regularize Deep Networks'},\n",
       "  'T-Fixup': {'full_name': 'T-Fixup',\n",
       "   'url': 'https://proceedings.icml.cc/static/paper_files/icml/2020/5691-Paper.pdf',\n",
       "   'title': 'Improving Transformer Optimization Through Better Initialization'},\n",
       "  'ATSS': {'full_name': 'Adaptive Training Sample Selection',\n",
       "   'url': 'https://arxiv.org/abs/1912.02424v4',\n",
       "   'title': 'Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection'},\n",
       "  'ByteScheduler': {'full_name': 'ByteScheduler', 'url': None, 'title': None},\n",
       "  'TrOCR': {'full_name': 'TrOCR',\n",
       "   'url': 'https://arxiv.org/abs/2109.10282v4',\n",
       "   'title': 'TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models'},\n",
       "  'Bi3D': {'full_name': 'Bi3D',\n",
       "   'url': 'https://arxiv.org/abs/2005.07274v2',\n",
       "   'title': 'Bi3D: Stereo Depth Estimation via Binary Classifications'},\n",
       "  'Causal Convolution': {'full_name': 'Causal Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1609.03499v2',\n",
       "   'title': 'WaveNet: A Generative Model for Raw Audio'},\n",
       "  'PixLoc': {'full_name': 'PixLoc',\n",
       "   'url': 'https://arxiv.org/abs/2103.09213v2',\n",
       "   'title': 'Back to the Feature: Learning Robust Camera Localization from Pixels to Pose'},\n",
       "  'Symbolic rule learning': {'full_name': 'Symbolic rule learning',\n",
       "   'url': 'https://arxiv.org/abs/2012.05750v1',\n",
       "   'title': 'Scalable and interpretable rule-based link prediction for large heterogeneous knowledge graphs'},\n",
       "  'Explanation vs Attention': {'full_name': 'Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'AdaShift': {'full_name': 'AdaShift',\n",
       "   'url': 'https://arxiv.org/abs/1810.00143v4',\n",
       "   'title': 'AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods'},\n",
       "  'Multiscale Dilated Convolution Block': {'full_name': 'Multiscale Dilated Convolution Block',\n",
       "   'url': 'http://arxiv.org/abs/1609.07093v3',\n",
       "   'title': 'Neural Photo Editing with Introspective Adversarial Networks'},\n",
       "  'hdxresnet': {'full_name': 'Hybrid-deconvolution',\n",
       "   'url': 'https://arxiv.org/abs/2009.12318v2',\n",
       "   'title': 'Predicting galaxy spectra from images with hybrid convolutional neural networks'},\n",
       "  'GCT': {'full_name': 'Gated Channel Transformation',\n",
       "   'url': 'https://arxiv.org/abs/1909.11519v2',\n",
       "   'title': 'Gated Channel Transformation for Visual Recognition'},\n",
       "  'DeepSIM': {'full_name': 'DeepSIM',\n",
       "   'url': 'https://arxiv.org/abs/2109.06151v3',\n",
       "   'title': 'Image Shape Manipulation from a Single Augmented Training Sample'},\n",
       "  'RetinaNet-RS': {'full_name': 'RetinaNet-RS',\n",
       "   'url': 'https://arxiv.org/abs/2107.00057v1',\n",
       "   'title': 'Simple Training Strategies and Model Scaling for Object Detection'},\n",
       "  'HetPipe': {'full_name': 'HetPipe', 'url': None, 'title': None},\n",
       "  'PAU': {'full_name': 'Padé Activation Units',\n",
       "   'url': 'https://arxiv.org/abs/1907.06732v3',\n",
       "   'title': 'Padé Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks'},\n",
       "  'BiGG': {'full_name': 'BiGG',\n",
       "   'url': 'https://arxiv.org/abs/2006.15502v1',\n",
       "   'title': 'Scalable Deep Generative Modeling for Sparse Graphs'},\n",
       "  'BIMAN': {'full_name': 'BIMAN',\n",
       "   'url': 'https://arxiv.org/abs/2003.03172v3',\n",
       "   'title': 'Detecting and Characterizing Bots that Commit Code'},\n",
       "  'GreedyNAS-B': {'full_name': 'GreedyNAS-B',\n",
       "   'url': 'https://arxiv.org/abs/2003.11236v1',\n",
       "   'title': 'GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet'},\n",
       "  'Levenshtein Transformer': {'full_name': 'Levenshtein Transformer',\n",
       "   'url': 'https://arxiv.org/abs/1905.11006v2',\n",
       "   'title': 'Levenshtein Transformer'},\n",
       "  'NeRF': {'full_name': 'Neural Radiance Field',\n",
       "   'url': 'https://arxiv.org/abs/2003.08934v2',\n",
       "   'title': 'NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis'},\n",
       "  'SSD': {'full_name': 'SSD',\n",
       "   'url': 'http://arxiv.org/abs/1512.02325v5',\n",
       "   'title': 'SSD: Single Shot MultiBox Detector'},\n",
       "  'BTmPG': {'full_name': 'BTmPG',\n",
       "   'url': 'https://arxiv.org/abs/2109.01862v1',\n",
       "   'title': 'Pushing Paraphrase Away from Original Sentence: A Multi-Round Paraphrase Generation Approach'},\n",
       "  '1-bit Adam': {'full_name': '1-bit Adam',\n",
       "   'url': 'https://arxiv.org/abs/2102.02888v2',\n",
       "   'title': \"1-bit Adam: Communication Efficient Large-Scale Training with Adam's Convergence Speed\"},\n",
       "  'AUCO ResNet': {'full_name': 'Auditory Cortex ResNet',\n",
       "   'url': 'https://www.sciencedirect.com/science/article/pii/S0031320322001376',\n",
       "   'title': 'AUCO ResNet: an end-to-end network for Covid-19 pre-screening from cough and breath'},\n",
       "  'ELU': {'full_name': 'Exponential Linear Unit',\n",
       "   'url': 'http://arxiv.org/abs/1511.07289v5',\n",
       "   'title': 'Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)'},\n",
       "  'Gather-Excite Networks': {'full_name': 'Gather-Excite Networks',\n",
       "   'url': 'http://arxiv.org/abs/1810.12348v3',\n",
       "   'title': 'Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks'},\n",
       "  'Gaussian Affinity': {'full_name': 'Gaussian Affinity',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'G-GLN Neuron': {'full_name': 'G-GLN Neuron',\n",
       "   'url': 'https://arxiv.org/abs/2006.05964v2',\n",
       "   'title': 'Gaussian Gated Linear Networks'},\n",
       "  'SCARLET': {'full_name': 'SCARLET',\n",
       "   'url': 'https://arxiv.org/abs/1908.06022v6',\n",
       "   'title': 'SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search'},\n",
       "  'ScatNet': {'full_name': 'Scattering Transform',\n",
       "   'url': 'https://arxiv.org/abs/1203.1513v2',\n",
       "   'title': 'Invariant Scattering Convolution Networks'},\n",
       "  'SchNet': {'full_name': 'Schrödinger Network',\n",
       "   'url': 'http://arxiv.org/abs/1706.08566v5',\n",
       "   'title': 'SchNet: A continuous-filter convolutional neural network for modeling quantum interactions'},\n",
       "  'DeepIR': {'full_name': 'DeepIR',\n",
       "   'url': 'https://arxiv.org/abs/2108.07973v2',\n",
       "   'title': 'Thermal Image Processing via Physics-Inspired Deep Networks'},\n",
       "  'Deep Voice 3': {'full_name': 'Deep Voice 3',\n",
       "   'url': 'http://arxiv.org/abs/1710.07654v3',\n",
       "   'title': 'Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning'},\n",
       "  'Sinkhorn Transformer': {'full_name': 'Sinkhorn Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2002.11296v1',\n",
       "   'title': 'Sparse Sinkhorn Attention'},\n",
       "  'FcaNet': {'full_name': 'Frequency channel attention networks',\n",
       "   'url': 'https://arxiv.org/abs/2012.11879v4',\n",
       "   'title': 'FcaNet: Frequency Channel Attention Networks'},\n",
       "  'Adapter': {'full_name': 'Adapter',\n",
       "   'url': 'https://arxiv.org/abs/2101.03289v5',\n",
       "   'title': 'Trankit: A Light-Weight Transformer-based Toolkit for Multilingual Natural Language Processing'},\n",
       "  'CTC Loss': {'full_name': 'Connectionist Temporal Classification Loss',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Group Normalization': {'full_name': 'Group Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1803.08494v3',\n",
       "   'title': 'Group Normalization'},\n",
       "  'CVRL': {'full_name': 'Contrastive Video Representation Learning',\n",
       "   'url': 'https://arxiv.org/abs/2008.03800v4',\n",
       "   'title': 'Spatiotemporal Contrastive Video Representation Learning'},\n",
       "  'Concrete Dropout': {'full_name': 'Concrete Dropout',\n",
       "   'url': 'http://arxiv.org/abs/1705.07832v1',\n",
       "   'title': 'Concrete Dropout'},\n",
       "  'ECA-Net': {'full_name': 'ECA-Net',\n",
       "   'url': 'https://arxiv.org/abs/1910.03151v4',\n",
       "   'title': 'ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks'},\n",
       "  'PowerSGD': {'full_name': 'PowerSGD',\n",
       "   'url': 'https://arxiv.org/abs/1905.13727v3',\n",
       "   'title': 'PowerSGD: Practical Low-Rank Gradient Compression for Distributed Optimization'},\n",
       "  'Temporal Activation Regularization': {'full_name': 'Temporal Activation Regularization',\n",
       "   'url': 'http://arxiv.org/abs/1708.01009v1',\n",
       "   'title': 'Revisiting Activation Regularization for Language RNNs'},\n",
       "  'Deep-MAC': {'full_name': 'Deep-MAC',\n",
       "   'url': 'https://arxiv.org/abs/2104.00613v2',\n",
       "   'title': 'The surprising impact of mask-head architecture on novel class segmentation'},\n",
       "  'FA': {'full_name': 'Feedback Alignment',\n",
       "   'url': 'http://arxiv.org/abs/1411.0247v1',\n",
       "   'title': 'Random feedback weights support learning in deep neural networks'},\n",
       "  'LFME': {'full_name': 'Learning From Multiple Experts',\n",
       "   'url': 'https://arxiv.org/abs/2001.01536v3',\n",
       "   'title': 'Learning From Multiple Experts: Self-paced Knowledge Distillation for Long-tailed Classification'},\n",
       "  'SNN': {'full_name': 'Self-Normalizing Neural Networks',\n",
       "   'url': 'http://arxiv.org/abs/1706.02515v5',\n",
       "   'title': 'Self-Normalizing Neural Networks'},\n",
       "  'Siamese U-Net': {'full_name': 'Siamese U-Net',\n",
       "   'url': 'https://arxiv.org/abs/2008.11201v1',\n",
       "   'title': 'Deep Active Learning in Remote Sensing for data efficient Change Detection'},\n",
       "  'SyncBN': {'full_name': 'Synchronized Batch Normalization',\n",
       "   'url': 'http://arxiv.org/abs/1803.08904v1',\n",
       "   'title': 'Context Encoding for Semantic Segmentation'},\n",
       "  'ParaNet': {'full_name': 'ParaNet',\n",
       "   'url': 'https://arxiv.org/abs/1905.08459v3',\n",
       "   'title': 'Non-Autoregressive Neural Text-to-Speech'},\n",
       "  'CRF-RNN': {'full_name': 'CRF-RNN',\n",
       "   'url': 'http://arxiv.org/abs/1502.03240v3',\n",
       "   'title': 'Conditional Random Fields as Recurrent Neural Networks'},\n",
       "  'Spatial Broadcast Decoder': {'full_name': 'Spatial Broadcast Decoder',\n",
       "   'url': 'https://arxiv.org/abs/1901.07017v2',\n",
       "   'title': 'Spatial Broadcast Decoder: A Simple Architecture for Learning Disentangled Representations in VAEs'},\n",
       "  'CutMix': {'full_name': 'CutMix',\n",
       "   'url': 'https://arxiv.org/abs/1905.04899v2',\n",
       "   'title': 'CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features'},\n",
       "  'SPNet': {'full_name': 'Strip Pooling Network',\n",
       "   'url': 'https://arxiv.org/abs/2003.13328v1',\n",
       "   'title': 'Strip Pooling: Rethinking Spatial Pooling for Scene Parsing'},\n",
       "  'SOHO': {'full_name': 'SOHO',\n",
       "   'url': 'https://arxiv.org/abs/2104.03135v2',\n",
       "   'title': 'Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning'},\n",
       "  'PP-YOLOv2': {'full_name': 'PP-YOLOv2',\n",
       "   'url': 'https://arxiv.org/abs/2104.10419v1',\n",
       "   'title': 'PP-YOLOv2: A Practical Object Detector'},\n",
       "  'VLG-Net': {'full_name': 'Video Language Graph Matching Network',\n",
       "   'url': 'https://arxiv.org/abs/2011.10132v2',\n",
       "   'title': 'VLG-Net: Video-Language Graph Matching Network for Video Grounding'},\n",
       "  'COCO-FUNIT': {'full_name': 'COCO-FUNIT',\n",
       "   'url': 'https://arxiv.org/abs/2007.07431v3',\n",
       "   'title': 'COCO-FUNIT: Few-Shot Unsupervised Image Translation with a Content Conditioned Style Encoder'},\n",
       "  'Local Augmentation': {'full_name': 'Local Augmentation',\n",
       "   'url': 'https://arxiv.org/abs/2109.03856v4',\n",
       "   'title': 'Local Augmentation for Graph Neural Networks'},\n",
       "  'GFP-GAN': {'full_name': 'GFP-GAN',\n",
       "   'url': 'https://arxiv.org/abs/2101.04061v2',\n",
       "   'title': 'Towards Real-World Blind Face Restoration with Generative Facial Prior'},\n",
       "  'LARS': {'full_name': 'LARS',\n",
       "   'url': 'http://arxiv.org/abs/1708.03888v3',\n",
       "   'title': 'Large Batch Training of Convolutional Networks'},\n",
       "  'PFPNet': {'full_name': 'Parallel Feature Pyramid Network',\n",
       "   'url': 'http://openaccess.thecvf.com/content_ECCV_2018/html/Seung-Wook_Kim_Parallel_Feature_Pyramid_ECCV_2018_paper.html',\n",
       "   'title': 'Parallel Feature Pyramid Network for Object Detection'},\n",
       "  'BigGAN': {'full_name': 'BigGAN',\n",
       "   'url': 'http://arxiv.org/abs/1809.11096v2',\n",
       "   'title': 'Large Scale GAN Training for High Fidelity Natural Image Synthesis'},\n",
       "  'RAN': {'full_name': 'Residual Attention Network',\n",
       "   'url': 'http://arxiv.org/abs/1704.06904v1',\n",
       "   'title': 'Residual Attention Network for Image Classification'},\n",
       "  'TSRUc': {'full_name': 'TSRUc',\n",
       "   'url': 'https://arxiv.org/abs/2003.04035v3',\n",
       "   'title': 'Transformation-based Adversarial Video Prediction on Large-Scale Data'},\n",
       "  'Dynamic Keypoint Head': {'full_name': 'Dynamic Keypoint Head',\n",
       "   'url': 'https://arxiv.org/abs/2105.14185v1',\n",
       "   'title': 'FCPose: Fully Convolutional Multi-Person Pose Estimation with Dynamic Instance-Aware Convolutions'},\n",
       "  'Window-based Discriminator': {'full_name': 'Window-based Discriminator',\n",
       "   'url': 'https://arxiv.org/abs/1910.06711v3',\n",
       "   'title': 'MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis'},\n",
       "  'Contrastive Multiview Coding': {'full_name': 'Contrastive Multiview Coding',\n",
       "   'url': 'https://arxiv.org/abs/1906.05849v5',\n",
       "   'title': 'Contrastive Multiview Coding'},\n",
       "  'TGN': {'full_name': 'Temporal Graph Network',\n",
       "   'url': 'https://arxiv.org/abs/2006.10637v3',\n",
       "   'title': 'Temporal Graph Networks for Deep Learning on Dynamic Graphs'},\n",
       "  'GeniePath': {'full_name': 'GeniePath',\n",
       "   'url': 'http://arxiv.org/abs/1802.00910v3',\n",
       "   'title': 'GeniePath: Graph Neural Networks with Adaptive Receptive Paths'},\n",
       "  'Pattern-Exploiting Training': {'full_name': 'Pattern-Exploiting Training',\n",
       "   'url': 'https://arxiv.org/abs/2001.07676v3',\n",
       "   'title': 'Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference'},\n",
       "  'ESIM': {'full_name': 'Enhanced Sequential Inference Model',\n",
       "   'url': 'http://arxiv.org/abs/1609.06038v3',\n",
       "   'title': 'Enhanced LSTM for Natural Language Inference'},\n",
       "  'CP N3': {'full_name': 'CP with N3 Regularizer',\n",
       "   'url': 'http://arxiv.org/abs/1806.07297v1',\n",
       "   'title': 'Canonical Tensor Decomposition for Knowledge Base Completion'},\n",
       "  'Fast Sample Re-Weighting': {'full_name': 'Fast Sample Re-Weighting',\n",
       "   'url': 'https://arxiv.org/abs/2109.03216v1',\n",
       "   'title': 'Learning Fast Sample Re-weighting Without Reward Data'},\n",
       "  'CornerNet-Squeeze Hourglass': {'full_name': 'CornerNet-Squeeze Hourglass',\n",
       "   'url': 'https://arxiv.org/abs/1904.08900v2',\n",
       "   'title': 'CornerNet-Lite: Efficient Keypoint Based Object Detection'},\n",
       "  'Swin Transformer': {'full_name': 'Swin Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2103.14030v2',\n",
       "   'title': 'Swin Transformer: Hierarchical Vision Transformer using Shifted Windows'},\n",
       "  'SKEP': {'full_name': 'SKEP',\n",
       "   'url': 'https://arxiv.org/abs/2005.05635v2',\n",
       "   'title': 'SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis'},\n",
       "  'SFAM': {'full_name': 'Scale-wise Feature Aggregation Module',\n",
       "   'url': 'http://arxiv.org/abs/1811.04533v3',\n",
       "   'title': 'M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network'},\n",
       "  'UFLoss': {'full_name': 'Unsupervised Feature Loss',\n",
       "   'url': 'https://arxiv.org/abs/2108.12460v1',\n",
       "   'title': 'High Fidelity Deep Learning-based MRI Reconstruction with Instance-wise Discriminative Feature Matching Loss'},\n",
       "  'T2T-ViT': {'full_name': 'Tokens-To-Token Vision Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2101.11986v3',\n",
       "   'title': 'Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet'},\n",
       "  'ENet Dilated Bottleneck': {'full_name': 'ENet Dilated Bottleneck',\n",
       "   'url': 'http://arxiv.org/abs/1606.02147v1',\n",
       "   'title': 'ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation'},\n",
       "  'TD-Gammon': {'full_name': 'TD-Gammon', 'url': None, 'title': None},\n",
       "  'Spatial Attention Module (ThunderNet)': {'full_name': 'Spatial Attention Module (ThunderNet)',\n",
       "   'url': 'https://arxiv.org/abs/1903.11752v3',\n",
       "   'title': 'ThunderNet: Towards Real-time Generic Object Detection'},\n",
       "  'TSDAE': {'full_name': 'TSDAE',\n",
       "   'url': 'https://arxiv.org/abs/2104.06979v3',\n",
       "   'title': 'TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning'},\n",
       "  'Concurrent Spatial and Channel Squeeze & Excitation': {'full_name': 'Concurrent Spatial and Channel Squeeze & Excitation (scSE)',\n",
       "   'url': 'http://arxiv.org/abs/1808.08127v1',\n",
       "   'title': \"Recalibrating Fully Convolutional Networks with Spatial and Channel 'Squeeze & Excitation' Blocks\"},\n",
       "  'SNAIL': {'full_name': 'Simple Neural Attention Meta-Learner',\n",
       "   'url': 'http://arxiv.org/abs/1707.03141v3',\n",
       "   'title': 'A Simple Neural Attentive Meta-Learner'},\n",
       "  'CCT': {'full_name': 'Compact Convolutional Transformers',\n",
       "   'url': 'https://arxiv.org/abs/2104.05704v4',\n",
       "   'title': 'Escaping the Big Data Paradigm with Compact Transformers'},\n",
       "  'VSGNet': {'full_name': 'Visual-Spatial-Graph Network',\n",
       "   'url': 'https://arxiv.org/abs/2003.05541v1',\n",
       "   'title': 'VSGNet: Spatial Attention Network for Detecting Human Object Interactions Using Graph Convolutions'},\n",
       "  'SVPG': {'full_name': 'Stein Variational Policy Gradient',\n",
       "   'url': 'http://arxiv.org/abs/1704.02399v1',\n",
       "   'title': 'Stein Variational Policy Gradient'},\n",
       "  'Tacotron 2': {'full_name': 'Tacotron2',\n",
       "   'url': 'http://arxiv.org/abs/1712.05884v2',\n",
       "   'title': 'Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions'},\n",
       "  'Capsule Network': {'full_name': 'Capsule Network',\n",
       "   'url': 'http://arxiv.org/abs/1710.09829v2',\n",
       "   'title': 'Dynamic Routing Between Capsules'},\n",
       "  'DualGCN': {'full_name': 'Dual Graph Convolutional Networks',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'Glow-TTS': {'full_name': 'Glow-TTS',\n",
       "   'url': 'https://arxiv.org/abs/2005.11129v1',\n",
       "   'title': 'Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search'},\n",
       "  'MutualGuide': {'full_name': 'Mutual Guidance',\n",
       "   'url': 'https://arxiv.org/abs/2009.14085v1',\n",
       "   'title': 'Localize to Classify and Classify to Localize: Mutual Guidance in Object Detection'},\n",
       "  'Self-Adjusting Smooth L1 Loss': {'full_name': 'Self-Adjusting Smooth L1 Loss',\n",
       "   'url': 'http://arxiv.org/abs/1901.03353v1',\n",
       "   'title': 'RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free'},\n",
       "  'Cross-Covariance Attention': {'full_name': 'Cross-Covariance Attention',\n",
       "   'url': 'https://arxiv.org/abs/2106.09681v2',\n",
       "   'title': 'XCiT: Cross-Covariance Image Transformers'},\n",
       "  'Hourglass Module': {'full_name': 'Hourglass Module',\n",
       "   'url': 'http://arxiv.org/abs/1603.06937v2',\n",
       "   'title': 'Stacked Hourglass Networks for Human Pose Estimation'},\n",
       "  'ALBERT': {'full_name': 'ALBERT',\n",
       "   'url': 'https://arxiv.org/abs/1909.11942v6',\n",
       "   'title': 'ALBERT: A Lite BERT for Self-supervised Learning of Language Representations'},\n",
       "  'CARAFE': {'full_name': 'CARAFE',\n",
       "   'url': 'https://arxiv.org/abs/1905.02188v3',\n",
       "   'title': 'CARAFE: Content-Aware ReAssembly of FEatures'},\n",
       "  'OSA (identity mapping + eSE)': {'full_name': 'OSA (identity mapping + eSE)',\n",
       "   'url': 'https://arxiv.org/abs/1911.06667v6',\n",
       "   'title': 'CenterMask : Real-Time Anchor-Free Instance Segmentation'},\n",
       "  'GANformer': {'full_name': 'Generative Adversarial Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2103.01209v4',\n",
       "   'title': 'Generative Adversarial Transformers'},\n",
       "  'Big-Little Net': {'full_name': 'Big-Little Net',\n",
       "   'url': 'https://arxiv.org/abs/1807.03848v3',\n",
       "   'title': 'Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition'},\n",
       "  'SimpleNet': {'full_name': 'SimpleNet',\n",
       "   'url': 'http://arxiv.org/abs/1608.06037v7',\n",
       "   'title': 'Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures'},\n",
       "  'CIDA': {'full_name': 'Continuously Indexed Domain Adaptation',\n",
       "   'url': 'https://arxiv.org/abs/2007.01807v2',\n",
       "   'title': 'Continuously Indexed Domain Adaptation'},\n",
       "  'RPN': {'full_name': 'Region Proposal Network',\n",
       "   'url': 'http://arxiv.org/abs/1506.01497v3',\n",
       "   'title': 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'},\n",
       "  'AdaRNN': {'full_name': 'AdaRNN',\n",
       "   'url': 'https://arxiv.org/abs/2108.04443v2',\n",
       "   'title': 'AdaRNN: Adaptive Learning and Forecasting of Time Series'},\n",
       "  'TayPO': {'full_name': 'Taylor Expansion Policy Optimization',\n",
       "   'url': 'https://arxiv.org/abs/2003.06259v1',\n",
       "   'title': 'Taylor Expansion Policy Optimization'},\n",
       "  'Restricted Boltzmann Machine': {'full_name': 'Restricted Boltzmann Machine',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'ResNeXt': {'full_name': 'ResNeXt',\n",
       "   'url': 'http://arxiv.org/abs/1611.05431v2',\n",
       "   'title': 'Aggregated Residual Transformations for Deep Neural Networks'},\n",
       "  'T5': {'full_name': 'T5',\n",
       "   'url': 'https://arxiv.org/abs/1910.10683v3',\n",
       "   'title': 'Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer'},\n",
       "  'NPID++': {'full_name': 'NPID++',\n",
       "   'url': 'https://arxiv.org/abs/1912.01991v1',\n",
       "   'title': 'Self-Supervised Learning of Pretext-Invariant Representations'},\n",
       "  'Spatial & Temporal Attention': {'full_name': 'Spatial & Temporal Attention',\n",
       "   'url': 'http://arxiv.org/abs/1611.06067v1',\n",
       "   'title': 'An End-to-End Spatio-Temporal Attention Model for Human Action Recognition from Skeleton Data'},\n",
       "  'IPL': {'full_name': 'Iterative Pseudo-Labeling',\n",
       "   'url': 'https://arxiv.org/abs/2005.09267v2',\n",
       "   'title': 'Iterative Pseudo-Labeling for Speech Recognition'},\n",
       "  'DDSP': {'full_name': 'Differentiable Digital Signal Processing',\n",
       "   'url': 'https://arxiv.org/abs/2001.04643v1',\n",
       "   'title': 'DDSP: Differentiable Digital Signal Processing'},\n",
       "  'MeshGraphNet': {'full_name': 'MeshGraphNet',\n",
       "   'url': 'https://arxiv.org/abs/2010.03409v4',\n",
       "   'title': 'Learning Mesh-Based Simulation with Graph Networks'},\n",
       "  'CT-Layer': {'full_name': 'Commute Times Layer',\n",
       "   'url': 'https://arxiv.org/abs/2206.07369v1',\n",
       "   'title': 'DiffWire: Inductive Graph Rewiring via the Lovász Bound'},\n",
       "  'Mixer Layer': {'full_name': 'MLP-Mixer Layer',\n",
       "   'url': 'https://arxiv.org/abs/2105.01601v4',\n",
       "   'title': 'MLP-Mixer: An all-MLP Architecture for Vision'},\n",
       "  'LMU': {'full_name': 'Legendre Memory Unit',\n",
       "   'url': 'http://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks',\n",
       "   'title': 'Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks'},\n",
       "  'TD-VAE': {'full_name': 'TD-VAE',\n",
       "   'url': 'http://arxiv.org/abs/1806.03107v3',\n",
       "   'title': 'Temporal Difference Variational Auto-Encoder'},\n",
       "  'AlphaStar': {'full_name': 'DeepMind AlphaStar', 'url': None, 'title': None},\n",
       "  'Rotary Embeddings': {'full_name': 'Rotary Position Embedding',\n",
       "   'url': 'https://arxiv.org/abs/2104.09864v4',\n",
       "   'title': 'RoFormer: Enhanced Transformer with Rotary Position Embedding'},\n",
       "  'BIDeN': {'full_name': 'Blind Image Decomposition Network',\n",
       "   'url': 'https://arxiv.org/abs/2108.11364v3',\n",
       "   'title': 'Blind Image Decomposition'},\n",
       "  'Boost-GNN': {'full_name': 'Boost-GNN',\n",
       "   'url': 'https://arxiv.org/abs/2101.08543v2',\n",
       "   'title': 'Boost then Convolve: Gradient Boosting Meets Graph Neural Networks'},\n",
       "  'Self-Calibrated Convolutions': {'full_name': 'Self-Calibrated Convolutions',\n",
       "   'url': 'http://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Improving_Convolutional_Networks_With_Self-Calibrated_Convolutions_CVPR_2020_paper.html',\n",
       "   'title': 'Improving Convolutional Networks With Self-Calibrated Convolutions'},\n",
       "  'MAD Learning': {'full_name': 'Memory-Associated Differential Learning',\n",
       "   'url': 'https://arxiv.org/abs/2102.05246v2',\n",
       "   'title': 'Memory-Associated Differential Learning'},\n",
       "  'Neural adjoint': {'full_name': 'Neural adjoint method',\n",
       "   'url': 'https://arxiv.org/abs/2009.12919v4',\n",
       "   'title': 'Benchmarking deep inverse models over time, and the neural-adjoint method'},\n",
       "  'DCGAN': {'full_name': 'Deep Convolutional GAN',\n",
       "   'url': 'http://arxiv.org/abs/1511.06434v2',\n",
       "   'title': 'Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks'},\n",
       "  'CheXNet': {'full_name': 'CheXNet',\n",
       "   'url': 'http://arxiv.org/abs/1711.05225v3',\n",
       "   'title': 'CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning'},\n",
       "  'Inception-v4': {'full_name': 'Inception-v4',\n",
       "   'url': 'http://arxiv.org/abs/1602.07261v2',\n",
       "   'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
       "  'Effective Squeeze-and-Excitation Block': {'full_name': 'Effective Squeeze-and-Excitation Block',\n",
       "   'url': 'https://arxiv.org/abs/1911.06667v6',\n",
       "   'title': 'CenterMask : Real-Time Anchor-Free Instance Segmentation'},\n",
       "  'Submanifold Convolution': {'full_name': 'Submanifold Convolution',\n",
       "   'url': 'http://arxiv.org/abs/1711.10275v1',\n",
       "   'title': '3D Semantic Segmentation with Submanifold Sparse Convolutional Networks'},\n",
       "  'FEFM': {'full_name': 'Field Embedded Factorization Machine',\n",
       "   'url': 'https://arxiv.org/abs/2009.09931v2',\n",
       "   'title': 'Field-Embedded Factorization Machines for Click-through rate prediction'},\n",
       "  'Polya-Gamma Augmentation': {'full_name': 'Data augmentation using Polya-Gamma latent variables.',\n",
       "   'url': 'http://arxiv.org/abs/1205.0310v3',\n",
       "   'title': 'Bayesian inference for logistic models using Polya-Gamma latent variables'},\n",
       "  'SABL': {'full_name': 'Side-Aware Boundary Localization',\n",
       "   'url': 'https://arxiv.org/abs/1912.04260v2',\n",
       "   'title': 'Side-Aware Boundary Localization for More Precise Object Detection'},\n",
       "  'Random Erasing': {'full_name': 'Random Erasing',\n",
       "   'url': 'http://arxiv.org/abs/1708.04896v2',\n",
       "   'title': 'Random Erasing Data Augmentation'},\n",
       "  'Feature-Centric Voting': {'full_name': 'Feature-Centric Voting',\n",
       "   'url': 'https://www.semanticscholar.org/paper/Voting-for-Voting-in-Online-Point-Cloud-Object-Wang-Posner/8154027ed2e0c1772b54e79c40d30ae9ee468331',\n",
       "   'title': 'Voting for Voting in Online Point Cloud Object Detection'},\n",
       "  'GPipe': {'full_name': 'GPipe',\n",
       "   'url': 'https://arxiv.org/abs/1811.06965v5',\n",
       "   'title': 'GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism'},\n",
       "  'Weight Tying': {'full_name': 'Weight Tying',\n",
       "   'url': 'http://arxiv.org/abs/1608.05859v3',\n",
       "   'title': 'Using the Output Embedding to Improve Language Models'},\n",
       "  'Depthwise Separable Convolution': {'full_name': 'Depthwise Separable Convolution',\n",
       "   'url': 'http://openaccess.thecvf.com/content_cvpr_2017/html/Chollet_Xception_Deep_Learning_CVPR_2017_paper.html',\n",
       "   'title': 'Xception: Deep Learning With Depthwise Separable Convolutions'},\n",
       "  'HMGNN': {'full_name': 'Heterogeneous Molecular Graph Neural Network',\n",
       "   'url': 'https://arxiv.org/abs/2009.12710v1',\n",
       "   'title': 'Heterogeneous Molecular Graph Neural Networks for Predicting Molecule Properties'},\n",
       "  'DPT': {'full_name': 'Dense Prediction Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2103.13413v1',\n",
       "   'title': 'Vision Transformers for Dense Prediction'},\n",
       "  'VisTR': {'full_name': 'VisTR',\n",
       "   'url': 'https://arxiv.org/abs/2011.14503v5',\n",
       "   'title': 'End-to-End Video Instance Segmentation with Transformers'},\n",
       "  'CondConv': {'full_name': 'CondConv',\n",
       "   'url': 'https://arxiv.org/abs/1904.04971v3',\n",
       "   'title': 'CondConv: Conditionally Parameterized Convolutions for Efficient Inference'},\n",
       "  'Attribute2Font': {'full_name': 'Attribute2Font',\n",
       "   'url': 'https://arxiv.org/abs/2005.07865v1',\n",
       "   'title': 'Attribute2Font: Creating Fonts You Want From Attributes'},\n",
       "  'Inception-ResNet-v2-B': {'full_name': 'Inception-ResNet-v2-B',\n",
       "   'url': 'http://arxiv.org/abs/1602.07261v2',\n",
       "   'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
       "  'LayerDrop': {'full_name': 'LayerDrop',\n",
       "   'url': 'https://arxiv.org/abs/1909.11556v1',\n",
       "   'title': 'Reducing Transformer Depth on Demand with Structured Dropout'},\n",
       "  'Truncation Trick': {'full_name': 'Truncation Trick',\n",
       "   'url': 'http://arxiv.org/abs/1706.00082v1',\n",
       "   'title': 'Megapixel Size Image Creation using Generative Adversarial Networks'},\n",
       "  'Maxout': {'full_name': 'Maxout',\n",
       "   'url': 'http://arxiv.org/abs/1302.4389v4',\n",
       "   'title': 'Maxout Networks'},\n",
       "  'Compressed Memory': {'full_name': 'Compressed Memory',\n",
       "   'url': 'https://arxiv.org/abs/1911.05507v1',\n",
       "   'title': 'Compressive Transformers for Long-Range Sequence Modelling'},\n",
       "  'EGT': {'full_name': 'Edge-augmented Graph Transformer',\n",
       "   'url': 'https://arxiv.org/abs/2108.03348v3',\n",
       "   'title': 'Global Self-Attention as a Replacement for Graph Convolution'},\n",
       "  'Softplus': {'full_name': 'Softplus', 'url': None, 'title': None},\n",
       "  'RAM': {'full_name': 'Recurrent models of visual attention',\n",
       "   'url': 'http://arxiv.org/abs/1406.6247v1',\n",
       "   'title': 'Recurrent Models of Visual Attention'},\n",
       "  'GELU': {'full_name': 'Gaussian Error Linear Units',\n",
       "   'url': 'https://arxiv.org/abs/1606.08415v4',\n",
       "   'title': 'Gaussian Error Linear Units (GELUs)'},\n",
       "  'FixMatch': {'full_name': 'FixMatch',\n",
       "   'url': 'https://arxiv.org/abs/2001.07685v2',\n",
       "   'title': 'FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence'},\n",
       "  'Rainbow DQN': {'full_name': 'Rainbow DQN',\n",
       "   'url': 'http://arxiv.org/abs/1710.02298v1',\n",
       "   'title': 'Rainbow: Combining Improvements in Deep Reinforcement Learning'},\n",
       "  'KnowPrompt': {'full_name': 'KnowPrompt',\n",
       "   'url': 'https://arxiv.org/abs/2104.07650v6',\n",
       "   'title': 'KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction'},\n",
       "  'Memory Network': {'full_name': 'Memory Network',\n",
       "   'url': 'http://arxiv.org/abs/1410.3916v11',\n",
       "   'title': 'Memory Networks'},\n",
       "  'NoisyNet-DQN': {'full_name': 'NoisyNet-DQN',\n",
       "   'url': 'https://arxiv.org/abs/1706.10295v3',\n",
       "   'title': 'Noisy Networks for Exploration'},\n",
       "  'LXMERT': {'full_name': 'Learning Cross-Modality Encoder Representations from Transformers',\n",
       "   'url': 'https://arxiv.org/abs/1908.07490v3',\n",
       "   'title': 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'},\n",
       "  'Polynomial Rate Decay': {'full_name': 'Polynomial Rate Decay',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'H3DNet': {'full_name': 'H3DNet', 'url': None, 'title': None},\n",
       "  'VEGA': {'full_name': 'VEGA',\n",
       "   'url': 'https://arxiv.org/abs/2011.01507v4',\n",
       "   'title': 'VEGA: Towards an End-to-End Configurable AutoML Pipeline'},\n",
       "  'Contextualized Topic Models': {'full_name': 'Contextualized Topic Models',\n",
       "   'url': 'https://arxiv.org/abs/2004.07737v2',\n",
       "   'title': 'Cross-lingual Contextualized Topic Models with Zero-shot Learning'},\n",
       "  'RFP': {'full_name': 'Recursive Feature Pyramid',\n",
       "   'url': 'https://arxiv.org/abs/2006.02334v2',\n",
       "   'title': 'DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution'},\n",
       "  'Partition Filter Network': {'full_name': 'Partition Filter Network',\n",
       "   'url': 'https://arxiv.org/abs/2108.12202v8',\n",
       "   'title': 'A Partition Filter Network for Joint Entity and Relation Extraction'},\n",
       "  'Accumulating Eligibility Trace': {'full_name': 'Accumulating Eligibility Trace',\n",
       "   'url': None,\n",
       "   'title': None},\n",
       "  'F2DNet': {'full_name': 'Fast Focal Detection Network',\n",
       "   'url': 'https://arxiv.org/abs/2203.02331v1',\n",
       "   'title': 'F2DNet: Fast Focal Detection Network for Pedestrian Detection'},\n",
       "  'Metrix': {'full_name': 'Metric mixup',\n",
       "   'url': 'https://arxiv.org/abs/2106.04990v2',\n",
       "   'title': 'It Takes Two to Tango: Mixup for Deep Metric Learning'},\n",
       "  'DELG': {'full_name': 'DELG',\n",
       "   'url': 'https://arxiv.org/abs/2001.05027v4',\n",
       "   'title': 'Unifying Deep Local and Global Features for Image Search'},\n",
       "  'gCANS': {'full_name': 'Global Coupled Adaptive Number of Shots',\n",
       "   'url': 'https://arxiv.org/abs/2108.10434v1',\n",
       "   'title': 'Adaptive shot allocation for fast convergence in variational quantum algorithms'},\n",
       "  'Disp R-CNN': {'full_name': 'Disp R-CNN',\n",
       "   'url': 'https://arxiv.org/abs/2004.03572v1',\n",
       "   'title': 'Disp R-CNN: Stereo 3D Object Detection via Shape Prior Guided Instance Disparity Estimation'},\n",
       "  'ZeRO': {'full_name': 'ZeRO',\n",
       "   'url': 'https://arxiv.org/abs/1910.02054v3',\n",
       "   'title': 'ZeRO: Memory Optimizations Toward Training Trillion Parameter Models'},\n",
       "  'PULSE': {'full_name': 'PULSE',\n",
       "   'url': 'https://arxiv.org/abs/2003.03808v3',\n",
       "   'title': 'PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models'},\n",
       "  ...}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34f5d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(entities, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a9872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
